{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7400515,"sourceType":"datasetVersion","datasetId":4303162}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Постановка задачи","metadata":{}},{"cell_type":"markdown","source":"Имеются изображения технологического процесса разлива металлических циллиндров. Есть риск нарушения технологии, когда стенки цилиндра не успевают застывать и трескаются. Не застывшый металл выливается, не образуя требуюмую заготовку. Необходимо оперативно определить лунку где произошел пролив. При этом пролив дольно редкое явление. Гораздо больше изображений можно собрать без пролива в лунке.\n\n## Задача: построить модель (на основе автоэнкодера) определяющую состояние лунки пролив\\не пролив.\n\ntitle\n\nДатесет\nДанные - вырезанные изображения лунок. Ссыла на даасет\n\ndataset\n```\n├── proliv  # изображения с проливами\n|       ├── 000.jpg\n│       ├── 001.jpg\n│       │   └── ...\n|\n├── test  # тестовая выборка где перемешаны проливы и не_проливы\n│       ├── imgs\n│       │   ├── 000.jpg\n│       │   ├── 001.jpg\n│       │   └── ...\n│       └── test_annotation.txt\n|\n├── train  #  обучающая выборка из не_проливов\n|       ├── 000.jpg\n│       ├── 001.jpg\n│       └── ...\n```\n## План решения\n- Имплементировать или найти автоэкодер (можно для старта взять пример из лекции по автоэнкодерам)\n- Обучаем автоэнкодер на не_проливах (dataset\\train)\n- Если через такой автоэнкодер прогнать изображение пролива, то MSE между входным изображением и выходным будет больше, чем если прогнать изображение без пролива. Следовательно, если определить некторое пороговое значение MSE, можно классифицировать изображение на классы пролив\\не_пролив. Если MSE между входной картинкой и выходной больше фиксированного порога, то на изображении пролив.\n- В качестве loss функции используем MSE (как минимум для baseline)\n- Для определения порога используем изображения из dataset\\proliv\n- Пишем метод классификации лунок\n- На изображениях из dataset\\test тестируем качество. Считаем True_positive_rate и True_negative_rate.\n- Цель: получить на тесте максимизаровать метрики True_positive_rate и True_negative_rate (получить более 91% по каждой)\n","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"!pip install lightning","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport lightning as L\nfrom lightning.pytorch.loggers import TensorBoardLogger\nfrom lightning.pytorch.callbacks import EarlyStopping, Callback\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix\n\nimport matplotlib.patches as patches\nfrom torchvision.transforms import ToPILImage\nfrom PIL import Image\nimport glob\n\nRANDOM_STATE = 42\nnp.seed = 42\ntorch.seed = 42","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:54.243887Z","iopub.execute_input":"2024-01-14T23:02:54.244214Z","iopub.status.idle":"2024-01-14T23:02:54.253892Z","shell.execute_reply.started":"2024-01-14T23:02:54.244185Z","shell.execute_reply":"2024-01-14T23:02:54.253128Z"},"trusted":true},"execution_count":426,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"batch_size = 256\nnum_workers = 4\n\nSHAPE = (64, 64)\n\nDATA_PATH = '/kaggle/input/metal-spill-detection/dataset'","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:54.254960Z","iopub.execute_input":"2024-01-14T23:02:54.255228Z","iopub.status.idle":"2024-01-14T23:02:54.268392Z","shell.execute_reply.started":"2024-01-14T23:02:54.255204Z","shell.execute_reply":"2024-01-14T23:02:54.267452Z"},"trusted":true},"execution_count":427,"outputs":[]},{"cell_type":"code","source":"train_path = os.path.join(DATA_PATH + '/train/')\npaths = glob.glob(train_path + '*')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:54.270593Z","iopub.execute_input":"2024-01-14T23:02:54.271193Z","iopub.status.idle":"2024-01-14T23:02:54.321304Z","shell.execute_reply.started":"2024-01-14T23:02:54.271159Z","shell.execute_reply":"2024-01-14T23:02:54.320448Z"},"trusted":true},"execution_count":428,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms.functional as TF\n\nclass AddGaussianNoise(object):\n    def __init__(self, mean=0., std=1.):\n        self.std = std\n        self.mean = mean\n        \n    def __call__(self, tensor):\n        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n\n    def __repr__(self):\n        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:54.322721Z","iopub.execute_input":"2024-01-14T23:02:54.323077Z","iopub.status.idle":"2024-01-14T23:02:54.329427Z","shell.execute_reply.started":"2024-01-14T23:02:54.323045Z","shell.execute_reply":"2024-01-14T23:02:54.328447Z"},"trusted":true},"execution_count":429,"outputs":[]},{"cell_type":"code","source":"# попробуем 0-1 нормализацию\ntrain_transforms = transforms.Compose([\n    transforms.Resize(SHAPE),\n    transforms.RandomHorizontalFlip(), \n    transforms.RandomVerticalFlip(),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=0, std=1),\n    AddGaussianNoise(0, 0.01),\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize(SHAPE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=0, std=1),\n])","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:55.141366Z","iopub.execute_input":"2024-01-14T23:02:55.142078Z","iopub.status.idle":"2024-01-14T23:02:55.148681Z","shell.execute_reply.started":"2024-01-14T23:02:55.142049Z","shell.execute_reply":"2024-01-14T23:02:55.147762Z"},"trusted":true},"execution_count":430,"outputs":[]},{"cell_type":"code","source":"class AnomalyDataset(Dataset):\n    def __init__(self, paths: list[str], transforms: transforms.Compose):\n        self.paths = paths\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, i):\n        img = Image.open(self.paths[i]).convert('L')\n        tensor = self.transforms(img)\n        return tensor\n        ","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:55.410217Z","iopub.execute_input":"2024-01-14T23:02:55.410529Z","iopub.status.idle":"2024-01-14T23:02:55.416751Z","shell.execute_reply.started":"2024-01-14T23:02:55.410504Z","shell.execute_reply":"2024-01-14T23:02:55.415722Z"},"trusted":true},"execution_count":431,"outputs":[]},{"cell_type":"code","source":"test_fnames = []\ngt_labels = []\nwith open(os.path.join(DATA_PATH + '/test/test_annotation.txt'), 'r') as f:\n    for line in f.readlines():\n        fname, label = line.split()\n        test_fnames.append(os.path.join(DATA_PATH + '/test/imgs/' + fname))\n        gt_labels.append(int(label))","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:56.262292Z","iopub.execute_input":"2024-01-14T23:02:56.263011Z","iopub.status.idle":"2024-01-14T23:02:56.279589Z","shell.execute_reply.started":"2024-01-14T23:02:56.262974Z","shell.execute_reply":"2024-01-14T23:02:56.278643Z"},"trusted":true},"execution_count":432,"outputs":[]},{"cell_type":"code","source":"class TestAnomalyDataset(Dataset):\n    def __init__(self, paths: list[str], labels: list[int], transforms: transforms.Compose):\n        self.paths = paths\n        self.labels = labels\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, i):\n        img = Image.open(self.paths[i]).convert('L')\n        label = self.labels[i]\n        tensor = self.transforms(img)\n        return tensor, label","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:56.478756Z","iopub.execute_input":"2024-01-14T23:02:56.479363Z","iopub.status.idle":"2024-01-14T23:02:56.485551Z","shell.execute_reply.started":"2024-01-14T23:02:56.479334Z","shell.execute_reply":"2024-01-14T23:02:56.484574Z"},"trusted":true},"execution_count":433,"outputs":[]},{"cell_type":"code","source":"train_paths, val_paths = train_test_split(paths, test_size=0.1, random_state=RANDOM_STATE)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:57.245001Z","iopub.execute_input":"2024-01-14T23:02:57.245662Z","iopub.status.idle":"2024-01-14T23:02:57.253840Z","shell.execute_reply.started":"2024-01-14T23:02:57.245631Z","shell.execute_reply":"2024-01-14T23:02:57.252903Z"},"trusted":true},"execution_count":434,"outputs":[]},{"cell_type":"code","source":"train_set = AnomalyDataset(train_paths, train_transforms)\nval_set = AnomalyDataset(val_paths, val_transforms)\ntest_set = TestAnomalyDataset(test_fnames, gt_labels, val_transforms)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:57.436792Z","iopub.execute_input":"2024-01-14T23:02:57.437338Z","iopub.status.idle":"2024-01-14T23:02:57.441782Z","shell.execute_reply.started":"2024-01-14T23:02:57.437309Z","shell.execute_reply":"2024-01-14T23:02:57.440786Z"},"trusted":true},"execution_count":435,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=num_workers, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size, num_workers=num_workers, shuffle=False)\ntest_loader = DataLoader(test_set, batch_size=batch_size, num_workers=num_workers, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:57.612680Z","iopub.execute_input":"2024-01-14T23:02:57.613215Z","iopub.status.idle":"2024-01-14T23:02:57.618939Z","shell.execute_reply.started":"2024-01-14T23:02:57.613185Z","shell.execute_reply":"2024-01-14T23:02:57.617926Z"},"trusted":true},"execution_count":436,"outputs":[]},{"cell_type":"code","source":"train_path = os.path.join(DATA_PATH + '/train/')\npaths = glob.glob(train_path + '*')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:57.757459Z","iopub.execute_input":"2024-01-14T23:02:57.757734Z","iopub.status.idle":"2024-01-14T23:02:57.800021Z","shell.execute_reply.started":"2024-01-14T23:02:57.757708Z","shell.execute_reply":"2024-01-14T23:02:57.798959Z"},"trusted":true},"execution_count":437,"outputs":[]},{"cell_type":"code","source":"proliv_dataset = AnomalyDataset(glob.glob(os.path.join(DATA_PATH + '/proliv/') + '*.jpg'), val_transforms)\nproliv_loader = DataLoader(proliv_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:57.829994Z","iopub.execute_input":"2024-01-14T23:02:57.830273Z","iopub.status.idle":"2024-01-14T23:02:57.837517Z","shell.execute_reply.started":"2024-01-14T23:02:57.830247Z","shell.execute_reply":"2024-01-14T23:02:57.836541Z"},"trusted":true},"execution_count":438,"outputs":[]},{"cell_type":"code","source":"for images in train_loader:\n    break","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-14T23:02:58.542181Z","iopub.execute_input":"2024-01-14T23:02:58.542541Z","iopub.status.idle":"2024-01-14T23:02:59.784092Z","shell.execute_reply.started":"2024-01-14T23:02:58.542511Z","shell.execute_reply":"2024-01-14T23:02:59.782669Z"},"trusted":true},"execution_count":439,"outputs":[]},{"cell_type":"code","source":"plt.imshow(images[0][0])","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:02:59.786529Z","iopub.execute_input":"2024-01-14T23:02:59.786850Z","iopub.status.idle":"2024-01-14T23:03:00.059681Z","shell.execute_reply.started":"2024-01-14T23:02:59.786820Z","shell.execute_reply":"2024-01-14T23:03:00.058779Z"},"trusted":true},"execution_count":440,"outputs":[{"execution_count":440,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7bfdb350f1f0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAaAAAAGfCAYAAAAZGgYhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABi0klEQVR4nO29eZBd1Xnu/Z55Hno83a3ullpoBIEASYg2OLFBNpdr+0KgEjtFKlxfV1wmghjw/RLrVmwSKrGIXYmJbVkeLhecGxPF5CtsY1+DfWUjPtuSDGJGotHQUrfUfXo+83zO/v4g7uRoPa+jBuHdtJ9fVVfBe5bWXtPe6+xeTz+vw7IsSwghhJBfM067G0AIIeQ3E25AhBBCbIEbECGEEFvgBkQIIcQWuAERQgixBW5AhBBCbIEbECGEEFvgBkQIIcQWuAERQgixBW5AhBBCbMH9VlW8a9cu+dznPifJZFI2btwoX/ziF+WKK674D/9do9GQsbExiUQi4nA43qrmEUIIeYuwLEuy2az09PSI0/kr3nOst4A9e/ZYXq/X+l//639Zr7zyivVHf/RHVjwetyYmJv7Dfzs6OmqJCH/4wx/+8Odt/jM6Ovorn/cOyzr/ZqRbt26VLVu2yJe+9CURef2tpq+vT+644w755Cc/+Sv/bTqdlng8Lv1f+n/EGfA1fVavuuC/cXrqRqyjJQvL1hq4jnzJi8tXQHkHHrJq2o/bV8LfALzLcjBengyZwUgVlpU53O7WlXMwXqubbcnlfaCkiIwHYLgRaMC45cVxX6xkxJa1pGHZfAX35z/1HIbxl7LLYHwiHzFiq2NTsOzpfBy3pYrb0hE05214rg2WbQvlYXyuEITxhoXf+lE9Wh2xQBHGe8MpGD883WXEAh683pLTMRi3aniNu301GK+VwC9fqrgOZxC3pQHWsoiIlME96zOfESIi7kk8x05cXLzr8botnIya7QvjSoKteH7KaExExA2ebyIijbq5VjzKPaihPf2jAfOenRhrgWU94bLZtmJZTv3x30oqlZJYDK8ZkbfgV3CVSkUOHTokO3bsmI85nU7Ztm2b7N+/3yhfLpelXP63DmSzr28czoBPnMHmB7qFNgMRcXrNCXKHKrCsVcd1uJx4ITbcYIiUDchZUTYg5ajNFcQ3pzMA6gngdouycbqCeFOxwE3rtHC7xa/EF7gBucBz0h0yF7iIiMuD++MPe2Dc08Dl3WL23xs+97IiIm5lA/IEzbXlKit1hPAcu5RrOpQNCNWj1eEO4nnwhJS1UjDrcXuVzSCP14S2ATn9yhp3gPvKrW1AytpXrinOc9+AnP6FbUCuIF63TnSvBHAlLmV+nE68xl3KBiRgA3KBZ+GvQtuAXEHzA/hcEhFnUD8q+Y+OUc67CGF6elrq9bokEommeCKRkGQyaZTfuXOnxGKx+Z++vr7z3SRCCCGLENtVcDt27JB0Oj3/Mzo6aneTCCGE/Bo477+Ca29vF5fLJRMTE03xiYkJ6eoyf9fs8/nE5zN/BVDLecRZb34lbenOwGtG/ebvIE+d6sANdCrvnEp8IUK8jj587jI1af5+WESkOIfPWBw186KOWfyrAkcn/pVAQ+lmOmX+PiwAfocrIlJQfmXla8O/w/Z68a9bVrVOG7FTafz75Es7xmA8Xcdj9f72F2D8e7LRiHmU36tMK2cpF7Wbb+wiIpNF83ypL56CZUdTcRgvV/Ctp43hXMHsf1X5dfL6+ASMV5Xzz3cvO2rEfjiyDpb1KGc67hAe28IUOM9UcIbxWY92BmKdUX4dCO7ZWgu+IRp+HK8F8TXryq8gwyvx2RAsC55XIiLLYriO4Ul8vljNm7+y8yrnSxXl+CIeweX9bnOeN64ZgWWPTrcbsbrn3M6izvsbkNfrlU2bNsnevXvnY41GQ/bu3SuDg4Pn+3KEEELeprwlfwd09913y6233iqbN2+WK664Qu6//37J5/Py4Q9/+K24HCGEkLchb8kG9MEPflCmpqbk05/+tCSTSbn00kvl8ccfN4QJhBBCfnN5y5wQbr/9drn99tvfquoJIYS8zbFdBUcIIeQ3k7fsDejN0tU3K+5QszquL5KCZZN5U2XW2oUVJbkCVrGs7ZqE8TMZs+539RyDZZ84tR7Gtb/w9sawGsYZN5U5jQaW41VyWKk2W8TKu2XLZo3Y5Jyp6hIREUUB6FFUSdlZrHiaDZpKm5qi4Homif8ObHkLVhi+lOqBcb/LVFQ9eWoVLLuhaxzGnx0/979JK+YVR4oW7IQQA39pLiKSK+N6ckB91RbHThpeJ1aqPTeNXSO2dJjqpsu6TsOyT59eDuPxEFZTlUbx2rJazT/mdSpK1OoUVkBacbwOkYpU3IostA3fgy7tb1ydWN2FlG2aq0XMh+d+ZXgGxtNl/Mxyt5htmUyFYdnL+/B8ahRq5jo8PovVeMWcqWJuFM/NYIdvQIQQQmyBGxAhhBBb4AZECCHEFrgBEUIIsYVFK0JYE5sy3ItfmTWtfDScygH6QAc+6FsbwfYl3YFzt9iIKAfL/avxAbp2SOl3mYfIZ7KKpbniKl2u4UP+cs2ccktpBzzMFZHCMBY4+HrxgfvYjNn2K1cMw7KZCj5w7vDjA/cjc/hvy4LADX1lO577V6c7YbyqpP9AgpUjJbw2Z2bxofC6Pmzzky1hh+ueNnMdrlUsd94TexnGVwdw+birYMROV1ph2dE4tlA69Zpyb2pWVlnTRqZRUdZhhyLWGceH8w2veQDu0Ky2lK/g/gB20y+XsGM1sq6JeHC7veD+FhFxOrDA4fplOBXJz6dXGrENPVhQ41bq1p5BYbfZ9s3d2KfzFa859/VCWc7F1ZNvQIQQQmyBGxAhhBBb4AZECCHEFrgBEUIIsQVuQIQQQmxh0arglgdnxB9sVpwU61iBsiyQMmJVCyuYjqSwWueVdDeMv7fTVKD87xNXwLJ9UayY6w2a7RMROTTdC+OXd5kJwjQV2PNT2F6lWsVTm0ubKrNIDNuo5DUrkShWu6XS2IonGDIVNYfGsM1NZxT3s2bh70qbgY2MiMj3hzYYsXjUVHuJiLgVexWsYRI5OmkmO/QoieRWJPCaKNbwWs4XsRVPIpI1YutDWPH0zQmcdwvdJyIiK/xmwsCfzV4Ay56ewio4URST7gKOu0rmfNaV5HDVHB4racEJ7Fwpc+03Msqjrg2r3YI+HNeUrm1+857QFGabYnjN/mRqDYxf2/kqjL+zA1uCIVrc+J7dO40TDyIlrqak+9DyQ0aslKvJ8+fQLr4BEUIIsQVuQIQQQmyBGxAhhBBb4AZECCHEFrgBEUIIsYVFq4I7mk+IR5oVQRdGsOrHKaZ6xqMk5bqgawrGhwpYHffUzGojtrULq1hensVKus0tp2B8dRz7fj01YSZO87hw8q2OEFaNaV5wpbypgss6sP9aS4uS8MyN29LVjhVf9Yb5PadQwcqmYhXHr+o4AeP7pwdgvFYwl3baib3DqikcD7Rj1dzWXnM+n5/AasTZAh7bVAorBmOxc1fqPZvph2WfH8dtqSTwmsjUzP6/v/NFWHZ4FnvEFdqw4it4HPe/DKpRhI7iKCsfKN5x9ai5Ph1erOCqV3Dds1pit+X43n96yFyHv3f5M7Csxh39e2H8mbzp+SYiEnSZOs0Ot6mWFBH54tF3wfhV3diTcWXAfE4eyePn2/NZU81bzWMV4dnwDYgQQogtcAMihBBiC9yACCGE2AI3IEIIIbbADYgQQogtLFoVXMKXEZ+/WRGVrmFFzdGsmdFS807T/OTafbj8R3r+PyP2ZGY9LLsiijNutivKFE8Yq8kaQA40nMHqI68T16ElonRGTP8sLSNqA6jXRESmZrGCq6H4ga3pMzNx5pTMn9U6vuZPJ7E3maYOlIbZFr8fe4dVfXhNVMo4fvD0ciNWTGMlXTCOffbCEewpps3F0JiZ+bWzNQPLehSVYq2BVXBhoKb64fSFsGx+BGfDdeeV7Lk92N8tMA7KK32vh7CCzVnEa6UOMqL6jynrLYrb1+jB8zOajcP4xatOm9d04vUWAxloRUSGSj0wPlWJwPjvtQGfyqmrYFlN7ZYs4fk8NG16NRYV5SpSxdbzmpNiM3wDIoQQYgvcgAghhNgCNyBCCCG2wA2IEEKILSxaEULUXRS/u9lO5+cz2JICJffSksDNlIMwXvPgA1qU3CvgwoeLPkUQ8O3kpTDeGcDihAPDpq1HJKwcZnuw5QU+WhVpazXFFlPJGCxbVA7hG9P4QPc9gy/A+FDKPECPB3F/0kV8mK+ccUtJSbwnbnMEstNYPKF9DXN7sJ1TEVj3dHQrieeUg1ttfgolnJDOAax4XA5cS8SPD4BnS3jtHx43k/dZigDFk8ETUY1hoYB3TrGE6jDb3lDyzmmDpZzxiwChTTWC26ElzCsV8boqaRZSXjP+2ClzXEVE1rRhO7D/3Ibtj6bd2Bbo2eIKI9bjT8Gyx/NmEkURkZeT2F6nv3XOiJ39PP4l5RoYKyXJo1HsnEoRQggh5xluQIQQQmyBGxAhhBBb4AZECCHEFrgBEUIIsYVFq4Jb5p2TgLe5eYkAVnIsA8qPqQpWjrR4sfqq3MBDEXKbKjOfkuzu5+MrYPzDFxyA8YdObIXxVd2TRmx0Lg7LHn0VJx/zdmC7j1agPou3YxuimqKEWrURJ9g7mW2D8VNnzHhLG75mpYLnoZDHyrtgCCu+PEFz3qpFRWZVwgqpZf1Y2XayYvZn6kwc113HKqttl78C41MlvG5fOGpao4xm2mFZVwivz0YVz6cXjFVlEo+3C1gciYiERvEY1hThIRoXD741xZ3HdXvyuLzrtGnZVcWOM1JRrHi0JHipcVxRo8vsj5a4sS9gKsxERKZruO4WpaNzYHCrit1SXBlcvxdLCccyZlt6Y/h+GE+ZZeuFc3u34RsQIYQQW+AGRAghxBa4ARFCCLEFbkCEEEJsgRsQIYQQW1i0Krj/M3WxeArNvliavxtKMqcp1TaExmB8fwr7zF0WGzFiL2RMRZKIyKrWaRgfKeNkcmtbsSdUxGMmw3Iqvl+jThzvjGCV2cmkqeBa1Y3bkalgJZSW7O9kFvdzZZ9Zf0rxfHO5sIeUW1EUlYrYO61eM79becaVsn04+ZjWxkbBvG2W9eNkhNq8HRgzk9qJiEQDuC1On9n/RhUrnkIhXEdmBkvSKhOmR5yzopjvKf1xVhWPuDCeT1fRLF8G/nAiIqFRJfEcXp4wXm7D7fBN47oDU3hsc/24ngxI0uj04jX7YgArV/dXTQ9IEZHBTpxMrgES+LkVD7ahjJm0U0QkX8SD+KF1h4zYt167HJaNhUyFXd1iQjpCCCGLGG5AhBBCbIEbECGEEFvgBkQIIcQWuAERQgixhQWr4J566in53Oc+J4cOHZLx8XF59NFH5cYbb5z/3LIsueeee+TrX/+6pFIpueqqq2T37t2yevXqBV3noui4+MLN6jYtw+CWLlOp9nttv4Blf5K9EMYbglU8p4qm39Z0CauJNrea7RDBKj0RkZqF9/9fjJsKKYeiPrKAEkZEZPg09s0LRk2F1MlpRaXXZXrSiehqt/E57GUVBaqshuIzp6ng8mciMG4FsdLIf9JUvGlKqJY49trS2hjuMMtPZ/CaaNQVBRdQ6YmI5OZw1tI48M5Lj+BMtlknrkNZ4uIqmm3xzeLCngyuo27ar4mIiF9RmVVi5nq2FEVnbiWeY3cG1+0A0xw9hvtTxOIwcSr9DEzga5aglyR+vI6H8VrWFJ0/F6yO87rMcZnN47lvD+M1HvTjjMr/7/FLzfZlsWJuoN1UgNYab5EKLp/Py8aNG2XXrl3w889+9rPyhS98Qb7yla/IwYMHJRQKyXXXXSelEpaGEkII+c1kwW9A119/vVx//fXwM8uy5P7775c///M/lxtuuEFERP7hH/5BEomEfPvb35YPfehDxr8pl8tSLv/bbpnJKF89CCGELCnO6xnQ8PCwJJNJ2bZt23wsFovJ1q1bZf/+/fDf7Ny5U2Kx2PxPXx/+I09CCCFLi/O6ASWTSRERSSQSTfFEIjH/2dns2LFD0un0/M/o6Oj5bBIhhJBFiu1WPD6fT3w+xVODEELIkuW8bkBdXV0iIjIxMSHd3d3z8YmJCbn00ksXVFfUVRK/q9nPbWMn9nEbjB43Yi+V8K/yjuWxOkzL/onoDuJzqlX+CRh/Nod9vw6d7IfxLQNmxtGhaSzXWdmGPcimAliVlUzGjdi2C1+FZZ+fwp5VHSHsBacpvmognprASiCHFyvVNIVUoisF4zPT5jxbUZz9MZvDEq6eNpwBMlMyvzD5Pdh7UBurV0e6YFxqWK1VqphKSsuPx8qRx7e1s4zrdgIhVENJHqvFa4oKTlMeOjqBSmoafxG1gnjeJI1VY+6c2c8qXm4SGsPrqtiOx6oWxOURDsUfr1DA/fR4FL/DKp7PC2Km92SujOsOebDarR7A96wHKOxm3HiNXxQbN2JlV1X2wtLNnNdfwQ0MDEhXV5fs3ftvl85kMnLw4EEZHBw8n5cihBDyNmfBb0C5XE6OHTs2///Dw8Py/PPPS2trq/T398udd94pf/VXfyWrV6+WgYEB+dSnPiU9PT1NfytECCGELHgDeuaZZ+Td7373/P/ffffdIiJy6623ykMPPSR/+qd/Kvl8Xj760Y9KKpWSq6++Wh5//HHx+7G1PSGEkN9MFrwBvetd7xLL0n8P6nA45N5775V77733TTWMEELI0sZ2FZzGC9le8TSaDxlXBPGBe8Uyu3GskAAlRVaFcPK1Z+ewaGGyHDZiL471wLIhFz7oO5Ezk8CJiHS2nfsf3TqVRFPjWcX+xo+dJ1b0mgeXhyZ6Ydl0Gtt6IFGBiMhvrzwG40jMsOYC8+BSROTUTAuMl6v4DXpqyLRKEhGxAuZ4ORQhQ7WAT9anvFjIEQmYB+j90TlYNl3Gp/ObLzCFJiIibuQjIyJH50xRRVccr59TY3i9SRkf2tdWmGuloggZ6pM4Dm7Bf/0AhxszZlssnyJYyOHKGz7Fngoku3NhLYhUQ1goEBnFbSm1KBZKQE+kPA6kXMbJ7jYsw/fE8Vk8nx1es1OvKpZdCxFZiYjkKub8BL1YDHKqYFpzVYtK58+CZqSEEEJsgRsQIYQQW+AGRAghxBa4ARFCCLEFbkCEEEJsYdGq4KaLIXE7m20lfqvlNVg2DbJhIfXar4pHvVg1NpYzk35pSdOmK1g1VaxhlVVZsdg4eGSlEWvvwoqnfAkrmxLhLIzHvUUjdmocq2wiUbOsiEgqiX1NfpxdA+OBoKmIOX4Eqw5d/ThxltOv2ICswea1Lz+/wgymFR8ZL1YOOZQEbm6gSGzxFmDZF85gO6PethSMJwJ43qanzDHPhrDtituLLV0CK7G1ELKGabgUNRVQzImIWCm8DiWGlVNobWWUdaVZCGm4wVRoVjyBKcWKpw1/N6/ix4eETpttLPTguv3DeN5OtOBEj1qiujOluHlNRekoQXxfRX14PvuDpqrzqTPmc0lEZDJlrvFG4dzyv/ENiBBCiC1wAyKEEGIL3IAIIYTYAjcgQgghtsANiBBCiC0sWhXcVe3HxR9uVi0dTGMVxsWR00asL4C9uSbK2DstV8XKFCfwVvK6scro4GsDMN7Sho2o5iZwW7xR02vMpySDmitj5d3RCZx4b0X7rBFLdGB1VHIM+7J54yCZmIjUFY+4fBr4uMVwf/xKUq6OGB7DVAl7rSFLtc51pg+eiEgOJJgTEemJYuXhayOmz+DmjhFY9oub/gnG92YvgvH9k3gNvW/Dy0ZMU10+O4q9/YI+7M+VmQLSLkUFp+FQEuk1Stj3LJs21364FysA8wHFSV9R3qHkeJovmzeL++lUcuDVFO+4MhCw1eJ4jTsU47xyBq/l1csmYRw9416WblBSJFfBa7w3nILxX0ya5nYoSZ2IiD9i9rPuws+Is+EbECGEEFvgBkQIIcQWuAERQgixBW5AhBBCbIEbECGEEFtYtCq4n0yuEXe+WbnR5sd+Rj+cvNCI1ZUMgC4lsyhSu4mITGVNpVFnFCuyGhZWyOSA15aIiKOAFUK1vJmJNDmKs5MGLsBKLb8HK3BOp0xvOw2HomCq1HB/Qh3YD80RMCVI+SxWNkHFnOjzps1zYLmpqJqcwarDrQMnYfx0Lg7ja5cnjZjPicf7hRJIlSkiz85iL7xru4ZgfKxszluljuenM47XZ1HxHkwsM9VUmk9hahyP4ZpLTCWqiMhrR3H2YOQRl0thFZiGsxUrrUpirk/fDF4nyi0rDcU2EPnMiYh4gICv7lMyufZhnzS/D0vvahZu+5FMlxG7JDEGy86W8fNDi6Osx7k8vjeXtafMf19lRlRCCCGLGG5AhBBCbIEbECGEEFvgBkQIIcQWFq0IYW1sUrzhZqsNr3LQ+0rKtJ8oVvEpYqGC40EvPgBE9jInj5pWLCKi25e4FbsPfK4ujTCwvFCsTryKRU9GOTCsZE37EofWvjg+SKxX8PcWzYqnlDEPhYNxnOyumMcCh+xpfPjt78LClPaIGe/qNMUDIiKZKh6r9gA+zO8JmMIPTYByrNAJ4+/uwMkVjxewhdJ1rS8ZsVeK2HLnJcEH/+N5PIbLwqYV06tTeI0H2vEpvCZucacVoQ24V9whfA9qpkB+Py7fGDLFDMqjQ/LdeM0iOx8RkXKbctOidmhWPDPYQsjZi++3kAfH81Ul+RxgLIPnvjuC7Y+u7D5lxF6cwevq9JRp2cWEdIQQQhY13IAIIYTYAjcgQgghtsANiBBCiC1wAyKEEGILi1YFN1poEY+jWeWR8GPFRrZsKqf8mjosh+UtOSdWXzWA3UlIUV7l53DdTh9O5OSoYUUesuixvFh9kytgBVdLBKuVGmFTfTY9hRUyTiUBVV353hJQEp6tX22qz547ji1qRLH/8XZg1dwl3dh6ZKpoJlnbEj+Jr6nwndMbYRzZNp3OxmFZtyJ1bLTgMewPmAkDRUSezpnJGIeyWKmWKeM1oSXeO1o2lXelEl6bjRput9uL77dGD1ZDuZJmG+PdODFipaYktVOUkUHQlHIr1tL5p7B6sRbC5RtKIkXXHHiUKspVzf+nkMPzc8qJE0MWgMVXPIrve5diNdYTwmP+zKRpFeVVngf9neaareXLchKWboZvQIQQQmyBGxAhhBBb4AZECCHEFrgBEUIIsQVuQIQQQmxh0argrm47Jv5wc/Ney5sJmDTmCooiTVODtOLEbiNjbUYsDxLGiYg4Soo6rAUruEpKri7UxkYFK4Eaiv9awIN9shCrVp+A8ZmSmYxPRGR0Ln7OdYuIvDoJ1FqKEsgZxu2uzGFl14mwOT8iIitiWE2G2Du5Dsav7cbJ4Z6aXHXOdZdr+BYbSmGPuENl7O+2pWvEiGleYA5ljffFUzB+ZNhciE4PVjw5Fb/DehWvT0uZ5+gaMwkeSoImIpKZMBWNIiIORWRWiZtt9GRwYQfuprgLuLzvCB7zSgsYl6xyz/rxGAYP4zWeXYYViZbfVFhOZ+KwrCOA1Xsng60wPps27/013ZOw7HTBLFs/t3x0fAMihBBiD9yACCGE2AI3IEIIIbbADYgQQogtcAMihBBiC4tWBVduuMXRaFZ/hNxlWLY1YPofHcu0w7LVHFaxjNax35LTa8pk6kWsbulcNQPjsxmsmgsEcX/KZXNafBGsDmsJYYXdRDoC4zFQXlO7XRCdhvHhKaycWZnA/c9VQUbUTiyTeX7Y9KASEXH4sVypXMVLOF02VZC5upL51I+9/TS12+Wto2Y7Glip9MwU7k9yDs9PWFkTE0XT9+yi+Dgsq9Gw8PfN8Tazbm1cS0m8VsK9WEVaVepB9bvdeI49yGdNRKotiv+cx1SwuUpY1Zbvw159WvlSJy7vbDPXs2sYrzdHXWnLCsVnLofnzVEwx6XWpmSVVTz8Uopa2OUy+9nqwz5zSLVblXOTwfENiBBCiC1wAyKEEGIL3IAIIYTYAjcgQgghtrCgDWjnzp2yZcsWiUQi0tnZKTfeeKMMDTXblZRKJdm+fbu0tbVJOByWm2++WSYmJs5rowkhhLz9WZAKbt++fbJ9+3bZsmWL1Go1+R//43/Ie9/7Xjl8+LCEQq+rY+666y75/ve/L4888ojEYjG5/fbb5aabbpKf/exnC2pY0FkVv7NZXfH9oQ2w7MW9Z4xYPYmVZ54urOSoTWI1iBU3VSWJ5dhnbGIsDuNSwft8XVG2DV4wbMRKdTxV2QpW2lzUjxVSxzJm9kvNO6yu+HhdufwkvmYYX/O7Zy42Ymkla6fTg1VG777gKIy/PIv9AedK5nzOVLCnWKsXq+C07KQvZ0zvNLdiKra+FX/5GvFi1WVSUS/2BlNGrMuLlWcuBx7D74/h+yd9Mm7E3AlF8dSC1U25jOK96MZt6eswveCKVSVD8LoUjLuVTKmlsqnUc+PErCJ46YuFqxaX4vdYT5nq2kAa3z+5Aax2C5zG93gtrDQSDK0zg+vw9edw3IPbguJDs9i/cH2bmfG4Wjs3FdyCNqDHH3+86f8feugh6ezslEOHDslv/dZvSTqdlgceeEAefvhhueaaa0RE5MEHH5T169fLgQMH5Morr1zI5QghhCxh3tQZUDr9ej7x1tbX/y7k0KFDUq1WZdu2bfNl1q1bJ/39/bJ//35YR7lclkwm0/RDCCFk6fOGN6BGoyF33nmnXHXVVbJhw+uv9slkUrxer8Tj8aayiURCkknzNU3k9XOlWCw2/9PXh/9wjxBCyNLiDW9A27dvl5dffln27NnzphqwY8cOSafT8z+jo+ZfmRNCCFl6vCErnttvv12+973vyVNPPSW9vf+WQKurq0sqlYqkUqmmt6CJiQnp6sKHxT6fT3w+06plrhYUX635UDKhJI2bLoLD5TZsaeJ5AR9E13rxIbL7jNm2bMiMiYj09WErmtFT2BYoEMIHdchyKFXBh7ynUzEY11gVnTJiPzu9EpaN+7DNz1wJCzx8TjyG7+4yBQQ/Sa6GZZUcY3KmgPu5rgUnyRrJmYf85QZe7heFTRHLr2IFmP9ObxaWna7i9dbmx5ZQATcWpkxXzIP152aWwbLv6DRFLCIi/RHz4F9EpLHWHPV0EYtESkX8ndVSEtJtvuAkjKeAVVJHAB+UH5kCCQ1FJBHDY14NmwKKMQsfoLuLeMXVAvjg39eDBSv1oimgyG/Ac+k7hZ8fdeWaioOSNHxmeXdeSfToVIRGDVy5122KELQkl8hqq1rV7uSz2nVOpf4Vy7Lk9ttvl0cffVR+/OMfy8DAQNPnmzZtEo/HI3v37p2PDQ0NycjIiAwODi7kUoQQQpY4C3oD2r59uzz88MPyne98RyKRyPy5TiwWk0AgILFYTD7ykY/I3XffLa2trRKNRuWOO+6QwcFBKuAIIYQ0saANaPfu3SIi8q53vasp/uCDD8p//a//VUREPv/5z4vT6ZSbb75ZyuWyXHfddfLlL3/5vDSWEELI0mFBG5BlKX8Q9e/w+/2ya9cu2bVr1xtuFCGEkKUPveAIIYTYwqJNSPeLmeXiLjWrK2qKYmNy0lRI+Y8vTGniH8cqnuIKU6nmB8maRETGpuMw/s6Lh2D8eBqr416e7TZilRqeqrUdWAW2MYaVXc+lzL+zuqb/NVj2pTnTckZEVytpHMub9j8bWrFtzxHFFkhjqoRVZg1gI1SsY6uXJ6fX4joUTd6G6JgRqytSpekybp/Gla1YwXaq2GbE1sXx3D89vRzGO4NYNXZmzEwwmOhKwbLvWIbb95Pja2A84MLKqWTNTIJ3Y9fzsOyaMO7no8cvgfHCFEiaF8XtqCkiUsccXivVEZyQL3JB2ohlT5t9FBEJJPG6UnIaiquC74nMSrMe7flWSWNV46qVOOnkVNHs5/gc7k9fn6murHqYkI4QQsgihhsQIYQQW+AGRAghxBa4ARFCCLEFbkCEEEJsYdGq4NIlv7iczUq2hqKCswqmgq0awWoQj5IkqtSFfcycfjNeLGCFXUsM+0S9Mo198FqD2GutDBRv8QAu2xXAyqaXQNI0EZFTKdMjbSyH1S0RH/bTSwMfLxERp6JgQ4q0Di9W0jUUZZfGs5PYD22w65QRO5bFqsOoF2cr6wmYyiYR7CmXqeExmSjiBHNtfrxWfE6s1popm/572ngHFQXSWA5LvpDiLe7H6+1UzlTMiYjUyvhR8lrKVECKiAxEzWR/rxZN9aeISNCJ+9MTx96Qo3XzOVGeVtas4m1XD2GlqzOM5yebNut3VPCzRkt2V8VLRWp1XI83ZcZKXbjdDpeijmvgxrSA+dfc3ZAHpENJ0Hg2fAMihBBiC9yACCGE2AI3IEIIIbbADYgQQogtcAMihBBiC4tWBed11cXlblZSOB1mlj4RkWzB3EfjR3C94TGsqJm+BGeoLOdND6VqAteRVdRxtRpWmjgVWYnLaSpZUExEJKmorPpDOPvlQMjM2lpVZDn9PlOpJCJSaOCx8ijKl7DLVJlpdaSqONvqWBEr9UJerEo6mjHVV1r22P88cBjGW9xmZk0R7BHnFKwy2tB9Gsb/78x6GC8rhmBoPg9MrIBltbWC1Igax5JYvXZ5/yiM+8NYMekHmTW1tpzIYZVipY7Xp0fJwBsJmm1pGcBzmRzFqr5EL75/Jk7i8i7wDAqO4+/3ZVyFKAJICY3htZVaB9qhqPoc7XisEoqK9mcnB4yYz4fncipg+h1Wy/SCI4QQsojhBkQIIcQWuAERQgixBW5AhBBCbIEbECGEEFtYtCo4n7smbnez+mUkieUjjYip8Ci1YTWRN4+77JtVvOOASKScUbKt+nDcsRorcFIZrPha1p4yYisjpnpNRGRKybg5W8F1j2TNMXQonmLJIFaerQ8nYbzdjRU1SB0X9+AxGS5i9VWHX/GOUzKRIn+79Z0TsOypAl5Xy1qwEiruMtv+3cmNsOzVrcdh3K0o1bTMqv/3lJm1dUvPCCx7EsyxiMhsHq8Jt8ucn99eeQyWHVfUiO8deBXGNeUd8tO7thVLV781thnGz2RwW3I5nP0TEe3E62omhe+rVWtxJt/jr5jei/k+PMfhU3iO3Xl8H+b68BiGgCCxomR4LXXja74wiT0jEX3xFIyvjZr3VdlZlcfPoU6+ARFCCLEFbkCEEEJsgRsQIYQQW+AGRAghxBYWrQihXHNL7azEbB7FCsI6aR46hsfwAaC7iOOVMLb7SK81DwYbEeyZ4ZnEwgd8tCjS04YTnk1lQ0bM78bXvLwFW6OMFPFBdFVJ6oc4mcZ1XBE7CeMRYLkjItLlThmxmTo+5HUrdj6tHly3liAt5jfLZyv4cPoPe/fD+GwNt/HbE5cZsbRS91AhAeOadU+mhuvZkDAPv/e9ugaWHeidgnEkNhAR2Zww15DHge+T7gBOAvfSHD7MvrwVr89kyRQQjFfjsOzaGBaP9ITw/XM6b9YzowgwOsNYhDCUxIkOjyv9dLSa1jPBF3ESPFcJz32xE4sNAlO4fC1gli/24Dl2jSnCjBgWAyHbnWQW2361+825pBUPIYSQRQ03IEIIIbbADYgQQogtcAMihBBiC9yACCGE2MKiVcFNzUbEWWpWbjQqWKkWTptqkBp2xZHIME6cVWjHKhlPFiQfm1GS17Vh5ZCltDvowUqRni5T3aNZmqRquN1xTxHGES7FimddK7bc+ensBTD+XzpfgPFrA6Yy57t5rOrTrHXURHWKHUsQJKqrKwrAH8/h5HADwWkYdwKF2H/qwkntnk4th3FtPkeLLTA+WTAVSJra7cws9mNZ3oathbp8prKtxZ2HZV/K9sL4VM5UboqI+NqxcrXLb15TUwau8GMbqmPFThifzJrqRW28tfXja8X3T6WA7/1GwXyUKoJGkQZuS/yootCN4PLAzUgix/CzJrNWmYcIts96bcxUb4ZbsQISKSYtwX05G74BEUIIsQVuQIQQQmyBGxAhhBBb4AZECCHEFrgBEUIIsYVFq4ITSwwTNUcWN9cFxGReJbmTO4W9j+o+rLLyzQAFChalSCWGP2htx0qToePYV8ofN33MWiNYlTSWw4qnuTz2oVreaiqhNIVQsY697T7a8xSMH8xjddwPC+Y1k7U4LOt2Yi8rjUs6cYKwqaKphIr5sLLpeKYdxkNurJjcHDcTwWXrWPLkd2H1UcCFVYDpKq4n7DXbcmoOK+auGTgK4weT/TCOfAOrPsUbUWnfCiV538lCG4yjNacpILV1qI3hxWBNDGeUZJbK2i+V8DU15eHIM9g7DhE5jRVirip+ZkVO43ui3GK2sdCjOE968TXHFRVgJHzuKtqjaTOJZC2P752z4RsQIYQQW+AGRAghxBa4ARFCCLEFbkCEEEJsgRsQIYQQW1i0Kji3ryaus7LylaN4v7QcwPjNwmqQ9MVYlaPYoUm5zfyg3IlVKQ4/jk9PYKXJ1guPw/grk11GTFPrTM3hLIWREM4gmquYY1VX6s6CsiIi/+y6AsY3RpTslzVTqTddxe2+MDgG48dL2PdrtozVi2fS5jXHnfiaIR/25Jsu44yoKK61Y2UE+5hpvme5Kh7z06A/Gj88ug7G+zqwUg2pyQoN7HnW5ceKzqMZUwklInKmgtudCJr1rAxghZmWVfZ0IQ7jSElZrWNV32wKz7HXhxV2J5P4+eEDnpF1P57jSgjfb5aiovWlcNybAc8mLPYT3xk8n8UoVvtVy+bW4GvDis7BzmGzHbmqHMRNaYJvQIQQQmyBGxAhhBBb4AZECCHEFrgBEUIIsYUFiRB2794tu3fvlpMnT4qIyEUXXSSf/vSn5frrrxcRkVKpJJ/4xCdkz549Ui6X5brrrpMvf/nLkkjgQ8RfhctlicvVbB/hnMMHZr6UeRjnzWBBgLukCAjq+JAO7dGBCTxsmUF8cIkSzImInM7GYbxSMevPKkIBn3JYmp7DCcIcreZYZXPYtmdw4ASMVxv4QPdMGVvD/DS/yohdHsOCBb8DCwL+7+k1MO5y4oPefNLs/7KVOMFcfwQfzofcuC0vz5oikSiwyhERmSzhQ+4jk/ie6IzmYDzqN+sfn8YH/B4vPiw+dbgbxn0Xm+WDSt81a6HZIhZhvKsH2wLF3KbVS8KD75MjFm631sa+oDmfJ+aweKA1jsd7agSvZY1St/lcCZ3E90kljusIjWG7nFwvfk9wglvfjbsjFn50ildZKyvaZ43YiQlsWXUmHjdi1RKem7NZ0BtQb2+v3HfffXLo0CF55pln5JprrpEbbrhBXnnlFRERueuuu+Sxxx6TRx55RPbt2ydjY2Ny0003LeQShBBCfkNY0BvQBz7wgab//+u//mvZvXu3HDhwQHp7e+WBBx6Qhx9+WK655hoREXnwwQdl/fr1cuDAAbnyyivPX6sJIYS87XnDZ0D1el327Nkj+XxeBgcH5dChQ1KtVmXbtm3zZdatWyf9/f2yf/9+tZ5yuSyZTKbphxBCyNJnwRvQSy+9JOFwWHw+n3zsYx+TRx99VC688EJJJpPi9XolftbvAxOJhCSTSbW+nTt3SiwWm//p6+tbcCcIIYS8/VjwBrR27Vp5/vnn5eDBg3LbbbfJrbfeKocPH37DDdixY4ek0+n5n9FRfDhNCCFkabFgKx6v1yurVr2uatq0aZM8/fTT8vd///fywQ9+UCqViqRSqaa3oImJCenqMlVDv8Tn84nPZ9qPVE5GxOlvTn7lBXYXIiKWCyi7ehXFnJLULrcM78XISaTcpijpJrGNyowPK9J6WrDq5+rlpvrs2YleWNbjxm0J+RV7mWnTjsbtw0qYFyZwkq16A4/V72x4FsZb3GYSQM3q5asnfwvGAx7cRs1GSPymokgrO6Uo1bAxjMjyKFBZpbDKKuTB6rjLus/A+AsTOEkhUkZaNTwPnR1YClWN4GSMkzmz/5sSp2HZGcVyKBHGFj1VCyvBHj11iRF7Zw9WXWpJ8Ao1vIZGC+euYCtV8fPAWVRsv3B3xAFuwzp+HIhHUapparfghGLpEzHXc2gMl527CMddyr2MbLj8AfxMeWXKfL7XC7+mhHSNRkPK5bJs2rRJPB6P7N27d/6zoaEhGRkZkcHBwTd7GUIIIUuMBb0B7dixQ66//nrp7++XbDYrDz/8sDz55JPyxBNPSCwWk4985CNy9913S2trq0SjUbnjjjtkcHCQCjhCCCEGC9qAJicn5Q//8A9lfHxcYrGYXHLJJfLEE0/Ie97zHhER+fznPy9Op1Nuvvnmpj9EJYQQQs5mQRvQAw888Cs/9/v9smvXLtm1a9ebahQhhJClD73gCCGE2MKiTUhXj9bECjQrnxwNxYNtpRnzZrDiqR7AcQcWWQnKGxYYx1KY8kWmv5WIiFtRqs3msaLI7TAVXPEgrltTpI2ewaos9zRQB/bh9uULWMaj9edLp94N4wG3aVoV9eKEecsVX7aDwytgPBzG9Tjc5hiWFcXTjJKUTFP9nJkzpZGa6vCl01hJGFUUaV43XoiNhrlua268DotVrACdy+D19g7g+ecEa1BE5MgEVrSe7dv4S14bx4kE3R5zDX1/aAMsuyKBk/qdGMPeZFtWnjJi2n2SO42TRbqqynOiG89bbcpU6rkUIVgdi/rUpJh1xcct32f+gyi23pNAUnnXuABfFKkDLUVFetUyc/1UclV5BV+xCb4BEUIIsQVuQIQQQmyBGxAhhBBb4AZECCHEFrgBEUIIsYVFq4LzjXnE5VfkH2cRHjWVHBXT8kxERIITWMFV6MCKoq6DpoJr/B142DxHcWbRfBv2rPJ0YmVbI2yqTZyKRKakqHtEUfE0PGY91qwiywnjbKshRcE1lcVqMqTgmwD+YyIis0mc5VOUzKeZPK7H12Kq43KKqk+THxWU8u0gi2ZKySqrqd1CXjy2uTJeK/U6yMwbxMq7TB7Pp5b98uKI6Us3XOyAZQM+fM1CSckorIxtDfjYdbdhb8SVEZzJttyJ78NTGdMLrlTGzxK/omgtdWJVn1XA9biBd5ymatMUt8VOxa+tqCjy6mb5Wkjxy1Se9K2KujbuN+NnMlgx+PKcmbG2lv81ecERQgghbwRuQIQQQmyBGxAhhBBb4AZECCHEFrgBEUIIsYVFq4KrrixKPdis8vAqKrNSm6n80HyY0hdg1Yt/BitQZi40VS++WVx3FQuy1G2+oihqjp1KGDF/BHeoNIPHRMMJ1HHuOdzAMhYMSsqFM7w6FaXaVNUc82gIe7i1d2Ml1MwsHtyWTpxe0gO8ySbG47DsmhVJGD8+gb3GskVTHRdUvODKii9bQ1EvFhW1FvLhys9gb7fly3Eu17EZrDCcrpqS0YPJflg2k8XXbNSx+soJPPlEROoF89Ez6cRz3BnE621sOo7rLpvrzaGsTacitNWUZzWfkinVbdZfxDZ4otjsScsRHIeGlCLiBreQpv6thnEd2RJWepZq5vxc2jEGy6JszfWSkqn4LPgGRAghxBa4ARFCCLEFbkCEEEJsgRsQIYQQW1i0IoRGyS3iaG6eJiwo9JinesExvLc2zs3dZ55Q0qy75tOsMXC82IsPAB3gIFZE4JljScli5SjjfobOKIfcHWblTsUaxPLh01KXcqBbr+Jr1rLmoBdBQjIRkUgAixO8fmxdU6rgCYW1KPPz2ogp+vhV5Qtp03amHMMihERrBsbHRnHCQG8UL/ILOk07mqEqbndBET6EFeHH/zl5oRHrjGBxhyaeyGSxGAYJAkREfKCfNSVh4OlsHMY13H5zQTucirWOAx/CqwktgU2WCBb31IL4mqHTeExqfkUooYiBan5wTUWTVAsqdSvj0gKseF5NYVVFENgz1Wr4fjCuf06lCCGEkPMMNyBCCCG2wA2IEEKILXADIoQQYgvcgAghhNjColXBOfx1cfib5R8uRfHUtd+MTV2GVR+BSUXdoijbAjNABQfUJyIiuX5F7aYo1RyKuqUB1DMOj+bfgSupT2LVXGjMbHsDi3LUdjeCStKrBo7Hu7JGTFNNIUWNiIhPSabmdeP+I+ues9fTLwlHcVKu7Dj2NQl25o1YcRzbyMy4sY1MT98MjCensF3Oa2Om4s2l9X0Ot6WRUySgwC4nN43brSkDtbGNtOCEfB6XWT5dwwtxTrH/8QfwWimdMOetoTzpAikcL7Xhe1lThlbB/emewxfV7rfQJK47OIbXZ77XvIeybiXBXg/uD7KsEhGZLZpjviyCbbIujI4bsXKuKs/A0s3wDYgQQogtcAMihBBiC9yACCGE2AI3IEIIIbbADYgQQogtLFoVnOeUT1z+Zp+m7ArNz8ncR6PHserDn8JqnUK7kpQtasYDM7iOfAoPZyUOw2J5lERTGVPJYuVw+7xpHNf8o6pAUOTBQiVxFZTvJ+243d0dczBeA/5hWwZOwbLJfBTGp6exIi0Uxf5ma3onjNjoXByW1fC3Y/VRBSSNsxQV2Ip2nL3wtSNmEi8RkVgvVhqhMSzksY9Zo6LIrFx43lB8/QqcfOxYsgO3bxqrLnOCFWziMK/pAR5uIrq6Mj+BlXqo95HjSiI5ZaicFSWhGvB8ExFx58yKagms0oueML0ERUTcBeX55sTXrAbMPmXWKGrRVnyf1BVvP6R4my7i8X6+Ya7lWl4x7jwLvgERQgixBW5AhBBCbIEbECGEEFvgBkQIIcQWuAERQgixhUWrghOXqVDxZLEaxJMzFTWFbkXFouy5yPNNo+FR2mFahL1e3qtkUawpGVR7TCVL+DieqvhxrL6a3ojlPU4gzCkksDrKpSQ1dCjZTDMlrMrKnTaVbfELscJsJo9VU5EYLl8o4GsOV8yMox0xnOVT0YaJ6WD3OtUqGNsKXldDR3tg3BHBGV6Lz7fCeMNrtlKxgpNKB1ZCeWbxGgqsTxmxI8O43c4MrsPTjaWUjWGsnKoDv0P3q1hJV92I582hKNI8GXMuSiATsIiIf0p7TmAcQcV7EWQDdk9itVtwCj9rvCmsHGt48L1c7DDbjhS0IiIVF75PEokpGHc6zDZW6rjuKjC3q2mGd2df55xKEUIIIecZbkCEEEJsgRsQIYQQW+AGRAghxBYWrQih0lETZ6D5MDV6GCfUsoCVSHBcSSilbLmadU3DbR70BZKKzYSFDx1dJXzRSgwfgCZ+ZpZPX4AvqYkNwiO4/9WQec0Kdr9Rk3g1KvgDB7BXERGJ96eM2FgGX3R1Gz4UHZ4zRQUiIvUaHtta3lwrc8qpPbLWERHxKEnw6kWz/5ptkUMRmmjtrsYUOxa3ObYoJiLiH8P9qYZx+dLLcSPmiON2NKKKXY6i5KiHFXEPEGGUNfubUSxk8BaU5HjgkpETuOqGYodVL+K6y2k8tv5JIHzowuvNm8Fj6KjhsarF8HMFEVybgvGIHz+zZkDiORGRoMecn1IV3/cXtZnXrFiKguks+AZECCHEFrgBEUIIsQVuQIQQQmyBGxAhhBBb4AZECCHEFt6UCu6+++6THTt2yMc//nG5//77RUSkVCrJJz7xCdmzZ4+Uy2W57rrr5Mtf/rIkEokF1e0suMR5lp0DSqYmIhIbNtUmlgOrWFKrsWosNIHVMJFh0wbEWcIKj4YHK7v8M7ju1ColoRhQ3vlnYFFV1acq2ICIx1XGY1VpwyoeS7Gd6ezAlin9ETMp22tznbBs0I0tajSFXSyGLWDSJ+NGzNupJCOcVOxiAnitODymWqkew3U7vDjuHtfmXrFFAio735xiRZNVFKCKOwpaQ5p6zx3Ea78+jm9Oy4eVXc45U9mlJVf04TyHcC2LiASA1U2+G9ftVuyznFioJt6UktgO3G/R1/CANxQ1pjOFG+MKYxWcF8xzKo/tjDTCijrOA2TBHhdu91zZnPuqopQ9mzf8BvT000/LV7/6Vbnkkkua4nfddZc89thj8sgjj8i+fftkbGxMbrrppjd6GUIIIUuUN7QB5XI5ueWWW+TrX/+6tLS0zMfT6bQ88MAD8nd/93dyzTXXyKZNm+TBBx+Un//853LgwIHz1mhCCCFvf97QBrR9+3Z53/veJ9u2bWuKHzp0SKrValN83bp10t/fL/v374d1lctlyWQyTT+EEEKWPgs+A9qzZ488++yz8vTTTxufJZNJ8Xq9Eo/Hm+KJREKSySSsb+fOnfKXf/mXC20GIYSQtzkLegMaHR2Vj3/84/LNb35T/P6FHXZp7NixQ9Lp9PzP6OjoeamXEELI4mZBb0CHDh2SyclJufzyy+dj9XpdnnrqKfnSl74kTzzxhFQqFUmlUk1vQRMTE9LV1QXr9Pl84vOZiqCGpyHibVazNLx4vyzFTbWJL43VN5rqpRpSvLyAyVX91WO4bOIyGJ/ZgDfr8JiikMqb8VIbnipvFvez2IoVOOnVZn98swtLyuUZx6qc8aCiAgTKtkIFS5gmihEYdzmxsquoqG2sgDmGqTO4fZ4WxdtPUd5VZ8F8evE8OIDaS0TEndMUbDjeANW4lGZriQRbjuD+FDrNtZ+N4LK16QCMOxXLN+/MuSUmE9FVehW8JESUZVsHCSM1VVt0FH+QXqH4HSqedyjRY2xYuaii0M1d1AHjNT9+NuX6cPUIzWNR44XRXiN2ce8ZWLYGJq6hTc5ZLGgDuvbaa+Wll15qin34wx+WdevWyZ/92Z9JX1+feDwe2bt3r9x8880iIjI0NCQjIyMyODi4kEsRQghZ4ixoA4pEIrJhw4amWCgUkra2tvn4Rz7yEbn77rultbVVotGo3HHHHTI4OChXXnnl+Ws1IYSQtz3nPR3D5z//eXE6nXLzzTc3/SEqIYQQ8u950xvQk08+2fT/fr9fdu3aJbt27XqzVRNCCFnC0AuOEEKILSzajKjOSFWcwWZ1hXPs3JvrLigKMyVzpYblMRUe5es3K4VxuOM57FfmGcMmV5lLTcWgJ49lRpWI4k2lKIoiJ011ClJYiYj4JnEl5ZVYfuUcxX5gZ0Bm0ZAPS7WGJ3DmUw2nIktyVM1xcVSxMqc2g1WKgW7sbVcLmf1xJbG3m0PJtOsq4bj2lRD5HTqriqqtA8+bq6Io28C0uZWMoE4la6mrdO7qPRERBxCIBZNKRt1jeL3NrcFjnusDbVFEWUhBKyJSiePy2j3uAUulEsWTGT2Gpbj5Pnz/FNuVrL9B85ng9WEvxd5gCsYfO3wxjK/tnTBio5kWUFIkA/znGgVtgTfDNyBCCCG2wA2IEEKILXADIoQQYgvcgAghhNgCNyBCCCG2sGhVcIFQRVzBZulK1YvVSv6UqRCqRrC6JTyGVSL5LuxNVmkxlTYOzfcqhdU6rgxWhDQi2FfLmzElQs6K4jVWx+0uxfHUVoAdmqZU0pRa7iT+B9U4lnyVimb5Wg3Pj9+P56eQw4qnel7x7Aqb9TimcbudZfw9rJjH15ScOebeFJZZoUyZrzcGh71pxX8uYLYxNl6EZd1FfNG64qWIfNJcigrOjQWd4sTTJg3Fly5+wlwrFcWPcXITvu+R/5qIiDdtxooJPK7ZfmUiFLVb62El8y0o75vFXnCWC/ezrKjmavgxIQ2/edGK4o14uhCH8d9ajX0tp0phI9YRUlShdbPd9YayIM6Cb0CEEEJsgRsQIYQQW+AGRAghxBa4ARFCCLGFRStCKOa84mw0HwK7lfPC9HKzG5rtSMdpfHCbXokP82cuMg+uw6cVm58iPlivd5oHeiIi7iwWLXhS5ul/uV1JBFbTMmThcOurZtunLsOFPXk84PmV+HDVlVGWU8Zsu5KqSype3B9np6KIyOExD5ww25Jbgw9GnUod0afx4XdhmdlGVWygTI8mNqgrghCUeNBS7oeUspbjJ3D/kV2QdtjeAMneREQKCcV2ZkRJmNgCDq4DuO5qCIYlPobrzvWadbsLuG7/DJ6H4DSuu6E8hOpg/oNFvMrdiihJHNiKp9SB22j5zDZekJiGZefKuO5T6VZcPm0O+vLEDCyLbLVqNUUhchZ8AyKEEGIL3IAIIYTYAjcgQgghtsANiBBCiC1wAyKEEGILi1YF5/bVxOVrVpEogiJpANGPR7EMqYaxQqjuw+oWpFbKDChqNx+2bnEXccvdASXhG0iSpSWYs5y43QFFxVMC6iPfjKLsUZxoQsOKbVFUSXgWMdsSGMMdqmHBoFRnlLFVEr4VukH/FQulRgSrlRpeLElzI3WgUrcH5x5T8ebwGHozwLqmBbev41lsmVJYhpVQHc+basxSG340eAq4o1378Q2XXY6vieys0H0sgm1uRERyffj7cwMsLa1uXwZXXorjun1p3H9f3qzHWcLrauxanHTRVcJt8U/j+zPXabbl1AxOGud243bnk1hi2LHcTJZ5ZjYGyzpA8+oF5YF1FnwDIoQQYgvcgAghhNgCNyBCCCG2wA2IEEKILXADIoQQYguLVgUXCZoJ6aa7sDdXw2t2I3oKqz4sF1aUhM9gORXylCu142Hz5hQplIJ/CvvSeVOmgkRTPGlecK4y7k+2DyXYw2PiUHJKVSM4HhpT1HResz/BSTxWc+uURGg5/F3JVcblUUK1wGtK3XgapO7DY4v8wDSlltbPhrIO/TOKz2DeVFTl2vD94AEJ80RwokMRERdQa/lnYVGpKcrNUodybypPmErU7L8niwfRg0V9Um5RkgCCJsZfw/NQDSprX1FXajjAfTi5FWR/FF1dmlmlJJ2sKUrXiKleLBfx3Pu8iv9cAHc0kzfns1rGkxmOmHXXPec2gHwDIoQQYgvcgAghhNgCNyBCCCG2wA2IEEKILXADIoQQYguLVgW3PDYrnlCz8mvuCPZQagC1UnolVuu4FY8ij+bBBTyeYiewwqMcPTf/o19SvBjLyaKnzGyChU48VZqixqtkJw2fMet2NLDCTlNquRWfvWKnoigC4p66klnTm1mYKknLaInQFE+xE1gGN70RZ6H1ZM2Yq6xkrVSylmqeauUWxWfQD7J8Kt5h+S48n5ERrIQqJkzFU82vNFyhGtIUkOdeT02Zn4qiunQpSTeDE+a4aO1wKkpPH8hAKyJiKV/ZKzFz3kpt567SExFxFXHltQ7cyADIRKrh82AFpC+E66hMmh5+4d4MLItW4bnelXwDIoQQYgvcgAghhNgCNyBCCCG2wA2IEEKILSxaEcJEPiJuaT5hD65OwbLZOfPArDGFT+fDY/g02z+DD/qKHaa1hSeL6/AoVjzFdnzq6FesR9CBs2bz40jDsHrQiax4tAN0bXVogoDAFK4nMmoegNYCyoGrYvVSx3oA9fAb9SlyBh/EJgdx5S7FvSScBAOgDGE1qFgIVRZ2yF0LmP0stitJ01JKYyxFKAGG3JfGk5xP4EWh2eJoNkelDrMtWuI1p7Le4sfwB7PrzA6Fxs697yK6CEO7V6pgfgLTuGxqrWLxFMRrIhjDgzg7Bax+6rjdxWmcGNATM+18REQiQHDQUBQ1lYq5JhqKFdjZ8A2IEEKILXADIoQQYgvcgAghhNgCNyBCCCG2wA2IEEKILSxaFdwF0WnxhpstRUbcLbBsNml6dZQSioonjWUvlTDei9ueT5nBYyOwrKMnAeMi2EJIU4L5Zk1lSt2PlVoORdlU8+C6g5OmEqyk2L846rjuQFqxkQF2JCIiqVWmkjA4gecnNKkkyFqO63ZWcRvdRTOe7cXLPTqsqBoVuxxX0Yxn+7D9jV4HvmZqJVZv+mfN/mhqRC1JYbkN1205TXVTph+PlWaX4wPtExHJDsCwOEGStcA0HqtSq6b2w8rVnp+b9jJORZWFbIhERAqdeL1p6jikUizjx5VYbtxPTZHmcuHyTq/Zp0ZBeaS7FPVeFq9bRGssD+N+YPNTd+C+nA3fgAghhNgCNyBCCCG2wA2IEEKILXADIoQQYgvcgAghhNjCglRwf/EXfyF/+Zd/2RRbu3atvPrqqyIiUiqV5BOf+ITs2bNHyuWyXHfddfLlL39ZEglNHaZTE6c4zjLGavHhTGjxbtO3KD0XgmUL3XjP7UgqSpMMuGZnOyxbDysJzDJK0qcoLl/oNuNaMjUPFqaIQ7EDq4CkeS5FSVYJ4bFquBfmk4U81WrA705EJHpSSZrWhtVKHpAwUESk7jPb6FW89zSvsboPtxH5u2nJ+MIvKMkLW5SEgYpXYSFhzls1DItKcBL3sxRXfPaAOK6YWFhiQEtZE6pvIEgal1fuTY8yb5r/Xh0oQB2q9552X+HKZ9fj8v4ZM1Zchr0HxY3rDgWxcszjVtaEEygjq3gMnSUlMWAXvmajYdYzeRQ/95ztZh0NJfGn8W/PqdS/46KLLpLx8fH5n5/+9Kfzn911113y2GOPySOPPCL79u2TsbExuemmmxZ6CUIIIb8BLPjvgNxut3R1dRnxdDotDzzwgDz88MNyzTXXiIjIgw8+KOvXr5cDBw7IlVdeCesrl8tSLv/bDprJ4LSvhBBClhYLfgM6evSo9PT0yMqVK+WWW26RkZHX/yjz0KFDUq1WZdu2bfNl161bJ/39/bJ//361vp07d0osFpv/6evrewPdIIQQ8nZjQRvQ1q1b5aGHHpLHH39cdu/eLcPDw/LOd75TstmsJJNJ8Xq9Eo/Hm/5NIpGQZDKp1rljxw5Jp9PzP6Ojo2+oI4QQQt5eLOhXcNdff/38f19yySWydetWWb58uXzrW9+SQEDJGPYf4PP5xOfDFiGEEEKWLm/KCy4ej8uaNWvk2LFj8p73vEcqlYqkUqmmt6CJiQl4ZvQfcUFwSvyhZg+xZ+aWw7Kr26aM2Cs1xcvJwt5H6QEla+m06ePmzmLlSC2KN1LvRA7GIxWsbkHKHEcVq3jqYdyfupJZFFHoxMug9WV8HlfoxQrD8Encz9wKU66lee+VOnB/gpO4/9q8tb8IlDlefE2t/z7F8y48amaorPtwxsliO6677sWqpHIMx2OnTEWV5cBlNcVkHQsJpdgOFIPKUWzsBFZ2TV2mqPpGFZUi6H/shKIYjOF5y/bj+y04YXrETW5R1uwZRWHWga/pwEtCCj2KJA/gDOAx1NRuU6fjMO6NA89IRf5aj+O6HXP4fvMlTPVv2a08a9Km12ND8To8mzf1d0C5XE6OHz8u3d3dsmnTJvF4PLJ37975z4eGhmRkZEQGBwffzGUIIYQsQRb0BvTf//t/lw984AOyfPlyGRsbk3vuuUdcLpf8/u//vsRiMfnIRz4id999t7S2tko0GpU77rhDBgcHVQUcIYSQ31wWtAGdPn1afv/3f19mZmako6NDrr76ajlw4IB0dHSIiMjnP/95cTqdcvPNNzf9ISohhBByNgvagPbs2fMrP/f7/bJr1y7ZtWvXm2oUIYSQpQ+94AghhNjCos2IOpTrEs9ZirU7e38Ey/7L7BYj9oKigqt0YAWKf8pUcoiIFBKm8iM+hQ3Yyv2KOZeF41rGUU8yDQorXk5u/B2iFsJT62iY19S83cavjsF4yzGcibLhxdcMjpn+bo4uLMkqRzX/ORiGPnMiIpObTIWUf1rJnlrC8UKn9v3M/JMDTR3lSymZeRO4QyiTq4hICWSb9ebxRathPJ+VqBKPg2umcNmZC3G7/ZMwLJYixkRea9p4tx3Gk5zvxiq4Qqd5LzsreFw1FaXmD1gL4zEPrDRlg/ksXuMO4OEmIlKr4/6vXT0G4ycmTG82f4ep0BQRKaVwW1ytWNFbmgPlg/jZ6faBzKxe7H95NnwDIoQQYgvcgAghhNgCNyBCCCG2wA2IEEKILSxaEYLXWROvq3l//N9T74BlW72mKCARz8Kyc158kJZpYKFALWgOUTneCssGpxS7mJX4sLT1MBYzWCHzANA5DYQJIuII4ro9aXwIWASH/4FpxRLIgQ9oc12K7YriRlIFie08ygF6cFqz3MEiEe1wOXbCrKfUir9vVSL4wL0ELGpERGpBc1xC47jd2V48VpHTeB1q1j2RUfOwOLUKz30oieez5sd1BybMfgYncH98GUX4AJL0iYhYylfc4KQpZCnHcfvmVuMDdM0qKb3evKjlwuuk4VGsa0JKArsAHtsLWs2MdEO1TljW78UinmIZW90cy+J66nlzvAKd2A6rpPQ/HMICjzpIjpedwM9IC4gQztWYiG9AhBBCbIEbECGEEFvgBkQIIcQWuAERQgixBW5AhBBCbGHRquAujZwWf7i5eXXBqqTpasSItfrNhEoiInE/tqo4qSRyytWiRsxVweqwuRYcD0zgul1HT8O4I2Ze0/JjhYzUFCXQKpwgLXYC9B/Y84iI5JbhOqInFRWPouCyXOa8ObEITGp+PMfuAm5jNaQkZQPKu1IrLuvBYkTxz+BrVkDSOM0qqNip2eJgVV9sGKusMiD5mnbNhgdfs+0VbLvinTGVUJNbzTUoIhIax+3zZvCa8I7MwrgVMPtTibbgOrJ4HrJ9+H5DyrZaRPFKUr6CO+NYRdqo4bEdmjSVauUCnuNqFbe7XsZxlxe33QmscXKK/Y8LKNVERDJZnMnaA9TCjioerHrepoR0hBBCyBuFGxAhhBBb4AZECCHEFrgBEUIIsQVuQIQQQmxh0argkpWo+CrN6ooWRa60yj9hxJ6d61vQ9f54zVMw/rnse41YaYuiBHoOeyUFFa+1+upeGHdlgVqpglVGAhRmIiLxo3iskDquodThzWD10cRmrMiLH1N8woBlWb5L8Q5TEu/VsVhHHIrYpg6u6VSG0KOorGqKws4FpkfzmfNgay5VBaglSIuOmGPrwYJO8c3iysffgb3jYidMFVP8GFaBeeawd5hzZBzGazNYBefuShix6HO47tSWbhgH4tfX453mRHsjuD81RdGqqd1icayujfjNRTEl+HnQaChqzJNYdVoewOrFMGhLpYIf6XUlQWdjDq+JShj46bnxfeKomGVRDME3IEIIIbbADYgQQogtcAMihBBiC9yACCGE2AI3IEIIIbawaFVwdXFK/az98R+PXQHLvrvvqBGLe7FEyOfCCqFXi1hpE4+bajKvG0uvkuuw91OpA8fjR0Iw7imYapi6V1GqKZlFfXO4nyiz5uSlWGIWHcV1txzF8cAkVhq5gaqv0If7XgEebiIiTiymEgsPCxwvX13xdosrmU+xrZYEgbefJ6/UHcZ1tx7Gaqp8L75o+JRZPrcCj6GrjNdn66ta5lsQdOJ25y7Ayi7HitUw7k3jdVj2m/NciWCl1szFuC0NRZXlCZkquJ5WnFF4No+VZ5lxLLHL+7ACNJ0C9aRwWWc7VrVVFbWb5PBjuhwwnyuVrOIZWVduFCVTqsdnzptzBNddB2FHiSo4QgghixhuQIQQQmyBGxAhhBBb4AZECCHEFrgBEUIIsYVFq4KrNNxGysfOCDbWOpbtMGJexWwrV8PeR07BapBE2Lxmux+3w+fCKqNTjXYYn3sXLu8/bKrS3JrvVxbHNXWYACVY5/O48nILVu9p/mvOqpJ1EhBIYt8v6cIqME1NVWxX2gim06t48hWq+DaIz+Lypbip1gpMYaO56HGsbMooajKtnkqLuW5Dp/G8OZQsua6yotSLnLsiTVMp+rL4muOD+H5DyY3907h99QHFf0653957wZBZ1oHbN+Q0PelERHI5vA5rZbxWehIpI3am0gbLuhQVrYzjsaq34rVfQ5lVFZ+5YDtWXdaO4My37hFTYVluxfNjASVdQ8myfDZ8AyKEEGIL3IAIIYTYAjcgQgghtsANiBBCiC0sWhHCRDkiHrdiK3EWUY95SLk5dgqWPVnCB4MtHnxId6YQM2KvTHfBspUaHs6OLmwDMjXSAuOF5cAGo4C/K7iLOO7148P5MLDXabiVg+UZfCBuuRVrFA+uJzNg2ppET+AD9HwCH35rIgSN0Lh5+F8N4vkJTmkCB1zeWTMPWCtxXLYWwv2J//g4jDf6O2EcCQvqIXx/1MI4Xo7i+UHn89le3O66Yk9UalPKB/BhtLNirqH0Wlw2EMAWT/k0bszRjClKmithu6mqkqhNEwo0nHgMZ7LAFkmxv6kqQobuDZMwPnamFcatOXOenco1K3NYbFCP4DF358166q34eeBMv/FthG9AhBBCbIEbECGEEFvgBkQIIcQWuAERQgixBW5AhBBCbGHRquBaPAXxepvVSZkKVr2czsWNmJaQLlnEiaZm3Ti5V9RrKuxWRaZh2ZECVrUF3VjFkyti640GsNOwprF1S1VJeFaJ4nip1VQDOYCqS0TEn8LxslK3N4vL13xm+dRqnAjMl8Z1zK7DY2U5cFt8c+Z3q2oYf9+ylORrijsTTHbnzWCrFwuLrKR02XIYb7iUeQMqM8VtSvyziqqvE/e/AQSTDaXdxR6sDgudwv/Aoaiyyh2gHmUa8rNYwebw4jF/7ZiZXLJ9GVaipmbxfR+MYvufUhH3s5w3FWmrVo/DssdPmyo9EZHJF7AtkEt5TfAOmD5cpTHcH21wtTVUC5mL338KqysrrWAezvHVhm9AhBBCbIEbECGEEFvgBkQIIcQWuAERQgixhQVvQGfOnJE/+IM/kLa2NgkEAnLxxRfLM888M/+5ZVny6U9/Wrq7uyUQCMi2bdvk6NGj57XRhBBC3v4sSAU3NzcnV111lbz73e+WH/zgB9LR0SFHjx6VlpZ/U3999rOflS984QvyjW98QwYGBuRTn/qUXHfddXL48GHx+xUjKcCrqYS4q83Kp2oD75fdoYwRC7lwIrBCDXvBXR4fhfF0zVTgjBax2u3kHI7/zsCLMN6+PA/jPxi60Ig12rH6qB7AYxJIKh5xQGVW7MAKmTxQr4mI5Pux+qj9ORgWdwkkrFL85LK9ii+doo4LTirJuoAHW+SkkpQrhH3zUqux8g4l5KsrY+UECQBFRLLL8DUt5SthuU3LMGgytxarlcIjuC0zm8359M4oDVGaUVPEV9Y6nLxRJs37qnvVFCw6dhIndAy0YKVrEHiW1ZVEbZ4A9jfrjWPV3LEiVrCJ0xzbsRT2X7OKim9gy8L8DssjpjLWVcP9RN5uIiKusuJXBzziUJJHERF31qyjUTq39bqgDehv/uZvpK+vTx588MH52MDAwPx/W5Yl999/v/z5n/+53HDDDSIi8g//8A+SSCTk29/+tnzoQx9ayOUIIYQsYRb0K7jvfve7snnzZvnd3/1d6ezslMsuu0y+/vWvz38+PDwsyWRStm3bNh+LxWKydetW2b9/P6yzXC5LJpNp+iGEELL0WdAGdOLECdm9e7esXr1annjiCbntttvkT/7kT+Qb3/iGiIgkk0kREUkkmv+gKpFIzH92Njt37pRYLDb/09fX90b6QQgh5G3GgjagRqMhl19+uXzmM5+Ryy67TD760Y/KH/3RH8lXvvKVN9yAHTt2SDqdnv8ZHcVnMYQQQpYWC9qAuru75cILmw/I169fLyMjIyIi0tX1eqK2iYmJpjITExPzn52Nz+eTaDTa9EMIIWTpsyARwlVXXSVDQ0NNsddee02WL3/d12pgYEC6urpk7969cumll4qISCaTkYMHD8ptt922oIYlQlnxhJqVbJoXHPJaKzdw19r9WHn2YmYZjK8Jm1kKL4vit7SZEpYCvZIxvalERM7kzGyrIiKtcbONc07snebvxCqe8jLsWVUcNdvorCqZKKcUZRfIZikikloDwyKWWR4pyX4VoSRu49xqPM9th81xya7AY6ipe5Dnm4iIu2j+g9kL8Xj7ZnHdqu9Zj+KnFzKValq7XQVceaFLmc84uH/8SqZQP564agkrBj1HsIehc7WpYNPUbuEEVtIVcvia8ZBZdyqP/eTiEaykG5lVfB1DWF1bqZz7o9QRxGo3q4bfB1wzWDHpBvNc7lDqduD5rGJrTGk5bMZS6/GC86TBulLUdWezoA3orrvukne84x3ymc98Rn7v935PfvGLX8jXvvY1+drXviYiIg6HQ+688075q7/6K1m9evW8DLunp0duvPHGhVyKEELIEmdBG9CWLVvk0UcflR07dsi9994rAwMDcv/998stt9wyX+ZP//RPJZ/Py0c/+lFJpVJy9dVXy+OPP76gvwEihBCy9FlwOob3v//98v73v1/93OFwyL333iv33nvvm2oYIYSQpQ294AghhNjCok1IN10MidvZfMjodmALmOmSedCJYiIiW1tPwvhLmR4Yz9TMXx1OVXDdbYrAocuP/7i2048PV8cKpjgh4MFig6kMbouSp00afnMM63E8roELcfuqShKvwHFsAVMPosNL3EBliqUawuUb+JJSbDOXdmgcJwZ0Kgn5im34+xlKAuibw+2oYd2D5AYWZruCCHbh9ZafwPNTbcf93NRvimqOTOLkaKUCHvBGEE+ccxk+5O+Im2tr9UpsxXNkBitoB/qxwuPEjGm3pVnr1BTvo66wmexNROT4NLbyCvrNtZWaUgQYPizksJTkfZrYxHKZH4RO4Ud6NaxUolBuMdsSUv5CphIHQSakI4QQspjhBkQIIcQWuAERQgixBW5AhBBCbIEbECGEEFtYtCq4uUJQXNKsgnMochCf59wVRUfznTB+QXgaxmcrpqJoroJtPSIebNORruLyU4pSr1o3bTM8Lqyc+c8rX4Hxp8ZXwXit31TrVGrYpqNSVZZHBX9vqbRiJRRyRXJYeC6RSk9ExDeL2xIeVdQ9QFBkuXG75y7AdRc7sSopOGZeM79sYao+/wS+ZmkZVjsiXPuwlZNzAF+0dRVWjeWqpqXNQBsu+2oZq+M8rSUYRzZMIiJTs6bnY1sAJwycncOqvkIZW9S4XGb/p/K4Du2Zot3LDSUpZi5vtsXhxfPgmMAWQhLG5b0pPIZeIK7N9eP+eOdwHfWAch+CoS30KO2bA2OirPuz4RsQIYQQW+AGRAghxBa4ARFCCLEFbkCEEEJsYdGJEKx/PZyuF8xDQO3AsO4+dxFCFeQOEhEp1/Hhb6Vilq9WlUN7pW61LWVcvlY3vxdoliFlxaIHjZ+ISB3UXVdECI2GYn9TVA7cS7iNDVC9li2kYeHTy3oZL9V65dxFCLUqXid1JZdLXclpgq6pldVECMp0SqN47iKEehkLUxolZQyVNVGzzLjlVA6nC4rYwKl1VFlD4DC/msf3g3bNuihjBUQIDqV92jOl6sJtqSttaYBnQgPcayIiosxPA7Rb5FetfVBHSXlGamtZ6b8DlFfXVdnsZ6P8+jhZitho/jrWf1Ti18zp06elr6/P7mYQQgh5k4yOjkpvb6/6+aLbgBqNhoyNjUkkEpFsNit9fX0yOjq6pFN1ZzIZ9nOJ8JvQRxH2c6lxvvtpWZZks1np6ekRp1M/6Vl0v4JzOp3zO6bjXy2do9Hokp78X8J+Lh1+E/oown4uNc5nP2Mx/Hdq/x6KEAghhNgCNyBCCCG2sKg3IJ/PJ/fcc4/4fIp1xRKB/Vw6/Cb0UYT9XGrY1c9FJ0IghBDym8GifgMihBCydOEGRAghxBa4ARFCCLEFbkCEEEJsgRsQIYQQW1jUG9CuXbtkxYoV4vf7ZevWrfKLX/zC7ia9KZ566in5wAc+ID09PeJwOOTb3/520+eWZcmnP/1p6e7ulkAgINu2bZOjR4/a09g3yM6dO2XLli0SiUSks7NTbrzxRhkaGmoqUyqVZPv27dLW1ibhcFhuvvlmmZiYsKnFb4zdu3fLJZdcMv+X44ODg/KDH/xg/vOl0Mezue+++8ThcMidd945H1sK/fyLv/gLcTgcTT/r1q2b/3wp9PGXnDlzRv7gD/5A2traJBAIyMUXXyzPPPPM/Oe/7mfQot2A/vmf/1nuvvtuueeee+TZZ5+VjRs3ynXXXSeTk5N2N+0Nk8/nZePGjbJr1y74+Wc/+1n5whe+IF/5ylfk4MGDEgqF5LrrrpNSSXEgXoTs27dPtm/fLgcOHJAf/ehHUq1W5b3vfa/k8/n5MnfddZc89thj8sgjj8i+fftkbGxMbrrpJhtbvXB6e3vlvvvuk0OHDskzzzwj11xzjdxwww3yyiuvp0hfCn389zz99NPy1a9+VS655JKm+FLp50UXXSTj4+PzPz/96U/nP1sqfZybm5OrrrpKPB6P/OAHP5DDhw/L3/7t30pLS8t8mV/7M8hapFxxxRXW9u3b5/+/Xq9bPT091s6dO21s1flDRKxHH310/v8bjYbV1dVlfe5zn5uPpVIpy+fzWf/0T/9kQwvPD5OTk5aIWPv27bMs6/U+eTwe65FHHpkvc+TIEUtErP3799vVzPNCS0uL9T//5/9ccn3MZrPW6tWrrR/96EfWb//2b1sf//jHLctaOnN5zz33WBs3boSfLZU+WpZl/dmf/Zl19dVXq5/b8QxalG9AlUpFDh06JNu2bZuPOZ1O2bZtm+zfv9/Glr11DA8PSzKZbOpzLBaTrVu3vq37nE6nRUSktbVVREQOHTok1Wq1qZ/r1q2T/v7+t20/6/W67NmzR/L5vAwODi65Pm7fvl3e9773NfVHZGnN5dGjR6Wnp0dWrlwpt9xyi4yMjIjI0urjd7/7Xdm8ebP87u/+rnR2dspll10mX//61+c/t+MZtCg3oOnpaanX65JIJJriiURCksmkTa16a/llv5ZSnxuNhtx5551y1VVXyYYNG0Tk9X56vV6Jx+NNZd+O/XzppZckHA6Lz+eTj33sY/Loo4/KhRdeuKT6uGfPHnn22Wdl586dxmdLpZ9bt26Vhx56SB5//HHZvXu3DA8Pyzvf+U7JZrNLpo8iIidOnJDdu3fL6tWr5YknnpDbbrtN/uRP/kS+8Y1viIg9z6BFl46BLB22b98uL7/8ctPv05cSa9euleeff17S6bT8y7/8i9x6662yb98+u5t13hgdHZWPf/zj8qMf/Uj8fr/dzXnLuP766+f/+5JLLpGtW7fK8uXL5Vvf+pYEAgEbW3Z+aTQasnnzZvnMZz4jIiKXXXaZvPzyy/KVr3xFbr31VlvatCjfgNrb28XlchlKk4mJCenq6rKpVW8tv+zXUunz7bffLt/73vfkJz/5SVNGxK6uLqlUKpJKpZrKvx376fV6ZdWqVbJp0ybZuXOnbNy4Uf7+7/9+yfTx0KFDMjk5KZdffrm43W5xu92yb98++cIXviBut1sSicSS6OfZxONxWbNmjRw7dmzJzKWISHd3t1x44YVNsfXr18//utGOZ9Ci3IC8Xq9s2rRJ9u7dOx9rNBqyd+9eGRwctLFlbx0DAwPS1dXV1OdMJiMHDx58W/XZsiy5/fbb5dFHH5Uf//jHMjAw0PT5pk2bxOPxNPVzaGhIRkZG3lb9RDQaDSmXy0umj9dee6289NJL8vzzz8//bN68WW655Zb5/14K/TybXC4nx48fl+7u7iUzlyIiV111lfEnEa+99posX75cRGx6Br0l0obzwJ49eyyfz2c99NBD1uHDh62PfvSjVjwet5LJpN1Ne8Nks1nrueees5577jlLRKy/+7u/s5577jnr1KlTlmVZ1n333WfF43HrO9/5jvXiiy9aN9xwgzUwMGAVi0WbW37u3HbbbVYsFrOefPJJa3x8fP6nUCjMl/nYxz5m9ff3Wz/+8Y+tZ555xhocHLQGBwdtbPXC+eQnP2nt27fPGh4etl588UXrk5/8pOVwOKwf/vCHlmUtjT4i/r0KzrKWRj8/8YlPWE8++aQ1PDxs/exnP7O2bdtmtbe3W5OTk5ZlLY0+WpZl/eIXv7Dcbrf113/919bRo0etb37zm1YwGLT+8R//cb7Mr/sZtGg3IMuyrC9+8YtWf3+/5fV6rSuuuMI6cOCA3U16U/zkJz+xRMT4ufXWWy3Lel0G+alPfcpKJBKWz+ezrr32WmtoaMjeRi8Q1D8RsR588MH5MsVi0frjP/5jq6WlxQoGg9bv/M7vWOPj4/Y1+g3w3/7bf7OWL19ueb1eq6Ojw7r22mvnNx/LWhp9RJy9AS2Ffn7wgx+0uru7La/Xay1btsz64Ac/aB07dmz+86XQx1/y2GOPWRs2bLB8Pp+1bt0662tf+1rT57/uZxDzARFCCLGFRXkGRAghZOnDDYgQQogtcAMihBBiC9yACCGE2AI3IEIIIbbADYgQQogtcAMihBBiC9yACCGE2AI3IEIIIbbADYgQQogtcAMihBBiC/8/ialdKmUgEdMAAAAASUVORK5CYII="},"metadata":{}}]},{"cell_type":"code","source":"for images in proliv_loader:\n    break","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:03:00.060830Z","iopub.execute_input":"2024-01-14T23:03:00.061105Z","iopub.status.idle":"2024-01-14T23:03:00.457930Z","shell.execute_reply.started":"2024-01-14T23:03:00.061079Z","shell.execute_reply":"2024-01-14T23:03:00.456538Z"},"trusted":true},"execution_count":441,"outputs":[]},{"cell_type":"code","source":"plt.imshow(images[0][0])","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:03:00.460291Z","iopub.execute_input":"2024-01-14T23:03:00.461164Z","iopub.status.idle":"2024-01-14T23:03:00.736379Z","shell.execute_reply.started":"2024-01-14T23:03:00.461133Z","shell.execute_reply":"2024-01-14T23:03:00.735481Z"},"trusted":true},"execution_count":442,"outputs":[{"execution_count":442,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7bfe22304610>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"for images, labels in test_loader:\n    break","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:03:00.737921Z","iopub.execute_input":"2024-01-14T23:03:00.738228Z","iopub.status.idle":"2024-01-14T23:03:01.617631Z","shell.execute_reply.started":"2024-01-14T23:03:00.738201Z","shell.execute_reply":"2024-01-14T23:03:01.616337Z"},"trusted":true},"execution_count":443,"outputs":[]},{"cell_type":"code","source":"plt.imshow(images[labels==1][0][0])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-14T23:03:01.619751Z","iopub.execute_input":"2024-01-14T23:03:01.620077Z","iopub.status.idle":"2024-01-14T23:03:01.886151Z","shell.execute_reply.started":"2024-01-14T23:03:01.620048Z","shell.execute_reply":"2024-01-14T23:03:01.885262Z"},"trusted":true},"execution_count":444,"outputs":[{"execution_count":444,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7bfdb3129120>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAaAAAAGfCAYAAAAZGgYhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9uUlEQVR4nO3dfZBU1Z0//nf37ad5YGZggBmIM4RUiGgMqKg4i9lNcBLKSixdqaxJmVo2a8XSDEYgW4lsRU2sxHG1NhqTEaNr0NTGZcNWYWK2xLUwYiULKKNWfNglmPBdRmEGQeepZ/rp9vn94S+dNPfzwT5MN6eneb+qukpPX26f2w/3Mz33PZ8TMsYYEBERnWJh1xMgIqLTEwsQERE5wQJEREROsAAREZETLEBEROQECxARETnBAkRERE6wABERkRMsQERE5AQLEBERORGp1I77+vpw9913Y3BwEEuXLsUPfvADXHTRRe/77/L5PA4dOoQZM2YgFApVanpERFQhxhiMjY1h/vz5CIdP8D3HVMCWLVtMLBYzP/7xj81rr71mvvzlL5uWlhYzNDT0vv92YGDAAOCNN954422a3wYGBk54vg8ZU/5mpMuXL8eFF16IH/7whwDe+1bT0dGBG2+8ETfffPMJ/+3IyAhaWlqw9CdfgVcfL7ov43viv5lMRwNj+ZzdbxdjiZw4HvX84LbCmLbtiWSV45H2MyOeFredXzcsjs+KTojj72TrA2P/b7xV3Patd5vF8Wxa/uLseXlxPByRxyXa65adCL7GAOCNKHNJBvfjyU+h9Xg4F/zI5CPyt3Ujv8QIKW8Vad/vjZc2diJ55fcd0rh2PJrY+NRPI7mEPK7NxY+Lw8g1CGP18vz8hDxu4vJ7NuQrz0suOO6l5G3DdqcJ5JX3kI1wWp6L7Xtf3LfwPvQzKez78e0YHh5Gc7N8HgEq8Cu4TCaD/v5+bNy48U8TDIfR3d2NXbt2BbZPp9NIp/90tGNjYwAArz4Or6H4Hebl5FfC82LBQcsC5CWyyr6D7xYvIr+DIpYFKK8UIGk/0bj8QYnVC8cOIB6VjyeWDW4fMfIn2UvLZwTfk982YaUAeRYFSHvdwkYuQGGtGPpCAVIeUh1XzqnhcPCOkFaAlE9YSCke0r7fGy9t7ERC2lyEce14NF5s6gXIyG9lfS5KAZLeznmt0NRVrgCFUZ4CpL5BbXahXM6w/UxIwifY+P0uo5Q9hHD06FH4vo+2trai8ba2NgwODga27+3tRXNzc+HW0dFR7ikREVEVcp6C27hxI0ZGRgq3gYEB11MiIqJToOy/gps9ezY8z8PQ0FDR+NDQENrb2wPbx+NxxOPKd+kaoV27qqSJvPz7jGSucs+1L/za60TjknxKfq5CSfmtGhGu9QBANBkc81LyY3op+dcwEWV7mbwP7bqL7fUb6dqQtg/tMaH8Skhm9ys17dqV3T60+Sm/JlO2l3696SnXQDS+8rN5WP7NNkLSNSDlMW1fe+1XpxITKfsl/Yoq+zegWCyGZcuWYceOHYWxfD6PHTt2oKurq9wPR0RE01RF/g5ow4YNWLNmDS644AJcdNFFuPfee5FMJvGlL32pEg9HRETTUEUK0NVXX423334bt956KwYHB3Huuedi+/btgWACERGdvirWCWHt2rVYu3ZtpXZPRETTnPMUHBERnZ4q9g1oqqKeX/Ifdmb94Ha+8geN2h9Fal0MYsIfnWqdELS0W0b5A1qN1PUg4cnxmzplfNKX/3Az5Qdf8nSuPG8DozznRki2hdLytrFxOTkUUcYTx+TUT2I4OB6ZUDo1aN0HshZ/QKvIR7U0lbxvbXurx1T+cDMfU8aF7fUkncw22SWJKGlEvSuDlviSEmnKHrTnypv6HxbrnTRK38eJHlN6jfy43bzVceEUp81vKvgNiIiInGABIiIiJ1iAiIjICRYgIiJyompDCNVCCxzYsFl2wdbRdKM4PpypE8dHhQ7X707I22pBDo3WGsUbD+4nfkwJiSgXbuNCqAAA6o8o4ZGxYDjDm5CvooayU38dysVESw+saIEFo4zn6uSPu83SC1pgw3b5BnEfakhC+xdaq5vS29HoS1RMPYSghSq0EILtc5tpDI5r8xOyR///vuVxMVTBEAIREdUKFiAiInKCBYiIiJxgASIiIidYgIiIyImqTcHFIzlEIqUlgjJCmiyn/NuI0FoHkFvuqI9n2XInp4w3xDPiuNQaZwRyUm1EHAUGR2fI+04FW/RoC8ZprXVUyvaxkeB4/ZC2CJw8HhuVW9fE35Fjc5ERYTW5bAViPGUWisofSSkdp706WgOhaFZ+v5WDryTsbOSV94+esNO2t9mHRkmkKck76X2rvZe1cU0uGFwFIKfppIXxACCknEq191BYOB2qLYGksRJPp/wGRERETrAAERGREyxARETkBAsQERE5wQJEREROVG0KLub5iJbYfEhKpUmL1AEnWHjOYpE5Le2m9XzT2CxUN56OieOTynhqJC7vyCbZpizeF4rIKZ6QrySEksExrYeb1g8rMim/F7wJeUG+ilKSauVg0wvOVjmeK71vnhLVUkgL8tn2totMaj3vgs9hrr70xNx74/J7OZcovb+b2vMtY5eCC1v16pPHbRJspxK/ARERkRMsQERE5AQLEBEROcECRERETrAAERGRE1Wbgkt4WUS90tIfaU84DKXPmpY801JmUrJN6+2mrSCq9VrLpEt/+tW+bEl5H96ksrpkXTCBY+JysklLu5mUfPyxYXmO0mqmkUm7VUj11TzlxwznhJSVsu10oCXEJFLC7ESkdJyadlP66dk+Zngi+PkMW/bqM/Vy0jMqJAn9evn9o72vtNScTf+5XEJb4VV7z8qPqCX1IkK7Q7WHnZakU0KXeYswpnQ0hr3giIiomrEAERGREyxARETkBAsQERE5UbUhBBvxSOkXL23b6EiBAy08oAUFjLJIlNYWR2xpo+xDCxvoghcpwwm7QIBRrlx6KW2xrtIvUGsX27WLwrlE6VdL7Rclqx5SiyLtonVkwu44pQCBGkKwbENkE2YITYhX1WGSE/K+Y8HFFQEgXB9cvDFcL7cKCjXL4+GsEk5IyI8pvbds2/yorXuU9lTye8Ju377SsUtr3SMRF6Qr8WPJb0BEROQECxARETnBAkRERE6wABERkRMsQERE5ETVpuBSfhS+X5w4SfvydNO54Li0kBxgl3YD5MRbXmlFE0or6TAlqeallVYdwm6M0hbHF1rrAICJy8mzROtkYKy5ITgG6Iv0DaRaxXEvLQ6LqZ+JttLTRACQaZTHtbSOL4SbbNqLlEtYCYGF7LrOAAgevyeHxhBR04jyz5sxYQG3yKTcmkpqcXQinhxgE44GMFl5wTyTkdtqmXFhpUMA4YzQWkiehnoCDGeV42+V37c2tHScrvRUo568k8fVheos5shWPERENO2wABERkRMsQERE5AQLEBEROcECRERETlRtCu5U0xaTk/q7qWm3MXkf0aSSSpJDPMg1BMdSs5W0W4OyQJjS321O03hgbG79mLhtwpP3/VaiRRzX5IREmp8ofWEvQH5O3tuPsgCXRZIwrwWblO21vnwSLQGppeNsaL33ckq6MjKuLZAWHNcSc1pfssiEnI4LKQvVhS16yhkh1QYAJiun4/LBtzjCSt847ZXUfjKPTAT7zAG2PQnLMy5vO736HfIbEBEROcECRERETrAAERGREyxARETkBAsQERE5YZ2Ce+6553D33Xejv78fhw8fxrZt23DllVcW7jfG4LbbbsNDDz2E4eFhrFixAps2bcKiRYusHifhZRH1ihMdWi84qe+btvKp1vPN90tfzVRLNtmm3bReXlLiS0u7NbbKzba04xxPB3tcxSNysielpOA8T042ZZWkWt4LPi+5RiVhpvDjlgk2iZJqM54yl4jS90xaRVJJUfrKz3hGDnZZ0XrbaUkobXs/IfWZ01bWVFJwWp85ZSXbWF3ws6wszgkvKr/I2kqpIi1Jp2yuZcni78grqEqz11bx1V6fnPA6AHJfQ1vayqf2fenKy/obUDKZxNKlS9HX1yfef9ddd+G+++7DAw88gD179qChoQGrVq1CKqWcbYmI6LRkXf8uu+wyXHbZZeJ9xhjce++9+OY3v4krrrgCAPCTn/wEbW1tePzxx/H5z38+8G/S6TTS6T+1UR4dHbWdEhERTUNlvQZ04MABDA4Ooru7uzDW3NyM5cuXY9euXeK/6e3tRXNzc+HW0dFRzikREVGVKmsBGhwcBAC0tbUVjbe1tRXuO97GjRsxMjJSuA0MDJRzSkREVKWct+KJx+OIx7XLj0REVKvKWoDa29sBAENDQ5g3b15hfGhoCOeee245H+rUkXrBKb3AtBVBo+Ny1iasrIqZFjI4Wm+39ia5j9vg6AxxfFJIwR2Tp4FYRH5MT0mH5ZSkWq4hOO432q2sWUkh5bkNaSk4gVHSYfC1/msl71qnvH+0nndGSV9JKbiwkmi0fe/nlJ5/uYSUbGsUt41FlRWI65V42IjwmVBScLbpuMiITSRN/sFa6xunru6r/Hwuba+ttKvt27Wy/gpu4cKFaG9vx44dOwpjo6Oj2LNnD7q6usr5UERENM1Z18Xx8XG88cYbhf8/cOAAXn75ZcyaNQudnZ1Yt24dvvOd72DRokVYuHAhbrnlFsyfP7/ob4WIiIisC9DevXvxyU9+svD/GzZsAACsWbMGjzzyCL7+9a8jmUziuuuuw/DwMC655BJs374diUQZ/pqKiIhqhnUB+sQnPgFj9L9iD4VCuP3223H77bdPaWJERFTbqvTSlCyutIYZEy72ZYX2PACQScuHnB+X231448HLZFrLHa21jhY2sFmASloYDwDG0vIVyomkPC4dZwpyKx7bi/NmhjIeD+5HC1Voxym1RDohKTyiBAL0fZd+iVTbh3bRXqUtgmexbV5tJCNvHxI+KtqFb20hPTXgEC89+ADIn8F8VH4d4sfkz7i0dWhC/nCarF04AUffFYcjmBnctzLvTJP2vrJbvFD6tGlhA+1co7W4slkwUXq/5ZVzXuBxSn8YIiKi8mEBIiIiJ1iAiIjICRYgIiJyggWIiIicmFYpOBvagmxayiqUlse9tLBYl9J2RGuDodEWptJaqUiSQmsdADAj8nhsuPTWQrkGZZG1FuVAhbQbAEQbgokirZ2P7ymtW5S3qnU6Tty5krwTc0ZAyCapVkXUxfuipR+PFo7S0lTae0tOzdkt4AbIf1soBfjU3Jmypp1RUnD5d4bFcWn/Xr38GYyk5HHb84cNvT1T6UlKm2RcqfgNiIiInGABIiIiJ1iAiIjICRYgIiJyggWIiIicqNoUXMqPwveLYztpX55uzCs9nmFScjouNi4nbWIjwfHIuLzvsLIoWU7sewWkW+X9ZBuD+9HmnVT6uBlPnou0b3X5Lcu0l5YO8/3Sf86x2faEhJSdUX7eUnvEKdsbm7SS9hxq6b1ypPoUYaW9WTloaTe1j5nwUfaVhvnpFu05kc8Hufr6wFisSU6eeZPyi+lNyE9WeEKOwEq95rzD74jbzpjIyPvONIvjo53ycUrnj6yw+OOJSClfjZp0FE5N+RM0rP5z/AZEREROsAAREZETLEBEROQECxARETnBAkRERE5UbQou43vIK6m3qdASTxEtBTccTHNElJVP1VUHlXRPpllbQTQ4rs0bSeVBlRScaahgw6kaoz7nFGDbJ0zqQaatnpqXA6Bqj7hcIvhzdaZRTsGFc3KDvEhK/tAmjslLxcYOBj9X/puHxW3Nm2+J4w04UxxPzZoljk+2BY/fV1YlDk8qqzgnlX6PieDro/USDAsp2lL7WfIbEBEROcECRERETrAAERGREyxARETkRNWGEJpiKURjxRfUUr58FSydCx6GrywyprU6sbmImlNCBb7SckfpsKEvECbQWuuolAXfbLhYeM3zlIXq1H9R+s9Q2gJzWsudclCDDLYteqqcFhSwEVLORtqrY5Q3hfw5lJ/vsOXznZkhf2ij9cGTQigmb2uyciseZOWAUGxcft/GRoJPuokoi/opr4/WukcMEVgsXpcvMevEb0BEROQECxARETnBAkRERE6wABERkRMsQERE5ETVpuBmxZKIxYsXhTqWbhC3PeoHx7WFzTylJUXIokONbdrNpuUOgKpJsIXKMA9ATrZ5Zdo3lNScxFcSQkZZSFBjLJJTtgm7SmbgpLRS2UQrl5g06lnK5niUNj/K515rq6X9zB5vDqbgIo3y+QrJpDgsLWoHAIljcmou0yjFcbXFL+XXJ9Nq2UNJIiR0Tb60zyW/ARERkRMsQERE5AQLEBEROcECRERETrAAERGRE1Wbgqvzcoh5xYmOhFe5xdS0pI2UeMsq4RYt7ea3yPOuZK+1ciTYtL5s1vsR5hKJlCF9Uyb2M5l6/zl9+wr2pavYnk/AJjFo0WsM0HvHSYlW2z5z2mNmGuXt07OCC9VFRmaK23qZrDiuiYykxfHEO8Fec7mE3PQt06z1JJTfn1M9N4W0Rn3H4TcgIiJyggWIiIicYAEiIiInWICIiMgJFiAiInKialNws6LjSESLUx6TyoqoEqOsiKqtfKqtGJgXEm+ZZjkhoqXdGlsnxPF0Sj4erY+dxDapVrYebAIt2Rb1guMxZdtMTn4hpH0AQNaf+lKc2nOirqorPOf6a2b5M55FOtCmJx1Q2YSdxmaGWvIsrKxmarciqkxLv2q9IX1ljqlZwfdhbKxe3DY20STvXFkRNTwi946riwYfM1cvR3Qn25TnNiE/ibF46Ylj6XOS90v79/wGRERETrAAERGREyxARETkBAsQERE5YVWAent7ceGFF2LGjBmYO3currzySuzbt69om1QqhZ6eHrS2tqKxsRGrV6/G0NBQWSdNRETTn1UKbufOnejp6cGFF16IXC6Hf/zHf8SnP/1pvP7662hoeC99sX79evznf/4ntm7diubmZqxduxZXXXUVfvOb30x5sslcsN8SICenrBNCyjMhrYzoz5BTU9EGucfTzPpJcfxtJfFlwzbVVskebFpSTUu8TXXbcskpr4NNOk5LI9oejZbelGj9utT3fgUTkLCYtwvq51vZ3vZocsLipJkZcso10iwn1bS0m5mQzx/hkeBBJY7FxG29tHzu1Ez5PFHie82qAG3fvr3o/x955BHMnTsX/f39+Mu//EuMjIzg4YcfxmOPPYaVK1cCADZv3oyzzjoLu3fvxsUXX2zzcEREVMOm9GPLyMgIAGDWrFkAgP7+fmSzWXR3dxe2Wbx4MTo7O7Fr1y5xH+l0GqOjo0U3IiKqfSddgPL5PNatW4cVK1bgnHPOAQAMDg4iFouhpaWlaNu2tjYMDg6K++nt7UVzc3Ph1tHRcbJTIiKiaeSkC1BPTw9effVVbNmyZUoT2LhxI0ZGRgq3gYGBKe2PiIimh5NqxbN27Vr88pe/xHPPPYczzjijMN7e3o5MJoPh4eGib0FDQ0Nob28X9xWPxxGPBy+QTfox5I9rvZPy5emK7VgsL4pKYQMAyDUEL6aZuHyBrrEhJY43xeXx8bh8wXASwfFyhQe0oIAN26BArAyPeboozzPlIBCQLsNyd7YL0indXqTWPXqbH5l2CV0LM2Qbg/vPNMl7jzXLgYDohLzwnBmXwwkhYWG7WL28by+ljCvhmYZ4JjBm0ybL90tbdM/qnWqMwdq1a7Ft2zY888wzWLhwYdH9y5YtQzQaxY4dOwpj+/btw8GDB9HV1WXzUEREVOOsvgH19PTgsccew89//nPMmDGjcF2nubkZdXV1aG5uxrXXXosNGzZg1qxZaGpqwo033oiuri4m4IiIqIhVAdq0aRMA4BOf+ETR+ObNm/F3f/d3AIB77rkH4XAYq1evRjqdxqpVq3D//feXZbJERFQ7rAqQMfLvaP9cIpFAX18f+vr6TnpSRERU+6r7z5eJiKhmVe2CdJP5GPx8cQpuJFMnbist7BbybVvxKAmcuuC4uohTmZJq5Ui8uUi7EZ1K6mdWSLxpi9rZpuNsZIRkHACkWpV2ORPyAnbhEbl1j5SOCylJOi8lH38uLZcALfFWbvwGRERETrAAERGREyxARETkBAsQERE5wQJEREROVG0K7limAdF0cVpkTFlUSUpyhCftUnB+XFncS+j7Fo/LTai05MhoWlitCpVNmZVj39XUwy0j9furMG2hOhs2i9oBem8uG5V81WwWzAMA473/3w6+H+2TrPVvhPDxNEprspDyEms937yUPBtpez8hb5tpVHrENcnpuES9nP6F0AsulJXPTRG5HSVMSn4CpP6aUn84jV/iuYPfgIiIyAkWICIicoIFiIiInGABIiIiJ1iAiIjIiapNwVVKXkm95IPt5AAAIaHflG2vNhcJLqJTSU27KSlAq31b/pwsZc/0nm/yvJXFlxHKWazOKodfT9AjTj4JRUebxHHprGKi8sTDOfk4I8PyuSnXGhyP1Zd+3ssxBUdERNWMBYiIiJxgASIiIidYgIiIyAkWICIicqJqU3ApPwL/uCiKzSp9WqpNS72YuJzWiQp932xXG02m5R5P2n6qpY9bPCL3lbKVzlXt28wZrUecC75f+s+hIW3eSuJL3d6CURJc+vZCysyTjzEfsVw5Oa2cP4T9aEk6TUpJ2MVa5Sc3kS39Mx5RVkRNvCM/LxNnBCdvcz7wStyW34CIiMgJFiAiInKCBYiIiJxgASIiIieq9upwwsshetyFw0ou4Ka1DJEuFtvOQ1rciaqf1nKpHAvVUensgwzBn6sN5H3YtvkpB19eV1NfwK5Jfr9FJoM78iaUBekm5OOPjMv7zisL1ZUbvwEREZETLEBEROQECxARETnBAkRERE6wABERkRNVm4Kr99KIHbcYnNZeRkrJaM07bBaeA+QklG2bm6TV1rWnXC19pqNKJub8XPX//Ggs5liOtj36vpUWOko6Dsq8tQUtQ2U4k/pKO6NUi5yOi0wET2Zy0y8gnJWPMzFc+vHHvdI/x2EuSEdERNWMBYiIiJxgASIiIidYgIiIyAkWICIicqJqU3AfSAwjkShOebwVbxG3HfSCSY7TN3dFdOqJi8BZK8/Pw1ZzsUwSGi1NJ4S+QpbPiW2PuFx9cO5hy8Ufw8qJMuSX4/Us4fFPyaMQEREdhwWIiIicYAEiIiInWICIiMgJFiAiInKialNwrZFx1EWKp5fwsuK20qqlOSWtEp6U0x2V60IFRJW+SBVd4bXGaP3k0papH4n2OmSUPm7S63m6rHqr9nYrQ186tS+bLZv+c5ZpL7WXpPD2DKsdKZV9Qzk3KW/xnJCOCyvHHs7Ic9H2LdHOvxKvxG35DYiIiJxgASIiIidYgIiIyAkWICIicsKqAG3atAlLlixBU1MTmpqa0NXVhSeffLJwfyqVQk9PD1pbW9HY2IjVq1djaGjopCY22xvHnMhY0a01nhRvkYgfuBHRqRPyQ+KNSmciRrz5cYi3XEK6heRbfVi85SMh8WY8E7hVglUBOuOMM3DnnXeiv78fe/fuxcqVK3HFFVfgtddeAwCsX78eTzzxBLZu3YqdO3fi0KFDuOqqqyoycSIimt6sMqyXX3550f9/97vfxaZNm7B7926cccYZePjhh/HYY49h5cqVAIDNmzfjrLPOwu7du3HxxReXb9ZERDTtnfQ1IN/3sWXLFiSTSXR1daG/vx/ZbBbd3d2FbRYvXozOzk7s2rVL3U86ncbo6GjRjYiIap91AXrllVfQ2NiIeDyO66+/Htu2bcPZZ5+NwcFBxGIxtLS0FG3f1taGwcFBdX+9vb1obm4u3Do6OqwPgoiIph/rAnTmmWfi5Zdfxp49e3DDDTdgzZo1eP311096Ahs3bsTIyEjhNjAwcNL7IiKi6cO6j0ksFsOHP/xhAMCyZcvwwgsv4Pvf/z6uvvpqZDIZDA8PF30LGhoaQnt7u7q/eDyOeDy4EtPsyBgaIsX1sTWaFPehtbo51bR2MRmlTUusgvPW5mK1D688y/ql/am3yylHy51Kqpb3YKVpR5nXUlJCmyxNSGmfZcumpY9Rfga3TfBJC9VprXVsGeWtn20sff+RlDyeS2j/IPgcJizOB16J207574Dy+TzS6TSWLVuGaDSKHTt2FO7bt28fDh48iK6urqk+DBER1RirHys3btyIyy67DJ2dnRgbG8Njjz2GZ599Fk899RSam5tx7bXXYsOGDZg1axaamppw4403oquriwk4IiIKsCpAR44cwd/+7d/i8OHDaG5uxpIlS/DUU0/hU5/6FADgnnvuQTgcxurVq5FOp7Fq1Srcf//9FZk4ERFNb1YF6OGHHz7h/YlEAn19fejr65vSpIiIqPaxFxwRETlRtdGi+lAGDaHi+ljvZcRtpQXFtN5F+Sj7UxFR5UnJOAAI5SwXwVPO0lI6Lh+R951LyHPxhUXtACCcODWpTn4DIiIiJ1iAiIjICRYgIiJyggWIiIicYAEiIiInqjYFN2FiCJnjUnBhJQUn9OEKN2bFbfOIiuNhi55Vtmx7vkm94yrZN06j9XDTesQlPPk5l/ZTrt5uWp+904G28m8uV7nnxPPkz0m+gp+fkLJvk1P6uFn0lNP6xqk94pT92PR9C8MuHRe2aMmo9o1T0m5+sA0nAPl1boikS55HRkksH4/fgIiIyAkWICIicoIFiIiInGABIiIiJ1iAiIjIiapNwdloigeX+3s7LkdH0kpyRkv3lIO2Omm1r/JJRCWySN5pvd3Ck9r2coItJJ1WlBVO80ow0le2jyeCidY6JeUqOWUrohIREZ0MFiAiInKCBYiIiJxgASIiIieq9ir4ZD6G0HFXzurDciuIlljw6t2cpnFx27fRaDWPqNACR2v/ooUNtNY1NrR9q9uX4TE1WosedfsKhi1sWhTZtu2RFjqstGwZWgvZtujxLNro+GVof1NpxmbBN+14fGUf2r6F49cWxdTk6+RxP6ftJzgXo3zsteCDH5f3XS98rrRWaBIvXFpggd+AiIjICRYgIiJyggWIiIicYAEiIiInWICIiMiJqk3BJfNxGK1/xHE6694JjKWUpJaWhMpUcBEvm4XabFUy7WarHMdDVPO0BfaU7wN+XelpOm2BOaOkFPPy+pxojAcTb/UlLjIHAOES2/bwGxARETnBAkRERE6wABERkRMsQERE5AQLEBEROVG1saUJE4XRGhgdZ3Y02Pdtoj4mbpvy5djH0YkGcVxKx6mJOSWBklCSakeUHmm2PcvEqVQwHVfRPnMO+saV4/k+XWh943y/cgs6TldaPzkt7ab2n1NIyTYt1aYtmGfi8mdCWuTTphdcOMwF6YiIqIqxABERkRMsQERE5AQLEBEROcECRERETlRtCu5YrgmJ4xJR2oqo0riUjAOAozF5RdTRdEIcr2SPuOlK621ng33jiKZGSryZuJxGDCXktFs0LqfVpM+4dv4VH48pOCIiqmYsQERE5AQLEBEROcECRERETlTtleBj2QbEs8VX2WZrbSYEWtuIhoh8IS0ekS+aVbJNi/aYU90W0C/y27TR0cIGWmshjdb+SGJ9nGVo3VNNLXqiylwkWcv5RSLyvnNlCNp43tRb8fi+/POwydn9nBxS2s6I+4bd4nB2zXLKRGuj4wXHtbBBvEE+H9YJC88B8md8Iq/0GhOkSlxMlN+AiIjICRYgIiJyggWIiIicYAEiIiInWICIiMiJKRWgO++8E6FQCOvWrSuMpVIp9PT0oLW1FY2NjVi9ejWGhoas9z2Zj2GixJuNOi8r3uJeTrxVkvaY8UjwRlTNvEhevNHUGc+It1DCD9wi8Zx4a26YFG+tDRPirSGSDtwq4aQL0AsvvIAf/ehHWLJkSdH4+vXr8cQTT2Dr1q3YuXMnDh06hKuuumrKEyUiotpyUgVofHwc11xzDR566CHMnDmzMD4yMoKHH34Y3/ve97By5UosW7YMmzdvxn//939j9+7dZZs0ERFNfydVgHp6evCZz3wG3d3dReP9/f3IZrNF44sXL0ZnZyd27dol7iudTmN0dLToRkREtc/6z8i3bNmCF198ES+88ELgvsHBQcRiMbS0tBSNt7W1YXBwUNxfb28vvv3tb9tOg4iIpjmrb0ADAwO46aab8NOf/hSJhLx+jq2NGzdiZGSkcBsYGCjLfomIqLpZfQPq7+/HkSNHcP755xfGfN/Hc889hx/+8Id46qmnkMlkMDw8XPQtaGhoCO3t7eI+4/E44vFgj6FJPwL/uB5iE+HSE2+zI2PyuOVCdeVYOC2l7KMcC7u5oB2PDduEodrbrgwJQa2fnNYjbrrSesdpPeIqybfs7yYxuQp2ZtMSfBb996RebSfat1E+VlpvO6m/m9bbbXZ9UhxviU2K463R4PaVWJDO6kxy6aWX4pVXXika+9KXvoTFixfjG9/4Bjo6OhCNRrFjxw6sXr0aALBv3z4cPHgQXV1dNg9FREQ1zqoAzZgxA+ecc07RWENDA1pbWwvj1157LTZs2IBZs2ahqakJN954I7q6unDxxReXb9ZERDTtlX05hnvuuQfhcBirV69GOp3GqlWrcP/995f7YYiIaJqbcgF69tlni/4/kUigr68PfX19U901ERHVMPaCIyIiJ6p2RdQJP45srjj1Vqekxuo9OfkhbquslDo7LqfjJMOZOnFcS2ppK4LqK44Gx21WFSU61WxWcgXKk4KrekraTUu1hZTttdVmpcRba8OEuO2HZ7wtjmupYO08WW6nwbuAiIiqEQsQERE5wQJEREROsAAREZETLEBERORE1abgbEiJDa1vkU0/I422OuCxdIM4PqKk5myovdAse6rZ9J9LKPsuRy84TTl6701nmVzpvcY0Ws+3SopZ9pPLRYJz9P0y/Txsk7CzXLXVpr9budJu2sqyjUIKrq1O7oHZGX9HHF8QOyqOJy1Xmj5eqb3g+A2IiIicYAEiIiInWICIiMgJFiAiInLitLvi26C1mIiMlryPo1l58bpkLriwHgCMKPs53S+40+lLWgQvk54GnweL9jq2YQP1IZWAh7QYo9ZSTAsbfDAqj7/tzwiMHckFx6aK34CIiMgJFiAiInKCBYiIiJxgASIiIidYgIiIyImqjZ3Ue2nElFYWx5uwaBvRYNuKxyIdZzMPQG9pU+2Lz2ktemxox2jbWqgcSUIpTQQA6VzVfjxOSFscrpItesrRQkhLh2lNfkwZHlNt22O5mFwkHnwPaS10tFSbpkFouQMAzbHJwJi2wNwc5Tw2R13MM9jSJ5mXU76SUKi0Y+Q3ICIicoIFiIiInGABIiIiJ1iAiIjICRYgIiJyYnrGfCrAJh03oWyrJVA0R9NyTzkbLhJz2oJ8mkouYEd0Kmn93eKJ4EKPWhrRdvG+GXH589YaTwbGZkfkBenmhCfE8fpQSBkPpvpszpGhMFNwRERUxViAiIjICRYgIiJyggWIiIicYAEiIiInqjaeVOflEPOKExr12mqmggmlb1EyX/o+NPVaCk55NrV5a6m5CT/YU+5YtkHcVluF1UXyrM4LJoGA8vSOo+pWyT5zFWXZ803rVycl3lob5OSZ1MMNkFNtANAalcc748cCYx9UVj5tCMvznlDabU6YU5Ou5TcgIiJyggWIiIicYAEiIiInWICIiMiJqg0hTJUeQrBrI9MgBAiksRPRQgsabe42qqn9jW3rHol2PAkl+GC37/IsjlctMkogwLYFjI1pG0IoE+m51cIGH2k8Io5LoQIAmKO11xEWmbNtuTNhSlv0s1L4DYiIiJxgASIiIidYgIiIyAkWICIicoIFiIiInKieqBSdUL0nJ+8m8sG2PYDe1oOoEnK5KkrBKe11JFrLnUhcTkA2NqTE8dn1wc+b9hnUPssuJPOlfwexSfMapfXP8fgNiIiInGABIiIiJ1iAiIjICRYgIiJyggWIiIicsErBfetb38K3v/3torEzzzwT//u//wsASKVS+NrXvoYtW7YgnU5j1apVuP/++9HW1mY9sbpwBvFwcUKlHOkRrc+alvBIKikzm31rtMeUxuvD8r7VRe3Cpc/blpa8c0Hr43aqpZVedencqQ+axoTF0QC9R5yNjJJ2y6Tl49QWcLOh7cNESv/5OaQk47R9xxNyj0FtkbkP1A8HxjoS74rbzlZ6u2m0c9AcYaySC881hEo//5pQhVJwH/3oR3H48OHC7de//nXhvvXr1+OJJ57A1q1bsXPnThw6dAhXXXWV7UMQEdFpwPrHs0gkgvb29sD4yMgIHn74YTz22GNYuXIlAGDz5s0466yzsHv3blx88cXi/tLpNNLpP/3EPzoa7PBKRES1x/ob0P79+zF//nx86EMfwjXXXIODBw8CAPr7+5HNZtHd3V3YdvHixejs7MSuXbvU/fX29qK5ublw6+joOInDICKi6caqAC1fvhyPPPIItm/fjk2bNuHAgQP4+Mc/jrGxMQwODiIWi6GlpaXo37S1tWFwcFDd58aNGzEyMlK4DQwMnNSBEBHR9GL1K7jLLrus8N9LlizB8uXLsWDBAvzsZz9DXV3dSU0gHo8jHp/6AmxERDS9TCmi09LSgo985CN444038KlPfQqZTAbDw8NF34KGhobEa0ZUWWrvOL86EmzaKqnJHH8YmY5MTv5lirYGaznScVqyzebxPGUfUSVJ2FYnJ9ikxFtn7Ki4rbaispZ2s12BuRySZmrniQlzCnrBjY+P4/e//z3mzZuHZcuWIRqNYseOHYX79+3bh4MHD6Krq2sqD0NERDXI6hvQP/zDP+Dyyy/HggULcOjQIdx2223wPA9f+MIX0NzcjGuvvRYbNmzArFmz0NTUhBtvvBFdXV1qAo6IiE5fVgXozTffxBe+8AUcO3YMc+bMwSWXXILdu3djzpz3/iTqnnvuQTgcxurVq4v+EJWIiOh4VgVoy5YtJ7w/kUigr68PfX19U5oUERHVPvaCIyIiJ6p2RdQ6L4OEd1wvuAqmQWz7uFVqHxqb1QipelSyF5xtbzetj5uNrPKYJhdS/kXp6TjbZJzN9lraLRKR024xZbyz7h1x/KzEocDYnIhlV5dckzjcoHz2bXqz1Yfk16c+JK/8+rY/IzCWtDi/TeS0/GMxfgMiIiInWICIiMgJFiAiInKCBYiIiJyo2hBCtbAJFpRrobZyBA60ubhoxSOFR7T51XnyQmDlkFIWjaNTTwoQaEEBja+0/6kkrcWVFDiwCQkAwNsnNaNTpxKtgvgNiIiInGABIiIiJ1iAiIjICRYgIiJyggWIiIicmFaxIJuUmda2x7Zdjs1jukiYafM7mm0Uxyf96JQfszWaFMe1hNDpbBQJcdy2jY64D8vWOlobHRs55TFDEaOMl74QnNYWxwXtuZ0dkRekmxOeCIw1hOVjT+bln/u1ljsuSG13bM6dk0Zu8XM8fgMiIiInWICIiMgJFiAiInKCBYiIiJxgASIiIieqNgU36ceQL0Nia6pskm3l6gVnMw/tMd+caBHHUxbPaULpy6am4MqwYKB2nJVcjFCTzFVugcFqoiXbbKhpN2XROCnxFvXsUnA289b6xmnjuYi876O54EJtAPB2vj4wNmHs3rM2C74Bcs/I+rySPlMSeROm9POB1qNS6gUXCnFBOiIiqmIsQERE5AQLEBEROcECRERETrAAERGRE1WbgnsnW49Y9uRTZeVKpNn0TrNNTTVE5FSJNHdtHsfSDeL4kQk5rTOeDu47pvTgml0vp900s4VVITVHc01W+9bY9J+bCNslCadrCk7r+aalxsqxsmgsLqevtP5uUuJNex9qsr68fToV/Kz4fnl+1tbTqMJ7RXlIrafa20rCTk2fSf3atFVYlXRc0mirnJbel07aNhRmCo6IiKoYCxARETnBAkRERE6wABERkRMsQERE5ET1puAyDYgKia1SJbzSVuR7Pym/9KfIps/aifYtzX04UyduO5qWV9x8d0LeXkoISatTAkDMsjeX1BMKAJJlWMlW315LEk49waalFG3ScfGI3fuwHCulumCTdgPsE29TZZSkn8mFxPE85Nfhd+NzxfHZ0fHAmPbe1Gh95urDU38va3N5W0mjSok87TMl7XsyyxVRiYioirEAERGREyxARETkBAsQERE5UbUhhENjzfCmcCFZu4Bue1HYRjpn93SmI/L2I8LYWFp+LpJKUGMiKW+fTwUvruYiRtx2PG7XusamfceEsq3thVs9+BDcj3YRdaIMF3m1QEm8TGGYamcbNrAJuNgGM6S2O0Z43wNAyJdDCJo3x1rE8Re9zsCYFmKpUxZ6PJpuFMe1/RyNBrc/KoQhAP1zpQUfBlIzA2Na+EaaX2a8tDARvwEREZETLEBEROQECxARETnBAkRERE6wABERkRNVm4J7d7Qe4ZzcZqYUWnsZrWWIC1pySKItMia11gHktBsAhNLBcQN5Htpj2izSZ0tLtWkJOy3dM0cY09uOaLORU0kS29ZPCSUJlfLk5zZt0RLKBe29orFt83TKKS163hmRF4B8QxibEZffm1oyUmurpSV33/JaAmMtsUlxWy1JZ7OgpbSYJSAnHf1kaWlWfgMiIiInWICIiMgJFiAiInKCBYiIiJywLkBvvfUWvvjFL6K1tRV1dXX42Mc+hr179xbuN8bg1ltvxbx581BXV4fu7m7s37+/rJMmIqLpzypa8+6772LFihX45Cc/iSeffBJz5szB/v37MXPmn/oG3XXXXbjvvvvw6KOPYuHChbjllluwatUqvP7660gkSk+15d5NIJwq3t54cs8ySVZJwYWUvmchZXsb2qJXGpvH9Dx5W6nvFQBAm4uU7vHkbXM5Odmk9YRKWvTu09JrWtptjjcm7ydkkT5T3u3agnn1npzIO5YNJoe0lJE2rtGeW6nXnG1iLu3J4za91jLKe2LScvFI6TFtk3Ha+1P6HKo935S0W1gOKSI7Ir8+R9LB53akQX7/aElcLdFqk+g9GpdTbZqRpLJwZTL4emr99CT5yVRJ21kVoH/6p39CR0cHNm/eXBhbuHBh4b+NMbj33nvxzW9+E1dccQUA4Cc/+Qna2trw+OOP4/Of/7zNwxERUQ2z+pH9F7/4BS644AJ87nOfw9y5c3HeeefhoYceKtx/4MABDA4Ooru7uzDW3NyM5cuXY9euXeI+0+k0RkdHi25ERFT7rArQH/7wB2zatAmLFi3CU089hRtuuAFf/epX8eijjwIABgcHAQBtbW1F/66tra1w3/F6e3vR3NxcuHV0dJzMcRAR0TRjVYDy+TzOP/983HHHHTjvvPNw3XXX4ctf/jIeeOCBk57Axo0bMTIyUrgNDAyc9L6IiGj6sCpA8+bNw9lnn100dtZZZ+HgwYMAgPb2dgDA0NBQ0TZDQ0OF+44Xj8fR1NRUdCMiotpnFUJYsWIF9u3bVzT2u9/9DgsWLADwXiChvb0dO3bswLnnngsAGB0dxZ49e3DDDTdYTSw6EkY4XVwf8xbtpkxErq15pY2ZUdJxNsk7WyZS+mqM2vGcLrS02xyr12dCHo3ICbuDmdkW+5a1RpNW22urZUr992wSc0B5+sxpSTrbFNx05Y0r55V0cDylJOy0JK5RtlcCeeJ+0nH5Nc4JKT0AQFIeD08G5xJS5ifRelEez6oArV+/Hn/xF3+BO+64A3/zN3+D559/Hg8++CAefPDB9yYYCmHdunX4zne+g0WLFhVi2PPnz8eVV15p81BERFTjrArQhRdeiG3btmHjxo24/fbbsXDhQtx777245pprCtt8/etfRzKZxHXXXYfh4WFccskl2L59u9XfABERUe2z7vH+2c9+Fp/97GfV+0OhEG6//XbcfvvtU5oYERHVttP7wgIRETlTtatceckQvOMuehmL2eaVC/xa2CDv2W1fDvmoXP9NPNh6w2DqrYIAANLxWC7ep7WX0Vra2NBb9MhzrA+V/pjaYnfaY9Yr29vQ2vmcLrR2ORlv6u1/XIgklc+s8LnKaqdXrR2YxUV+bT9ZdSFKed7RcSUoIcwlbNH1yk+Xdiz8BkRERE6wABERkRMsQERE5AQLEBEROcECRERETlRtCi7sv3f7czY5MK2y5qEsQAUlHadsXw7qYwoJPqMdURkW0qtF9eFgOq7eaE1NKjkPOQU3YZkYLEciT2vRQ6XTkmDSeSKctTunaIvgqbLB/eSj8r49obUOAHgpLQVnOZeT/Pf8BkRERE6wABERkRMsQERE5AQLEBEROVF1VyWNee/CnZ9OBe6zWg9I7iKDvHZxTG3RU/pj2lLbAgnhBHVdIi2EkJN/tgj5QsAhLz9Z/oTcoiYzLl8Qn7Tp1aFIRuXjGVOOM6a06MkJ42O+vG0yK4+nJuXjyUyUHghIKW+4VF6++JsWXh9NRtlHxpffK9mMvFZMVtlekvO190rw83oivh+84u57yr59+UPop+XXLT8pjE8qpzqt/Y3yVvaVljbSy5z3lPlpH5Opf3zUfYeUsIHWMmeqIYQ/nr//eD7XhMz7bXGKvfnmm+jo6HA9DSIimqKBgQGcccYZ6v1VV4Dy+TwOHTqEGTNmYGxsDB0dHRgYGKjppbpHR0d5nDXidDhGgMdZa8p9nMYYjI2NYf78+QiH9Ss9VfcruHA4XKiYodB7Xw+bmppq+sX/Ix5n7TgdjhHgcdaach5nc3Pz+27DEAIRETnBAkRERE5UdQGKx+O47bbbEI/HXU+lonicteN0OEaAx1lrXB1n1YUQiIjo9FDV34CIiKh2sQAREZETLEBEROQECxARETnBAkRERE5UdQHq6+vDBz/4QSQSCSxfvhzPP/+86ylNyXPPPYfLL78c8+fPRygUwuOPP150vzEGt956K+bNm4e6ujp0d3dj//79biZ7knp7e3HhhRdixowZmDt3Lq688krs27evaJtUKoWenh60traisbERq1evxtDQkKMZn5xNmzZhyZIlhb8c7+rqwpNPPlm4vxaO8Xh33nknQqEQ1q1bVxirheP81re+hVAoVHRbvHhx4f5aOMY/euutt/DFL34Rra2tqKurw8c+9jHs3bu3cP+pPgdVbQH693//d2zYsAG33XYbXnzxRSxduhSrVq3CkSNHXE/tpCWTSSxduhR9fX3i/XfddRfuu+8+PPDAA9izZw8aGhqwatUqpFJ2nYZd2rlzJ3p6erB79248/fTTyGaz+PSnP41kMlnYZv369XjiiSewdetW7Ny5E4cOHcJVV13lcNb2zjjjDNx5553o7+/H3r17sXLlSlxxxRV47bXXANTGMf65F154AT/60Y+wZMmSovFaOc6PfvSjOHz4cOH261//unBfrRzju+++ixUrViAajeLJJ5/E66+/jn/+53/GzJkzC9uc8nOQqVIXXXSR6enpKfy/7/tm/vz5pre31+GsygeA2bZtW+H/8/m8aW9vN3fffXdhbHh42MTjcfNv//ZvDmZYHkeOHDEAzM6dO40x7x1TNBo1W7duLWzzP//zPwaA2bVrl6tplsXMmTPNv/zLv9TcMY6NjZlFixaZp59+2vzVX/2Vuemmm4wxtfNa3nbbbWbp0qXifbVyjMYY841vfMNccskl6v0uzkFV+Q0ok8mgv78f3d3dhbFwOIzu7m7s2rXL4cwq58CBAxgcHCw65ubmZixfvnxaH/PIyAgAYNasWQCA/v5+ZLPZouNcvHgxOjs7p+1x+r6PLVu2IJlMoqurq+aOsaenB5/5zGeKjgeorddy//79mD9/Pj70oQ/hmmuuwcGDBwHU1jH+4he/wAUXXIDPfe5zmDt3Ls477zw89NBDhftdnIOqsgAdPXoUvu+jra2taLytrQ2Dg4OOZlVZfzyuWjrmfD6PdevWYcWKFTjnnHMAvHecsVgMLS0tRdtOx+N85ZVX0NjYiHg8juuvvx7btm3D2WefXVPHuGXLFrz44ovo7e0N3Fcrx7l8+XI88sgj2L59OzZt2oQDBw7g4x//OMbGxmrmGAHgD3/4AzZt2oRFixbhqaeewg033ICvfvWrePTRRwG4OQdV3XIMVDt6enrw6quvFv0+vZaceeaZePnllzEyMoL/+I//wJo1a7Bz507X0yqbgYEB3HTTTXj66aeRSCRcT6diLrvsssJ/L1myBMuXL8eCBQvws5/9DHV1dQ5nVl75fB4XXHAB7rjjDgDAeeedh1dffRUPPPAA1qxZ42ROVfkNaPbs2fA8L5A0GRoaQnt7u6NZVdYfj6tWjnnt2rX45S9/iV/96ldFKyK2t7cjk8lgeHi4aPvpeJyxWAwf/vCHsWzZMvT29mLp0qX4/ve/XzPH2N/fjyNHjuD8889HJBJBJBLBzp07cd999yESiaCtra0mjvN4LS0t+MhHPoI33nijZl5LAJg3bx7OPvvsorGzzjqr8OtGF+egqixAsVgMy5Ytw44dOwpj+XweO3bsQFdXl8OZVc7ChQvR3t5edMyjo6PYs2fPtDpmYwzWrl2Lbdu24ZlnnsHChQuL7l+2bBmi0WjRce7btw8HDx6cVscpyefzSKfTNXOMl156KV555RW8/PLLhdsFF1yAa665pvDftXCcxxsfH8fvf/97zJs3r2ZeSwBYsWJF4E8ifve732HBggUAHJ2DKhJtKIMtW7aYeDxuHnnkEfP666+b6667zrS0tJjBwUHXUztpY2Nj5qWXXjIvvfSSAWC+973vmZdeesn83//9nzHGmDvvvNO0tLSYn//85+a3v/2tueKKK8zChQvN5OSk45mX7oYbbjDNzc3m2WefNYcPHy7cJiYmCttcf/31prOz0zzzzDNm7969pqury3R1dTmctb2bb77Z7Ny50xw4cMD89re/NTfffLMJhULmv/7rv4wxtXGMkj9PwRlTG8f5ta99zTz77LPmwIED5je/+Y3p7u42s2fPNkeOHDHG1MYxGmPM888/byKRiPnud79r9u/fb37605+a+vp686//+q+FbU71OahqC5AxxvzgBz8wnZ2dJhaLmYsuusjs3r3b9ZSm5Fe/+pUBELitWbPGGPNeDPKWW24xbW1tJh6Pm0svvdTs27fP7aQtSccHwGzevLmwzeTkpPnKV75iZs6caerr681f//Vfm8OHD7ub9En4+7//e7NgwQITi8XMnDlzzKWXXlooPsbUxjFKji9AtXCcV199tZk3b56JxWLmAx/4gLn66qvNG2+8Ubi/Fo7xj5544glzzjnnmHg8bhYvXmwefPDBovtP9TmI6wEREZETVXkNiIiIah8LEBEROcECRERETrAAERGREyxARETkBAsQERE5wQJEREROsAAREZETLEBEROQECxARETnBAkRERE78f/AfD+9RfL+rAAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"### Unet Encoder","metadata":{}},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ConvBlock, self).__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:03:07.235678Z","iopub.execute_input":"2024-01-14T23:03:07.236149Z","iopub.status.idle":"2024-01-14T23:03:07.242674Z","shell.execute_reply.started":"2024-01-14T23:03:07.236110Z","shell.execute_reply":"2024-01-14T23:03:07.241638Z"},"trusted":true},"execution_count":445,"outputs":[]},{"cell_type":"code","source":"class Down(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(Down, self).__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            ConvBlock(in_channels, out_channels)\n        )\n\n    def forward(self, x):\n        return self.maxpool_conv(x)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:03:08.845460Z","iopub.execute_input":"2024-01-14T23:03:08.845837Z","iopub.status.idle":"2024-01-14T23:03:08.851896Z","shell.execute_reply.started":"2024-01-14T23:03:08.845798Z","shell.execute_reply":"2024-01-14T23:03:08.850918Z"},"trusted":true},"execution_count":446,"outputs":[]},{"cell_type":"code","source":"class UNetEncoder(nn.Module):\n    def __init__(self, n_classes):\n        super(UNetEncoder, self).__init__()\n\n        self.conv_down1 = ConvBlock(1, 16)\n        self.conv_down2 = Down(16, 24)\n        self.conv_down3 = Down(24, 32)\n\n    def forward(self, x):\n        x = self.conv_down1(x)\n        x = self.conv_down2(x)\n        x = self.conv_down3(x)  # Включаем дополнительный слой в прямой проход\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:15:49.857805Z","iopub.execute_input":"2024-01-14T23:15:49.858760Z","iopub.status.idle":"2024-01-14T23:15:49.864980Z","shell.execute_reply.started":"2024-01-14T23:15:49.858724Z","shell.execute_reply":"2024-01-14T23:15:49.864051Z"},"trusted":true},"execution_count":471,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self):\n        super(Decoder, self).__init__()\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(32, 16, 2, stride=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(inplace=True),\n\n            nn.ConvTranspose2d(16, 1, 2, stride=2),\n            nn.BatchNorm2d(1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.decoder(x)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:15:52.622505Z","iopub.execute_input":"2024-01-14T23:15:52.622867Z","iopub.status.idle":"2024-01-14T23:15:52.629872Z","shell.execute_reply.started":"2024-01-14T23:15:52.622840Z","shell.execute_reply":"2024-01-14T23:15:52.628821Z"},"trusted":true},"execution_count":472,"outputs":[]},{"cell_type":"code","source":"encoder = UNetEncoder(n_classes = 1)\ndecoder = Decoder()\nz = encoder(images)\nprint(z.shape)\nout = decoder(z)\nprint(out.shape)\nassert out.shape == images.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:15:56.318745Z","iopub.execute_input":"2024-01-14T23:15:56.319127Z","iopub.status.idle":"2024-01-14T23:15:56.916723Z","shell.execute_reply.started":"2024-01-14T23:15:56.319094Z","shell.execute_reply":"2024-01-14T23:15:56.915791Z"},"trusted":true},"execution_count":473,"outputs":[{"name":"stdout","text":"torch.Size([256, 32, 16, 16])\ntorch.Size([256, 1, 64, 64])\n","output_type":"stream"}]},{"cell_type":"code","source":"class Autoencoder(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Autoencoder, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:16:01.120347Z","iopub.execute_input":"2024-01-14T23:16:01.120735Z","iopub.status.idle":"2024-01-14T23:16:01.126669Z","shell.execute_reply.started":"2024-01-14T23:16:01.120702Z","shell.execute_reply":"2024-01-14T23:16:01.125584Z"},"trusted":true},"execution_count":474,"outputs":[]},{"cell_type":"markdown","source":"# Training loop","metadata":{}},{"cell_type":"code","source":"class CalculateThresholdCallback(Callback):\n    def __init__(self, every_n_epochs, val_loader, proliv_loader):\n        self.every_n_epochs = every_n_epochs\n        self.val_loader = val_loader\n        self.proliv_loader = proliv_loader\n        \n    def on_train_epoch_end(self, trainer, pl_module):\n        if not trainer.current_epoch % self.every_n_epochs == 0:\n            return\n\n        mse_normal = self.calculate_mse_for_loader(pl_module.model, self.val_loader, pl_module.device)\n        mse_anomaly = self.calculate_mse_for_loader(pl_module.model, self.proliv_loader, pl_module.device)\n\n        labels = np.array([0] * len(mse_normal) + [1] * len(mse_anomaly))\n        mse_values = np.concatenate([mse_normal, mse_anomaly])\n        fpr, tpr, thresholds = roc_curve(labels, mse_values)\n        roc_auc = auc(fpr, tpr)\n        optimal_idx = np.argmax(tpr - fpr)\n        optimal_threshold = thresholds[optimal_idx]\n        pl_module.log('roc_auc', roc_auc)\n        pl_module.log('opt_thresh', optimal_threshold)\n        pl_module.optimal_threshold = optimal_threshold\n\n    @staticmethod\n    def calculate_mse_for_loader(model, loader, device):\n        mse_values = []\n        model.eval()\n        with torch.no_grad():\n            for images in loader:\n                images = images.to(device)\n                outputs = model(images)\n                mse = F.huber_loss(outputs, images, reduction='none').mean([1, 2, 3])\n                mse_values.extend(mse.detach().cpu().numpy())\n        model.train()\n        return np.array(mse_values)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:16:02.359173Z","iopub.execute_input":"2024-01-14T23:16:02.360033Z","iopub.status.idle":"2024-01-14T23:16:02.370503Z","shell.execute_reply.started":"2024-01-14T23:16:02.359999Z","shell.execute_reply":"2024-01-14T23:16:02.369461Z"},"trusted":true},"execution_count":475,"outputs":[]},{"cell_type":"code","source":"class TestAnomalyCallback(Callback):\n    def __init__(self, every_n_epochs, test_loader):\n        self.every_n_epochs = every_n_epochs\n        self.test_loader = test_loader\n\n    def on_train_epoch_end(self, trainer, pl_module):\n        if not trainer.current_epoch % self.every_n_epochs == 0:\n            return\n\n        \n\n        all_labels = []\n        all_preds = []\n        pl_module.model.eval()\n        for images, labels in self.test_loader:\n            with torch.no_grad():\n                images = images.to(pl_module.device)\n            outputs = pl_module(images)\n            mse = F.huber_loss(outputs, images, reduction='none').mean([1, 2, 3])\n            preds = mse > pl_module.optimal_threshold\n\n            all_labels.extend(labels.detach().cpu().numpy())\n            all_preds.extend(preds.detach().cpu().numpy())\n\n        pl_module.model.train()\n        tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n        tpr = tp / (tp + fn)\n        tnr = tn / (tn + fp)\n\n        pl_module.log('metrics/tpr', tpr)\n        pl_module.log('metrics/tnr', tnr)\n        pl_module.log('metrics/mean', (tpr+tnr)/2)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:16:03.119885Z","iopub.execute_input":"2024-01-14T23:16:03.120642Z","iopub.status.idle":"2024-01-14T23:16:03.130094Z","shell.execute_reply.started":"2024-01-14T23:16:03.120609Z","shell.execute_reply":"2024-01-14T23:16:03.129027Z"},"trusted":true},"execution_count":476,"outputs":[]},{"cell_type":"code","source":"class LModule(L.LightningModule):\n    def __init__(self, model: nn.Module):\n        super(LModule, self).__init__()\n        self.model = model\n        self.loss = nn.HuberLoss() \n        self.optimal_threshold = 0\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, images, batch_idx):\n        outputs = self.model(images)\n        loss = self.loss(outputs, images)\n        self.log('loss/train', loss)\n        return loss\n\n    def validation_step(self, images, batch_idx):\n        outputs = self.model(images)\n        loss = self.loss(outputs, images)\n        \n        self.log('loss/val', loss)\n\n    def configure_optimizers(self):\n        return torch.optim.AdamW(self.parameters(), lr=3e-5)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:16:03.903727Z","iopub.execute_input":"2024-01-14T23:16:03.904497Z","iopub.status.idle":"2024-01-14T23:16:03.912320Z","shell.execute_reply.started":"2024-01-14T23:16:03.904465Z","shell.execute_reply":"2024-01-14T23:16:03.911298Z"},"trusted":true},"execution_count":477,"outputs":[]},{"cell_type":"code","source":"every_n_epochs = 5","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:16:05.093458Z","iopub.execute_input":"2024-01-14T23:16:05.093840Z","iopub.status.idle":"2024-01-14T23:16:05.098608Z","shell.execute_reply.started":"2024-01-14T23:16:05.093801Z","shell.execute_reply":"2024-01-14T23:16:05.097474Z"},"trusted":true},"execution_count":478,"outputs":[]},{"cell_type":"code","source":"eval_callback = CalculateThresholdCallback(every_n_epochs=every_n_epochs, val_loader=val_loader, proliv_loader=proliv_loader)\ntest_callback = TestAnomalyCallback(every_n_epochs=every_n_epochs, test_loader=test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:16:05.322306Z","iopub.execute_input":"2024-01-14T23:16:05.322903Z","iopub.status.idle":"2024-01-14T23:16:05.328336Z","shell.execute_reply.started":"2024-01-14T23:16:05.322870Z","shell.execute_reply":"2024-01-14T23:16:05.327444Z"},"trusted":true},"execution_count":479,"outputs":[]},{"cell_type":"code","source":"callbacks = [eval_callback, test_callback]","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:16:06.015098Z","iopub.execute_input":"2024-01-14T23:16:06.015460Z","iopub.status.idle":"2024-01-14T23:16:06.020359Z","shell.execute_reply.started":"2024-01-14T23:16:06.015433Z","shell.execute_reply":"2024-01-14T23:16:06.019432Z"},"trusted":true},"execution_count":480,"outputs":[]},{"cell_type":"code","source":"max_epochs = 10\nlog_every_n_steps = 10","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:16:06.270895Z","iopub.execute_input":"2024-01-14T23:16:06.271172Z","iopub.status.idle":"2024-01-14T23:16:06.275327Z","shell.execute_reply.started":"2024-01-14T23:16:06.271147Z","shell.execute_reply":"2024-01-14T23:16:06.274297Z"},"trusted":true},"execution_count":481,"outputs":[]},{"cell_type":"code","source":"model = Autoencoder(GatedEncoder(), Decoder())","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:16:07.125611Z","iopub.execute_input":"2024-01-14T23:16:07.126376Z","iopub.status.idle":"2024-01-14T23:16:07.134165Z","shell.execute_reply.started":"2024-01-14T23:16:07.126340Z","shell.execute_reply":"2024-01-14T23:16:07.133289Z"},"trusted":true},"execution_count":482,"outputs":[]},{"cell_type":"code","source":"module = LModule(model)\ntrainer = L.Trainer(\n    callbacks=callbacks,\n    max_epochs=max_epochs,\n    log_every_n_steps=log_every_n_steps,\n    logger=TensorBoardLogger('../logs_hw2', f'gated_huber_loss'),\n)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-14T23:16:08.191181Z","iopub.execute_input":"2024-01-14T23:16:08.192107Z","iopub.status.idle":"2024-01-14T23:16:08.251853Z","shell.execute_reply.started":"2024-01-14T23:16:08.192071Z","shell.execute_reply":"2024-01-14T23:16:08.250831Z"},"trusted":true},"execution_count":483,"outputs":[{"name":"stderr","text":"INFO: GPU available: True (cuda), used: True\nINFO: TPU available: False, using: 0 TPU cores\nINFO: IPU available: False, using: 0 IPUs\nINFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntrainer.fit(module, train_loader, val_dataloaders=val_loader)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-14T23:16:09.927956Z","iopub.execute_input":"2024-01-14T23:16:09.928338Z","iopub.status.idle":"2024-01-14T23:17:12.316596Z","shell.execute_reply.started":"2024-01-14T23:16:09.928301Z","shell.execute_reply":"2024-01-14T23:17:12.315501Z"},"trusted":true},"execution_count":484,"outputs":[{"name":"stderr","text":"INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\nINFO: \n  | Name  | Type        | Params\n--------------------------------------\n0 | model | Autoencoder | 11.9 K\n1 | loss  | HuberLoss   | 0     \n--------------------------------------\n11.9 K    Trainable params\n0         Non-trainable params\n11.9 K    Total params\n0.047     Total estimated model params size (MB)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b97af2f72ac44a7e817762e871626c46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"beab3d9fcb5540588f1b733758047158"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1e7a65f724498bb7f0e3e531cc40bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d784c2e1d5843569b33391a166f33a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1541a0aaab5745068b4ae121b683d2bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fbf08a21b7042e3b4fbc779129dd372"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a5e755bd0a145e8a01d891bc817bfa6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77fa46659fc54fd681aadb41d9b38881"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d5b389911164aa88ef44687baf44fb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"606bdf90d5a34d52ad107aadc19dd21f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9179889d3bfb4009a8beb67e6693d465"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c49d5e092eb4babadb714a1bb5e73a3"}},"metadata":{}},{"name":"stderr","text":"INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 5.65 s, sys: 5 s, total: 10.6 s\nWall time: 1min 2s\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python.summary.summary_iterator import summary_iterator\ndef print_tensorboard_log(log_file):\n    for e in summary_iterator(log_file):\n        for v in e.summary.value:\n            if v.HasField('simple_value'):\n                print(f\"Step: {e.step}, {v.tag}: {v.simple_value}\")\nlog_file_path = '/kaggle/working/lightning_logs/version_7/events.out.tfevents.1705272153.c53641067ef8.26.7'\nprint_tensorboard_log(log_file_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:18:56.153221Z","iopub.execute_input":"2024-01-14T23:18:56.154276Z","iopub.status.idle":"2024-01-14T23:18:56.224280Z","shell.execute_reply.started":"2024-01-14T23:18:56.154235Z","shell.execute_reply":"2024-01-14T23:18:56.223325Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":485,"outputs":[{"name":"stdout","text":"Step: 0, loss/train: 0.020700223743915558\nStep: 0, epoch: 0.0\nStep: 1, loss/train: 0.020637942478060722\nStep: 1, epoch: 0.0\nStep: 2, loss/train: 0.020373236387968063\nStep: 2, epoch: 0.0\nStep: 3, loss/train: 0.020430758595466614\nStep: 3, epoch: 0.0\nStep: 4, loss/train: 0.020067501813173294\nStep: 4, epoch: 0.0\nStep: 5, loss/train: 0.020075928419828415\nStep: 5, epoch: 0.0\nStep: 6, loss/train: 0.019894562661647797\nStep: 6, epoch: 0.0\nStep: 7, loss/train: 0.019694682210683823\nStep: 7, epoch: 0.0\nStep: 8, loss/train: 0.019585274159908295\nStep: 8, epoch: 0.0\nStep: 9, loss/train: 0.019232146441936493\nStep: 9, epoch: 0.0\nStep: 10, loss/train: 0.019417688250541687\nStep: 10, epoch: 0.0\nStep: 11, loss/train: 0.01899321936070919\nStep: 11, epoch: 0.0\nStep: 12, loss/train: 0.01908491924405098\nStep: 12, epoch: 0.0\nStep: 13, loss/train: 0.01895618624985218\nStep: 13, epoch: 0.0\nStep: 14, loss/train: 0.018757030367851257\nStep: 14, epoch: 0.0\nStep: 15, loss/train: 0.01866263337433338\nStep: 15, epoch: 0.0\nStep: 16, loss/train: 0.018238957971334457\nStep: 16, epoch: 0.0\nStep: 17, loss/train: 0.018400749191641808\nStep: 17, epoch: 0.0\nStep: 18, loss/train: 0.01819998398423195\nStep: 18, epoch: 0.0\nStep: 19, loss/train: 0.017976565286517143\nStep: 19, epoch: 0.0\nStep: 20, loss/train: 0.017772763967514038\nStep: 20, epoch: 0.0\nStep: 21, loss/train: 0.017627663910388947\nStep: 21, epoch: 0.0\nStep: 22, loss/train: 0.0178369227796793\nStep: 22, epoch: 0.0\nStep: 23, loss/train: 0.01743859052658081\nStep: 23, epoch: 0.0\nStep: 24, loss/train: 0.017305154353380203\nStep: 24, epoch: 0.0\nStep: 25, loss/train: 0.017207052558660507\nStep: 25, epoch: 0.0\nStep: 26, loss/train: 0.01709139160811901\nStep: 26, epoch: 0.0\nStep: 27, loss/train: 0.017008263617753983\nStep: 27, epoch: 0.0\nStep: 28, loss/train: 0.016854025423526764\nStep: 28, epoch: 0.0\nStep: 29, loss/train: 0.01668776571750641\nStep: 29, epoch: 0.0\nStep: 30, loss/train: 0.01660202629864216\nStep: 30, epoch: 0.0\nStep: 31, loss/train: 0.016368648037314415\nStep: 31, epoch: 0.0\nStep: 32, loss/train: 0.016313884407281876\nStep: 32, epoch: 0.0\nStep: 33, loss/train: 0.016105182468891144\nStep: 33, epoch: 0.0\nStep: 34, loss/train: 0.016077667474746704\nStep: 34, epoch: 0.0\nStep: 35, loss/train: 0.01624685525894165\nStep: 35, epoch: 0.0\nStep: 35, loss/val: 0.002694907132536173\nStep: 35, epoch: 0.0\nStep: 35, roc_auc: 0.9469350576400757\nStep: 35, opt_thresh: 0.0037735537625849247\nStep: 35, metrics/tpr: 0.9922480583190918\nStep: 35, metrics/tnr: 0.6968622207641602\nStep: 35, metrics/mean: 0.844555139541626\nStep: 35, epoch: 0.0\nStep: 36, loss/train: 0.015749551355838776\nStep: 36, epoch: 1.0\nStep: 37, loss/train: 0.015518547967076302\nStep: 37, epoch: 1.0\nStep: 38, loss/train: 0.015540312975645065\nStep: 38, epoch: 1.0\nStep: 39, loss/train: 0.015619213692843914\nStep: 39, epoch: 1.0\nStep: 40, loss/train: 0.015210876241326332\nStep: 40, epoch: 1.0\nStep: 41, loss/train: 0.015162399969995022\nStep: 41, epoch: 1.0\nStep: 42, loss/train: 0.015078302472829819\nStep: 42, epoch: 1.0\nStep: 43, loss/train: 0.014866644516587257\nStep: 43, epoch: 1.0\nStep: 44, loss/train: 0.01481970027089119\nStep: 44, epoch: 1.0\nStep: 45, loss/train: 0.014792298898100853\nStep: 45, epoch: 1.0\nStep: 46, loss/train: 0.014545604586601257\nStep: 46, epoch: 1.0\nStep: 47, loss/train: 0.014528956264257431\nStep: 47, epoch: 1.0\nStep: 48, loss/train: 0.014349650591611862\nStep: 48, epoch: 1.0\nStep: 49, loss/train: 0.0142661826685071\nStep: 49, epoch: 1.0\nStep: 50, loss/train: 0.014219332486391068\nStep: 50, epoch: 1.0\nStep: 51, loss/train: 0.01398773118853569\nStep: 51, epoch: 1.0\nStep: 52, loss/train: 0.013920866884291172\nStep: 52, epoch: 1.0\nStep: 53, loss/train: 0.01369272917509079\nStep: 53, epoch: 1.0\nStep: 54, loss/train: 0.013680748641490936\nStep: 54, epoch: 1.0\nStep: 55, loss/train: 0.013668650761246681\nStep: 55, epoch: 1.0\nStep: 56, loss/train: 0.013506544753909111\nStep: 56, epoch: 1.0\nStep: 57, loss/train: 0.013445919379591942\nStep: 57, epoch: 1.0\nStep: 58, loss/train: 0.013305403292179108\nStep: 58, epoch: 1.0\nStep: 59, loss/train: 0.013366857543587685\nStep: 59, epoch: 1.0\nStep: 60, loss/train: 0.013160391710698605\nStep: 60, epoch: 1.0\nStep: 61, loss/train: 0.013029715046286583\nStep: 61, epoch: 1.0\nStep: 62, loss/train: 0.012872045859694481\nStep: 62, epoch: 1.0\nStep: 63, loss/train: 0.013060151599347591\nStep: 63, epoch: 1.0\nStep: 64, loss/train: 0.012699082493782043\nStep: 64, epoch: 1.0\nStep: 65, loss/train: 0.012672564014792442\nStep: 65, epoch: 1.0\nStep: 66, loss/train: 0.012565510347485542\nStep: 66, epoch: 1.0\nStep: 67, loss/train: 0.01271643117070198\nStep: 67, epoch: 1.0\nStep: 68, loss/train: 0.012321405112743378\nStep: 68, epoch: 1.0\nStep: 69, loss/train: 0.012313700281083584\nStep: 69, epoch: 1.0\nStep: 70, loss/train: 0.012204225175082684\nStep: 70, epoch: 1.0\nStep: 71, loss/train: 0.0118935601785779\nStep: 71, epoch: 1.0\nStep: 71, loss/val: 0.007667500991374254\nStep: 71, epoch: 1.0\nStep: 72, loss/train: 0.012007529847323895\nStep: 72, epoch: 2.0\nStep: 73, loss/train: 0.012090511620044708\nStep: 73, epoch: 2.0\nStep: 74, loss/train: 0.011838343925774097\nStep: 74, epoch: 2.0\nStep: 75, loss/train: 0.011894343420863152\nStep: 75, epoch: 2.0\nStep: 76, loss/train: 0.011880126781761646\nStep: 76, epoch: 2.0\nStep: 77, loss/train: 0.01171779539436102\nStep: 77, epoch: 2.0\nStep: 78, loss/train: 0.011585569009184837\nStep: 78, epoch: 2.0\nStep: 79, loss/train: 0.011602561920881271\nStep: 79, epoch: 2.0\nStep: 80, loss/train: 0.011503606103360653\nStep: 80, epoch: 2.0\nStep: 81, loss/train: 0.011407308280467987\nStep: 81, epoch: 2.0\nStep: 82, loss/train: 0.01142535824328661\nStep: 82, epoch: 2.0\nStep: 83, loss/train: 0.01135921012610197\nStep: 83, epoch: 2.0\nStep: 84, loss/train: 0.011192510835826397\nStep: 84, epoch: 2.0\nStep: 85, loss/train: 0.011179600842297077\nStep: 85, epoch: 2.0\nStep: 86, loss/train: 0.011323452927172184\nStep: 86, epoch: 2.0\nStep: 87, loss/train: 0.011308555491268635\nStep: 87, epoch: 2.0\nStep: 88, loss/train: 0.011021195910871029\nStep: 88, epoch: 2.0\nStep: 89, loss/train: 0.010958933271467686\nStep: 89, epoch: 2.0\nStep: 90, loss/train: 0.010883931070566177\nStep: 90, epoch: 2.0\nStep: 91, loss/train: 0.010956551879644394\nStep: 91, epoch: 2.0\nStep: 92, loss/train: 0.010789381340146065\nStep: 92, epoch: 2.0\nStep: 93, loss/train: 0.0108170872554183\nStep: 93, epoch: 2.0\nStep: 94, loss/train: 0.01069122739136219\nStep: 94, epoch: 2.0\nStep: 95, loss/train: 0.010721566155552864\nStep: 95, epoch: 2.0\nStep: 96, loss/train: 0.010746101848781109\nStep: 96, epoch: 2.0\nStep: 97, loss/train: 0.010636214166879654\nStep: 97, epoch: 2.0\nStep: 98, loss/train: 0.01043009851127863\nStep: 98, epoch: 2.0\nStep: 99, loss/train: 0.010344079695641994\nStep: 99, epoch: 2.0\nStep: 100, loss/train: 0.010369349271059036\nStep: 100, epoch: 2.0\nStep: 101, loss/train: 0.010414558462798595\nStep: 101, epoch: 2.0\nStep: 102, loss/train: 0.010214812122285366\nStep: 102, epoch: 2.0\nStep: 103, loss/train: 0.010226333513855934\nStep: 103, epoch: 2.0\nStep: 104, loss/train: 0.010156895965337753\nStep: 104, epoch: 2.0\nStep: 105, loss/train: 0.010146493092179298\nStep: 105, epoch: 2.0\nStep: 106, loss/train: 0.009951172396540642\nStep: 106, epoch: 2.0\nStep: 107, loss/train: 0.009857556782662868\nStep: 107, epoch: 2.0\nStep: 107, loss/val: 0.008513996377587318\nStep: 107, epoch: 2.0\nStep: 108, loss/train: 0.01007005199790001\nStep: 108, epoch: 3.0\nStep: 109, loss/train: 0.010073770768940449\nStep: 109, epoch: 3.0\nStep: 110, loss/train: 0.009890399873256683\nStep: 110, epoch: 3.0\nStep: 111, loss/train: 0.009726769290864468\nStep: 111, epoch: 3.0\nStep: 112, loss/train: 0.009867079555988312\nStep: 112, epoch: 3.0\nStep: 113, loss/train: 0.009689569473266602\nStep: 113, epoch: 3.0\nStep: 114, loss/train: 0.009753184393048286\nStep: 114, epoch: 3.0\nStep: 115, loss/train: 0.009701332077383995\nStep: 115, epoch: 3.0\nStep: 116, loss/train: 0.0098346509039402\nStep: 116, epoch: 3.0\nStep: 117, loss/train: 0.009627947583794594\nStep: 117, epoch: 3.0\nStep: 118, loss/train: 0.009629584848880768\nStep: 118, epoch: 3.0\nStep: 119, loss/train: 0.009439179673790932\nStep: 119, epoch: 3.0\nStep: 120, loss/train: 0.009455225430428982\nStep: 120, epoch: 3.0\nStep: 121, loss/train: 0.00952779408544302\nStep: 121, epoch: 3.0\nStep: 122, loss/train: 0.009468058124184608\nStep: 122, epoch: 3.0\nStep: 123, loss/train: 0.009337686002254486\nStep: 123, epoch: 3.0\nStep: 124, loss/train: 0.00932283140718937\nStep: 124, epoch: 3.0\nStep: 125, loss/train: 0.00931890495121479\nStep: 125, epoch: 3.0\nStep: 126, loss/train: 0.009176671504974365\nStep: 126, epoch: 3.0\nStep: 127, loss/train: 0.009214559569954872\nStep: 127, epoch: 3.0\nStep: 128, loss/train: 0.009053226560354233\nStep: 128, epoch: 3.0\nStep: 129, loss/train: 0.009119019843637943\nStep: 129, epoch: 3.0\nStep: 130, loss/train: 0.009076472371816635\nStep: 130, epoch: 3.0\nStep: 131, loss/train: 0.009024670347571373\nStep: 131, epoch: 3.0\nStep: 132, loss/train: 0.008989443071186543\nStep: 132, epoch: 3.0\nStep: 133, loss/train: 0.009066539816558361\nStep: 133, epoch: 3.0\nStep: 134, loss/train: 0.009089119732379913\nStep: 134, epoch: 3.0\nStep: 135, loss/train: 0.009035824798047543\nStep: 135, epoch: 3.0\nStep: 136, loss/train: 0.008960792794823647\nStep: 136, epoch: 3.0\nStep: 137, loss/train: 0.00881214439868927\nStep: 137, epoch: 3.0\nStep: 138, loss/train: 0.008794047869741917\nStep: 138, epoch: 3.0\nStep: 139, loss/train: 0.008749914355576038\nStep: 139, epoch: 3.0\nStep: 140, loss/train: 0.00877360813319683\nStep: 140, epoch: 3.0\nStep: 141, loss/train: 0.008776303380727768\nStep: 141, epoch: 3.0\nStep: 142, loss/train: 0.008670059964060783\nStep: 142, epoch: 3.0\nStep: 143, loss/train: 0.008901499211788177\nStep: 143, epoch: 3.0\nStep: 143, loss/val: 0.007636649534106255\nStep: 143, epoch: 3.0\nStep: 144, loss/train: 0.008673891425132751\nStep: 144, epoch: 4.0\nStep: 145, loss/train: 0.0087440712377429\nStep: 145, epoch: 4.0\nStep: 146, loss/train: 0.008598340675234795\nStep: 146, epoch: 4.0\nStep: 147, loss/train: 0.008556343615055084\nStep: 147, epoch: 4.0\nStep: 148, loss/train: 0.008534845896065235\nStep: 148, epoch: 4.0\nStep: 149, loss/train: 0.008477061986923218\nStep: 149, epoch: 4.0\nStep: 150, loss/train: 0.008646285161376\nStep: 150, epoch: 4.0\nStep: 151, loss/train: 0.008538294583559036\nStep: 151, epoch: 4.0\nStep: 152, loss/train: 0.008382713422179222\nStep: 152, epoch: 4.0\nStep: 153, loss/train: 0.008312533609569073\nStep: 153, epoch: 4.0\nStep: 154, loss/train: 0.008345242589712143\nStep: 154, epoch: 4.0\nStep: 155, loss/train: 0.008311400189995766\nStep: 155, epoch: 4.0\nStep: 156, loss/train: 0.00833615381270647\nStep: 156, epoch: 4.0\nStep: 157, loss/train: 0.008207248523831367\nStep: 157, epoch: 4.0\nStep: 158, loss/train: 0.008318986743688583\nStep: 158, epoch: 4.0\nStep: 159, loss/train: 0.008348742499947548\nStep: 159, epoch: 4.0\nStep: 160, loss/train: 0.008187735453248024\nStep: 160, epoch: 4.0\nStep: 161, loss/train: 0.00828523375093937\nStep: 161, epoch: 4.0\nStep: 162, loss/train: 0.008033573627471924\nStep: 162, epoch: 4.0\nStep: 163, loss/train: 0.008055364713072777\nStep: 163, epoch: 4.0\nStep: 164, loss/train: 0.007965397089719772\nStep: 164, epoch: 4.0\nStep: 165, loss/train: 0.008232027292251587\nStep: 165, epoch: 4.0\nStep: 166, loss/train: 0.00797213613986969\nStep: 166, epoch: 4.0\nStep: 167, loss/train: 0.008253403007984161\nStep: 167, epoch: 4.0\nStep: 168, loss/train: 0.008015809580683708\nStep: 168, epoch: 4.0\nStep: 169, loss/train: 0.008106346242129803\nStep: 169, epoch: 4.0\nStep: 170, loss/train: 0.007964959368109703\nStep: 170, epoch: 4.0\nStep: 171, loss/train: 0.007951529696583748\nStep: 171, epoch: 4.0\nStep: 172, loss/train: 0.007996243424713612\nStep: 172, epoch: 4.0\nStep: 173, loss/train: 0.00785822793841362\nStep: 173, epoch: 4.0\nStep: 174, loss/train: 0.007859412580728531\nStep: 174, epoch: 4.0\nStep: 175, loss/train: 0.007828084751963615\nStep: 175, epoch: 4.0\nStep: 176, loss/train: 0.007871628738939762\nStep: 176, epoch: 4.0\nStep: 177, loss/train: 0.00792852696031332\nStep: 177, epoch: 4.0\nStep: 178, loss/train: 0.007903696969151497\nStep: 178, epoch: 4.0\nStep: 179, loss/train: 0.007634937763214111\nStep: 179, epoch: 4.0\nStep: 179, loss/val: 0.006872550584375858\nStep: 179, epoch: 4.0\nStep: 180, loss/train: 0.007873430848121643\nStep: 180, epoch: 5.0\nStep: 181, loss/train: 0.007744521833956242\nStep: 181, epoch: 5.0\nStep: 182, loss/train: 0.007746994495391846\nStep: 182, epoch: 5.0\nStep: 183, loss/train: 0.007778566796332598\nStep: 183, epoch: 5.0\nStep: 184, loss/train: 0.0076894089579582214\nStep: 184, epoch: 5.0\nStep: 185, loss/train: 0.007579750381410122\nStep: 185, epoch: 5.0\nStep: 186, loss/train: 0.007543590851128101\nStep: 186, epoch: 5.0\nStep: 187, loss/train: 0.007783771958202124\nStep: 187, epoch: 5.0\nStep: 188, loss/train: 0.007558761164546013\nStep: 188, epoch: 5.0\nStep: 189, loss/train: 0.007472497411072254\nStep: 189, epoch: 5.0\nStep: 190, loss/train: 0.007541732396930456\nStep: 190, epoch: 5.0\nStep: 191, loss/train: 0.007520803716033697\nStep: 191, epoch: 5.0\nStep: 192, loss/train: 0.0074384440667927265\nStep: 192, epoch: 5.0\nStep: 193, loss/train: 0.007590762339532375\nStep: 193, epoch: 5.0\nStep: 194, loss/train: 0.007440873421728611\nStep: 194, epoch: 5.0\nStep: 195, loss/train: 0.007411107420921326\nStep: 195, epoch: 5.0\nStep: 196, loss/train: 0.0074331266805529594\nStep: 196, epoch: 5.0\nStep: 197, loss/train: 0.0073891207575798035\nStep: 197, epoch: 5.0\nStep: 198, loss/train: 0.007453713566064835\nStep: 198, epoch: 5.0\nStep: 199, loss/train: 0.007329979911446571\nStep: 199, epoch: 5.0\nStep: 200, loss/train: 0.007330358028411865\nStep: 200, epoch: 5.0\nStep: 201, loss/train: 0.007302338257431984\nStep: 201, epoch: 5.0\nStep: 202, loss/train: 0.0074746254831552505\nStep: 202, epoch: 5.0\nStep: 203, loss/train: 0.007415499538183212\nStep: 203, epoch: 5.0\nStep: 204, loss/train: 0.007244869135320187\nStep: 204, epoch: 5.0\nStep: 205, loss/train: 0.007324668578803539\nStep: 205, epoch: 5.0\nStep: 206, loss/train: 0.007287111133337021\nStep: 206, epoch: 5.0\nStep: 207, loss/train: 0.00726360734552145\nStep: 207, epoch: 5.0\nStep: 208, loss/train: 0.007141678594052792\nStep: 208, epoch: 5.0\nStep: 209, loss/train: 0.0071431053802371025\nStep: 209, epoch: 5.0\nStep: 210, loss/train: 0.007150653284043074\nStep: 210, epoch: 5.0\nStep: 211, loss/train: 0.0072321705520153046\nStep: 211, epoch: 5.0\nStep: 212, loss/train: 0.007117936387658119\nStep: 212, epoch: 5.0\nStep: 213, loss/train: 0.007110206410288811\nStep: 213, epoch: 5.0\nStep: 214, loss/train: 0.007042221259325743\nStep: 214, epoch: 5.0\nStep: 215, loss/train: 0.007350187283009291\nStep: 215, epoch: 5.0\nStep: 215, loss/val: 0.006324409041553736\nStep: 215, epoch: 5.0\nStep: 215, roc_auc: 0.9963051676750183\nStep: 215, opt_thresh: 0.00750334095209837\nStep: 215, metrics/tpr: 0.7829457521438599\nStep: 215, metrics/tnr: 0.8548431396484375\nStep: 215, metrics/mean: 0.8188944458961487\nStep: 215, epoch: 5.0\nStep: 216, loss/train: 0.00725370179861784\nStep: 216, epoch: 6.0\nStep: 217, loss/train: 0.00706817302852869\nStep: 217, epoch: 6.0\nStep: 218, loss/train: 0.007078236434608698\nStep: 218, epoch: 6.0\nStep: 219, loss/train: 0.007060440257191658\nStep: 219, epoch: 6.0\nStep: 220, loss/train: 0.007146339863538742\nStep: 220, epoch: 6.0\nStep: 221, loss/train: 0.007015795446932316\nStep: 221, epoch: 6.0\nStep: 222, loss/train: 0.006974528543651104\nStep: 222, epoch: 6.0\nStep: 223, loss/train: 0.006969332229346037\nStep: 223, epoch: 6.0\nStep: 224, loss/train: 0.0069299363531172276\nStep: 224, epoch: 6.0\nStep: 225, loss/train: 0.006839130539447069\nStep: 225, epoch: 6.0\nStep: 226, loss/train: 0.0069463858380913734\nStep: 226, epoch: 6.0\nStep: 227, loss/train: 0.006878707557916641\nStep: 227, epoch: 6.0\nStep: 228, loss/train: 0.006861518602818251\nStep: 228, epoch: 6.0\nStep: 229, loss/train: 0.00684907054528594\nStep: 229, epoch: 6.0\nStep: 230, loss/train: 0.006751633249223232\nStep: 230, epoch: 6.0\nStep: 231, loss/train: 0.006875797174870968\nStep: 231, epoch: 6.0\nStep: 232, loss/train: 0.006814758758991957\nStep: 232, epoch: 6.0\nStep: 233, loss/train: 0.006836654618382454\nStep: 233, epoch: 6.0\nStep: 234, loss/train: 0.006866432726383209\nStep: 234, epoch: 6.0\nStep: 235, loss/train: 0.0067681437358260155\nStep: 235, epoch: 6.0\nStep: 236, loss/train: 0.0069096945226192474\nStep: 236, epoch: 6.0\nStep: 237, loss/train: 0.006745011545717716\nStep: 237, epoch: 6.0\nStep: 238, loss/train: 0.006592702120542526\nStep: 238, epoch: 6.0\nStep: 239, loss/train: 0.006753684487193823\nStep: 239, epoch: 6.0\nStep: 240, loss/train: 0.006693831644952297\nStep: 240, epoch: 6.0\nStep: 241, loss/train: 0.0067129721865057945\nStep: 241, epoch: 6.0\nStep: 242, loss/train: 0.006710677407681942\nStep: 242, epoch: 6.0\nStep: 243, loss/train: 0.006689013913273811\nStep: 243, epoch: 6.0\nStep: 244, loss/train: 0.006629482842981815\nStep: 244, epoch: 6.0\nStep: 245, loss/train: 0.006706078536808491\nStep: 245, epoch: 6.0\nStep: 246, loss/train: 0.006581621244549751\nStep: 246, epoch: 6.0\nStep: 247, loss/train: 0.006585688330233097\nStep: 247, epoch: 6.0\nStep: 248, loss/train: 0.0065272096544504166\nStep: 248, epoch: 6.0\nStep: 249, loss/train: 0.006464785896241665\nStep: 249, epoch: 6.0\nStep: 250, loss/train: 0.00659433426335454\nStep: 250, epoch: 6.0\nStep: 251, loss/train: 0.006660284008830786\nStep: 251, epoch: 6.0\nStep: 251, loss/val: 0.005882470868527889\nStep: 251, epoch: 6.0\nStep: 252, loss/train: 0.006577909458428621\nStep: 252, epoch: 7.0\nStep: 253, loss/train: 0.006429262459278107\nStep: 253, epoch: 7.0\nStep: 254, loss/train: 0.006399729289114475\nStep: 254, epoch: 7.0\nStep: 255, loss/train: 0.006475301459431648\nStep: 255, epoch: 7.0\nStep: 256, loss/train: 0.0064863841980695724\nStep: 256, epoch: 7.0\nStep: 257, loss/train: 0.006387423723936081\nStep: 257, epoch: 7.0\nStep: 258, loss/train: 0.0063846539705991745\nStep: 258, epoch: 7.0\nStep: 259, loss/train: 0.006352925207465887\nStep: 259, epoch: 7.0\nStep: 260, loss/train: 0.0063714561983942986\nStep: 260, epoch: 7.0\nStep: 261, loss/train: 0.0063698869198560715\nStep: 261, epoch: 7.0\nStep: 262, loss/train: 0.00652973260730505\nStep: 262, epoch: 7.0\nStep: 263, loss/train: 0.0062937866896390915\nStep: 263, epoch: 7.0\nStep: 264, loss/train: 0.006367470137774944\nStep: 264, epoch: 7.0\nStep: 265, loss/train: 0.006351222284138203\nStep: 265, epoch: 7.0\nStep: 266, loss/train: 0.006434968672692776\nStep: 266, epoch: 7.0\nStep: 267, loss/train: 0.006185580510646105\nStep: 267, epoch: 7.0\nStep: 268, loss/train: 0.006305192597210407\nStep: 268, epoch: 7.0\nStep: 269, loss/train: 0.006261555477976799\nStep: 269, epoch: 7.0\nStep: 270, loss/train: 0.0063028400763869286\nStep: 270, epoch: 7.0\nStep: 271, loss/train: 0.006273418664932251\nStep: 271, epoch: 7.0\nStep: 272, loss/train: 0.006322920322418213\nStep: 272, epoch: 7.0\nStep: 273, loss/train: 0.006282530725002289\nStep: 273, epoch: 7.0\nStep: 274, loss/train: 0.006180633790791035\nStep: 274, epoch: 7.0\nStep: 275, loss/train: 0.006259518675506115\nStep: 275, epoch: 7.0\nStep: 276, loss/train: 0.00617360370233655\nStep: 276, epoch: 7.0\nStep: 277, loss/train: 0.006206841673702002\nStep: 277, epoch: 7.0\nStep: 278, loss/train: 0.00612791208550334\nStep: 278, epoch: 7.0\nStep: 279, loss/train: 0.006212825421243906\nStep: 279, epoch: 7.0\nStep: 280, loss/train: 0.006032860837876797\nStep: 280, epoch: 7.0\nStep: 281, loss/train: 0.00615835702046752\nStep: 281, epoch: 7.0\nStep: 282, loss/train: 0.006205009296536446\nStep: 282, epoch: 7.0\nStep: 283, loss/train: 0.006119986530393362\nStep: 283, epoch: 7.0\nStep: 284, loss/train: 0.006144621409475803\nStep: 284, epoch: 7.0\nStep: 285, loss/train: 0.006143621634691954\nStep: 285, epoch: 7.0\nStep: 286, loss/train: 0.006193133071064949\nStep: 286, epoch: 7.0\nStep: 287, loss/train: 0.006156553514301777\nStep: 287, epoch: 7.0\nStep: 287, loss/val: 0.005493383388966322\nStep: 287, epoch: 7.0\nStep: 288, loss/train: 0.006058940663933754\nStep: 288, epoch: 8.0\nStep: 289, loss/train: 0.006139424163848162\nStep: 289, epoch: 8.0\nStep: 290, loss/train: 0.006010687444359064\nStep: 290, epoch: 8.0\nStep: 291, loss/train: 0.005971954204142094\nStep: 291, epoch: 8.0\nStep: 292, loss/train: 0.005922775249928236\nStep: 292, epoch: 8.0\nStep: 293, loss/train: 0.006153509020805359\nStep: 293, epoch: 8.0\nStep: 294, loss/train: 0.005966118071228266\nStep: 294, epoch: 8.0\nStep: 295, loss/train: 0.006195097230374813\nStep: 295, epoch: 8.0\nStep: 296, loss/train: 0.0060802954249084\nStep: 296, epoch: 8.0\nStep: 297, loss/train: 0.00599541375413537\nStep: 297, epoch: 8.0\nStep: 298, loss/train: 0.0059200553223490715\nStep: 298, epoch: 8.0\nStep: 299, loss/train: 0.005898240953683853\nStep: 299, epoch: 8.0\nStep: 300, loss/train: 0.005971443839371204\nStep: 300, epoch: 8.0\nStep: 301, loss/train: 0.006037757266312838\nStep: 301, epoch: 8.0\nStep: 302, loss/train: 0.006005165167152882\nStep: 302, epoch: 8.0\nStep: 303, loss/train: 0.006025772541761398\nStep: 303, epoch: 8.0\nStep: 304, loss/train: 0.005851316265761852\nStep: 304, epoch: 8.0\nStep: 305, loss/train: 0.005935732275247574\nStep: 305, epoch: 8.0\nStep: 306, loss/train: 0.005799766629934311\nStep: 306, epoch: 8.0\nStep: 307, loss/train: 0.0058995578438043594\nStep: 307, epoch: 8.0\nStep: 308, loss/train: 0.005819899030029774\nStep: 308, epoch: 8.0\nStep: 309, loss/train: 0.005945109762251377\nStep: 309, epoch: 8.0\nStep: 310, loss/train: 0.005771700292825699\nStep: 310, epoch: 8.0\nStep: 311, loss/train: 0.005936445668339729\nStep: 311, epoch: 8.0\nStep: 312, loss/train: 0.005878881551325321\nStep: 312, epoch: 8.0\nStep: 313, loss/train: 0.005799839273095131\nStep: 313, epoch: 8.0\nStep: 314, loss/train: 0.005807692185044289\nStep: 314, epoch: 8.0\nStep: 315, loss/train: 0.005863022059202194\nStep: 315, epoch: 8.0\nStep: 316, loss/train: 0.005771344061940908\nStep: 316, epoch: 8.0\nStep: 317, loss/train: 0.005786963272839785\nStep: 317, epoch: 8.0\nStep: 318, loss/train: 0.005679924041032791\nStep: 318, epoch: 8.0\nStep: 319, loss/train: 0.00569872697815299\nStep: 319, epoch: 8.0\nStep: 320, loss/train: 0.005713183432817459\nStep: 320, epoch: 8.0\nStep: 321, loss/train: 0.005716430023312569\nStep: 321, epoch: 8.0\nStep: 322, loss/train: 0.0058098747394979\nStep: 322, epoch: 8.0\nStep: 323, loss/train: 0.005987703800201416\nStep: 323, epoch: 8.0\nStep: 323, loss/val: 0.005201087333261967\nStep: 323, epoch: 8.0\nStep: 324, loss/train: 0.00564256077632308\nStep: 324, epoch: 9.0\nStep: 325, loss/train: 0.005782106891274452\nStep: 325, epoch: 9.0\nStep: 326, loss/train: 0.005801294930279255\nStep: 326, epoch: 9.0\nStep: 327, loss/train: 0.005717907100915909\nStep: 327, epoch: 9.0\nStep: 328, loss/train: 0.00581988412886858\nStep: 328, epoch: 9.0\nStep: 329, loss/train: 0.0057092527858912945\nStep: 329, epoch: 9.0\nStep: 330, loss/train: 0.005687805823981762\nStep: 330, epoch: 9.0\nStep: 331, loss/train: 0.005929659586399794\nStep: 331, epoch: 9.0\nStep: 332, loss/train: 0.005612626671791077\nStep: 332, epoch: 9.0\nStep: 333, loss/train: 0.005819818936288357\nStep: 333, epoch: 9.0\nStep: 334, loss/train: 0.005742806475609541\nStep: 334, epoch: 9.0\nStep: 335, loss/train: 0.0056070853024721146\nStep: 335, epoch: 9.0\nStep: 336, loss/train: 0.005530036054551601\nStep: 336, epoch: 9.0\nStep: 337, loss/train: 0.005652849096804857\nStep: 337, epoch: 9.0\nStep: 338, loss/train: 0.005677148699760437\nStep: 338, epoch: 9.0\nStep: 339, loss/train: 0.005564805120229721\nStep: 339, epoch: 9.0\nStep: 340, loss/train: 0.0056006815284490585\nStep: 340, epoch: 9.0\nStep: 341, loss/train: 0.005561062600463629\nStep: 341, epoch: 9.0\nStep: 342, loss/train: 0.005686030723154545\nStep: 342, epoch: 9.0\nStep: 343, loss/train: 0.005555564537644386\nStep: 343, epoch: 9.0\nStep: 344, loss/train: 0.005687974859029055\nStep: 344, epoch: 9.0\nStep: 345, loss/train: 0.0055638691410422325\nStep: 345, epoch: 9.0\nStep: 346, loss/train: 0.005458480212837458\nStep: 346, epoch: 9.0\nStep: 347, loss/train: 0.005570803768932819\nStep: 347, epoch: 9.0\nStep: 348, loss/train: 0.00554262101650238\nStep: 348, epoch: 9.0\nStep: 349, loss/train: 0.005450030323117971\nStep: 349, epoch: 9.0\nStep: 350, loss/train: 0.005447291769087315\nStep: 350, epoch: 9.0\nStep: 351, loss/train: 0.005599770694971085\nStep: 351, epoch: 9.0\nStep: 352, loss/train: 0.00543916504830122\nStep: 352, epoch: 9.0\nStep: 353, loss/train: 0.005399031098932028\nStep: 353, epoch: 9.0\nStep: 354, loss/train: 0.005534901283681393\nStep: 354, epoch: 9.0\nStep: 355, loss/train: 0.005490160547196865\nStep: 355, epoch: 9.0\nStep: 356, loss/train: 0.0055076004937291145\nStep: 356, epoch: 9.0\nStep: 357, loss/train: 0.005357140209525824\nStep: 357, epoch: 9.0\nStep: 358, loss/train: 0.0054385606199502945\nStep: 358, epoch: 9.0\nStep: 359, loss/train: 0.006367874331772327\nStep: 359, epoch: 9.0\nStep: 359, loss/val: 0.005042742937803268\nStep: 359, epoch: 9.0\nStep: 360, loss/train: 0.0054117972031235695\nStep: 360, epoch: 10.0\nStep: 361, loss/train: 0.005471533164381981\nStep: 361, epoch: 10.0\nStep: 362, loss/train: 0.005515716969966888\nStep: 362, epoch: 10.0\nStep: 363, loss/train: 0.005364243406802416\nStep: 363, epoch: 10.0\nStep: 364, loss/train: 0.005382386036217213\nStep: 364, epoch: 10.0\nStep: 365, loss/train: 0.005480622872710228\nStep: 365, epoch: 10.0\nStep: 366, loss/train: 0.005368516314774752\nStep: 366, epoch: 10.0\nStep: 367, loss/train: 0.005351422820240259\nStep: 367, epoch: 10.0\nStep: 368, loss/train: 0.005383642390370369\nStep: 368, epoch: 10.0\nStep: 369, loss/train: 0.005418101325631142\nStep: 369, epoch: 10.0\nStep: 370, loss/train: 0.0053371237590909\nStep: 370, epoch: 10.0\nStep: 371, loss/train: 0.005361878778785467\nStep: 371, epoch: 10.0\nStep: 372, loss/train: 0.00547580374404788\nStep: 372, epoch: 10.0\nStep: 373, loss/train: 0.005415802821516991\nStep: 373, epoch: 10.0\nStep: 374, loss/train: 0.00530325248837471\nStep: 374, epoch: 10.0\nStep: 375, loss/train: 0.005304309539496899\nStep: 375, epoch: 10.0\nStep: 376, loss/train: 0.00535469688475132\nStep: 376, epoch: 10.0\nStep: 377, loss/train: 0.005351533647626638\nStep: 377, epoch: 10.0\nStep: 378, loss/train: 0.005361937452107668\nStep: 378, epoch: 10.0\nStep: 379, loss/train: 0.005262573715299368\nStep: 379, epoch: 10.0\nStep: 380, loss/train: 0.0052452995441854\nStep: 380, epoch: 10.0\nStep: 381, loss/train: 0.00527601083740592\nStep: 381, epoch: 10.0\nStep: 382, loss/train: 0.005211623385548592\nStep: 382, epoch: 10.0\nStep: 383, loss/train: 0.005237642675638199\nStep: 383, epoch: 10.0\nStep: 384, loss/train: 0.005424946080893278\nStep: 384, epoch: 10.0\nStep: 385, loss/train: 0.0053648315370082855\nStep: 385, epoch: 10.0\nStep: 386, loss/train: 0.005325226578861475\nStep: 386, epoch: 10.0\nStep: 387, loss/train: 0.0051947711035609245\nStep: 387, epoch: 10.0\nStep: 388, loss/train: 0.005242073908448219\nStep: 388, epoch: 10.0\nStep: 389, loss/train: 0.005233812145888805\nStep: 389, epoch: 10.0\nStep: 390, loss/train: 0.00533011369407177\nStep: 390, epoch: 10.0\nStep: 391, loss/train: 0.005249629728496075\nStep: 391, epoch: 10.0\nStep: 392, loss/train: 0.005165767855942249\nStep: 392, epoch: 10.0\nStep: 393, loss/train: 0.005147950258105993\nStep: 393, epoch: 10.0\nStep: 394, loss/train: 0.005186663940548897\nStep: 394, epoch: 10.0\nStep: 395, loss/train: 0.005203183274716139\nStep: 395, epoch: 10.0\nStep: 395, loss/val: 0.004739722702652216\nStep: 395, epoch: 10.0\nStep: 395, roc_auc: 0.9958636164665222\nStep: 395, opt_thresh: 0.005189856048673391\nStep: 395, metrics/tpr: 0.7751938104629517\nStep: 395, metrics/tnr: 0.8106412291526794\nStep: 395, metrics/mean: 0.7929174900054932\nStep: 395, epoch: 10.0\nStep: 396, loss/train: 0.0052627697587013245\nStep: 396, epoch: 11.0\nStep: 397, loss/train: 0.005170086398720741\nStep: 397, epoch: 11.0\nStep: 398, loss/train: 0.005136100109666586\nStep: 398, epoch: 11.0\nStep: 399, loss/train: 0.005171698983758688\nStep: 399, epoch: 11.0\nStep: 400, loss/train: 0.0051201870664954185\nStep: 400, epoch: 11.0\nStep: 401, loss/train: 0.005155062302947044\nStep: 401, epoch: 11.0\nStep: 402, loss/train: 0.005102759227156639\nStep: 402, epoch: 11.0\nStep: 403, loss/train: 0.005108878016471863\nStep: 403, epoch: 11.0\nStep: 404, loss/train: 0.005200160201638937\nStep: 404, epoch: 11.0\nStep: 405, loss/train: 0.005063727032393217\nStep: 405, epoch: 11.0\nStep: 406, loss/train: 0.005072087049484253\nStep: 406, epoch: 11.0\nStep: 407, loss/train: 0.005177133716642857\nStep: 407, epoch: 11.0\nStep: 408, loss/train: 0.005072965286672115\nStep: 408, epoch: 11.0\nStep: 409, loss/train: 0.005166484974324703\nStep: 409, epoch: 11.0\nStep: 410, loss/train: 0.0050808582454919815\nStep: 410, epoch: 11.0\nStep: 411, loss/train: 0.005095168482512236\nStep: 411, epoch: 11.0\nStep: 412, loss/train: 0.004995438735932112\nStep: 412, epoch: 11.0\nStep: 413, loss/train: 0.0050844051875174046\nStep: 413, epoch: 11.0\nStep: 414, loss/train: 0.00504560861736536\nStep: 414, epoch: 11.0\nStep: 415, loss/train: 0.005067376885563135\nStep: 415, epoch: 11.0\nStep: 416, loss/train: 0.004996849223971367\nStep: 416, epoch: 11.0\nStep: 417, loss/train: 0.005021058488637209\nStep: 417, epoch: 11.0\nStep: 418, loss/train: 0.005027380771934986\nStep: 418, epoch: 11.0\nStep: 419, loss/train: 0.004977029282599688\nStep: 419, epoch: 11.0\nStep: 420, loss/train: 0.004999955650418997\nStep: 420, epoch: 11.0\nStep: 421, loss/train: 0.004940422251820564\nStep: 421, epoch: 11.0\nStep: 422, loss/train: 0.004979540593922138\nStep: 422, epoch: 11.0\nStep: 423, loss/train: 0.004985909443348646\nStep: 423, epoch: 11.0\nStep: 424, loss/train: 0.004938141442835331\nStep: 424, epoch: 11.0\nStep: 425, loss/train: 0.005074895918369293\nStep: 425, epoch: 11.0\nStep: 426, loss/train: 0.004983170889317989\nStep: 426, epoch: 11.0\nStep: 427, loss/train: 0.0048876069486141205\nStep: 427, epoch: 11.0\nStep: 428, loss/train: 0.004965910222381353\nStep: 428, epoch: 11.0\nStep: 429, loss/train: 0.0050485460087656975\nStep: 429, epoch: 11.0\nStep: 430, loss/train: 0.004916365258395672\nStep: 430, epoch: 11.0\nStep: 431, loss/train: 0.004858300555497408\nStep: 431, epoch: 11.0\nStep: 431, loss/val: 0.004492906387895346\nStep: 431, epoch: 11.0\nStep: 432, loss/train: 0.005046926438808441\nStep: 432, epoch: 12.0\nStep: 433, loss/train: 0.004931553266942501\nStep: 433, epoch: 12.0\nStep: 434, loss/train: 0.005033242516219616\nStep: 434, epoch: 12.0\nStep: 435, loss/train: 0.004957226105034351\nStep: 435, epoch: 12.0\nStep: 436, loss/train: 0.004846762865781784\nStep: 436, epoch: 12.0\nStep: 437, loss/train: 0.004976833239197731\nStep: 437, epoch: 12.0\nStep: 438, loss/train: 0.004845693241804838\nStep: 438, epoch: 12.0\nStep: 439, loss/train: 0.0048819417133927345\nStep: 439, epoch: 12.0\nStep: 440, loss/train: 0.004802715498954058\nStep: 440, epoch: 12.0\nStep: 441, loss/train: 0.004850735422223806\nStep: 441, epoch: 12.0\nStep: 442, loss/train: 0.004877873696386814\nStep: 442, epoch: 12.0\nStep: 443, loss/train: 0.004915088415145874\nStep: 443, epoch: 12.0\nStep: 444, loss/train: 0.0048295482993125916\nStep: 444, epoch: 12.0\nStep: 445, loss/train: 0.0048071714118123055\nStep: 445, epoch: 12.0\nStep: 446, loss/train: 0.0048065693117678165\nStep: 446, epoch: 12.0\nStep: 447, loss/train: 0.004849365912377834\nStep: 447, epoch: 12.0\nStep: 448, loss/train: 0.004774769768118858\nStep: 448, epoch: 12.0\nStep: 449, loss/train: 0.004842946771532297\nStep: 449, epoch: 12.0\nStep: 450, loss/train: 0.004865651018917561\nStep: 450, epoch: 12.0\nStep: 451, loss/train: 0.004925247747451067\nStep: 451, epoch: 12.0\nStep: 452, loss/train: 0.004813887178897858\nStep: 452, epoch: 12.0\nStep: 453, loss/train: 0.004765594843775034\nStep: 453, epoch: 12.0\nStep: 454, loss/train: 0.004754466004669666\nStep: 454, epoch: 12.0\nStep: 455, loss/train: 0.004719779826700687\nStep: 455, epoch: 12.0\nStep: 456, loss/train: 0.004768691025674343\nStep: 456, epoch: 12.0\nStep: 457, loss/train: 0.004655469208955765\nStep: 457, epoch: 12.0\nStep: 458, loss/train: 0.00479039316996932\nStep: 458, epoch: 12.0\nStep: 459, loss/train: 0.004723013378679752\nStep: 459, epoch: 12.0\nStep: 460, loss/train: 0.004820914939045906\nStep: 460, epoch: 12.0\nStep: 461, loss/train: 0.004693035967648029\nStep: 461, epoch: 12.0\nStep: 462, loss/train: 0.004662570543587208\nStep: 462, epoch: 12.0\nStep: 463, loss/train: 0.004730102606117725\nStep: 463, epoch: 12.0\nStep: 464, loss/train: 0.004657115787267685\nStep: 464, epoch: 12.0\nStep: 465, loss/train: 0.004627915099263191\nStep: 465, epoch: 12.0\nStep: 466, loss/train: 0.004687475506216288\nStep: 466, epoch: 12.0\nStep: 467, loss/train: 0.004607288632541895\nStep: 467, epoch: 12.0\nStep: 467, loss/val: 0.00425277603790164\nStep: 467, epoch: 12.0\nStep: 468, loss/train: 0.0046585192903876305\nStep: 468, epoch: 13.0\nStep: 469, loss/train: 0.00464201532304287\nStep: 469, epoch: 13.0\nStep: 470, loss/train: 0.004629802890121937\nStep: 470, epoch: 13.0\nStep: 471, loss/train: 0.004634364973753691\nStep: 471, epoch: 13.0\nStep: 472, loss/train: 0.004757275339215994\nStep: 472, epoch: 13.0\nStep: 473, loss/train: 0.0046338364481925964\nStep: 473, epoch: 13.0\nStep: 474, loss/train: 0.0045623513869941235\nStep: 474, epoch: 13.0\nStep: 475, loss/train: 0.004610096570104361\nStep: 475, epoch: 13.0\nStep: 476, loss/train: 0.0046108560636639595\nStep: 476, epoch: 13.0\nStep: 477, loss/train: 0.004656118340790272\nStep: 477, epoch: 13.0\nStep: 478, loss/train: 0.00455328356474638\nStep: 478, epoch: 13.0\nStep: 479, loss/train: 0.00469761248677969\nStep: 479, epoch: 13.0\nStep: 480, loss/train: 0.004642056301236153\nStep: 480, epoch: 13.0\nStep: 481, loss/train: 0.004733961541205645\nStep: 481, epoch: 13.0\nStep: 482, loss/train: 0.004547839518636465\nStep: 482, epoch: 13.0\nStep: 483, loss/train: 0.004625466652214527\nStep: 483, epoch: 13.0\nStep: 484, loss/train: 0.004632876254618168\nStep: 484, epoch: 13.0\nStep: 485, loss/train: 0.00466433260589838\nStep: 485, epoch: 13.0\nStep: 486, loss/train: 0.004582446999847889\nStep: 486, epoch: 13.0\nStep: 487, loss/train: 0.004546559415757656\nStep: 487, epoch: 13.0\nStep: 488, loss/train: 0.004526296630501747\nStep: 488, epoch: 13.0\nStep: 489, loss/train: 0.004541811067610979\nStep: 489, epoch: 13.0\nStep: 490, loss/train: 0.004561825655400753\nStep: 490, epoch: 13.0\nStep: 491, loss/train: 0.004607798531651497\nStep: 491, epoch: 13.0\nStep: 492, loss/train: 0.004525201395153999\nStep: 492, epoch: 13.0\nStep: 493, loss/train: 0.0044713011011481285\nStep: 493, epoch: 13.0\nStep: 494, loss/train: 0.004521701950579882\nStep: 494, epoch: 13.0\nStep: 495, loss/train: 0.004480238072574139\nStep: 495, epoch: 13.0\nStep: 496, loss/train: 0.004499322734773159\nStep: 496, epoch: 13.0\nStep: 497, loss/train: 0.004474608227610588\nStep: 497, epoch: 13.0\nStep: 498, loss/train: 0.004443055018782616\nStep: 498, epoch: 13.0\nStep: 499, loss/train: 0.0045217289589345455\nStep: 499, epoch: 13.0\nStep: 500, loss/train: 0.004459686577320099\nStep: 500, epoch: 13.0\nStep: 501, loss/train: 0.0044624945148825645\nStep: 501, epoch: 13.0\nStep: 502, loss/train: 0.004405287094414234\nStep: 502, epoch: 13.0\nStep: 503, loss/train: 0.004354715347290039\nStep: 503, epoch: 13.0\nStep: 503, loss/val: 0.004034112673252821\nStep: 503, epoch: 13.0\nStep: 504, loss/train: 0.0044173188507556915\nStep: 504, epoch: 14.0\nStep: 505, loss/train: 0.004501141142100096\nStep: 505, epoch: 14.0\nStep: 506, loss/train: 0.00449124863371253\nStep: 506, epoch: 14.0\nStep: 507, loss/train: 0.00435691699385643\nStep: 507, epoch: 14.0\nStep: 508, loss/train: 0.004446572158485651\nStep: 508, epoch: 14.0\nStep: 509, loss/train: 0.0043584736995399\nStep: 509, epoch: 14.0\nStep: 510, loss/train: 0.004418672528117895\nStep: 510, epoch: 14.0\nStep: 511, loss/train: 0.004457846283912659\nStep: 511, epoch: 14.0\nStep: 512, loss/train: 0.004367359913885593\nStep: 512, epoch: 14.0\nStep: 513, loss/train: 0.0043324921280145645\nStep: 513, epoch: 14.0\nStep: 514, loss/train: 0.004390487913042307\nStep: 514, epoch: 14.0\nStep: 515, loss/train: 0.004354941658675671\nStep: 515, epoch: 14.0\nStep: 516, loss/train: 0.004451478831470013\nStep: 516, epoch: 14.0\nStep: 517, loss/train: 0.004352868068963289\nStep: 517, epoch: 14.0\nStep: 518, loss/train: 0.004316492006182671\nStep: 518, epoch: 14.0\nStep: 519, loss/train: 0.004324514884501696\nStep: 519, epoch: 14.0\nStep: 520, loss/train: 0.004346989095211029\nStep: 520, epoch: 14.0\nStep: 521, loss/train: 0.004300985485315323\nStep: 521, epoch: 14.0\nStep: 522, loss/train: 0.004255340434610844\nStep: 522, epoch: 14.0\nStep: 523, loss/train: 0.004403427708894014\nStep: 523, epoch: 14.0\nStep: 524, loss/train: 0.0042621237225830555\nStep: 524, epoch: 14.0\nStep: 525, loss/train: 0.004261743277311325\nStep: 525, epoch: 14.0\nStep: 526, loss/train: 0.0042615365236997604\nStep: 526, epoch: 14.0\nStep: 527, loss/train: 0.004300558939576149\nStep: 527, epoch: 14.0\nStep: 528, loss/train: 0.004310211166739464\nStep: 528, epoch: 14.0\nStep: 529, loss/train: 0.004375987220555544\nStep: 529, epoch: 14.0\nStep: 530, loss/train: 0.004223205149173737\nStep: 530, epoch: 14.0\nStep: 531, loss/train: 0.0042143515311181545\nStep: 531, epoch: 14.0\nStep: 532, loss/train: 0.004264758434146643\nStep: 532, epoch: 14.0\nStep: 533, loss/train: 0.0041335998103022575\nStep: 533, epoch: 14.0\nStep: 534, loss/train: 0.004245962016284466\nStep: 534, epoch: 14.0\nStep: 535, loss/train: 0.0041944351978600025\nStep: 535, epoch: 14.0\nStep: 536, loss/train: 0.004233363084495068\nStep: 536, epoch: 14.0\nStep: 537, loss/train: 0.004199732560664415\nStep: 537, epoch: 14.0\nStep: 538, loss/train: 0.004243927076458931\nStep: 538, epoch: 14.0\nStep: 539, loss/train: 0.004322481341660023\nStep: 539, epoch: 14.0\nStep: 539, loss/val: 0.003840490709990263\nStep: 539, epoch: 14.0\nStep: 540, loss/train: 0.00417367136105895\nStep: 540, epoch: 15.0\nStep: 541, loss/train: 0.004137270152568817\nStep: 541, epoch: 15.0\nStep: 542, loss/train: 0.004094184376299381\nStep: 542, epoch: 15.0\nStep: 543, loss/train: 0.004268079996109009\nStep: 543, epoch: 15.0\nStep: 544, loss/train: 0.004220132250338793\nStep: 544, epoch: 15.0\nStep: 545, loss/train: 0.004100922029465437\nStep: 545, epoch: 15.0\nStep: 546, loss/train: 0.004159651231020689\nStep: 546, epoch: 15.0\nStep: 547, loss/train: 0.0042250072583556175\nStep: 547, epoch: 15.0\nStep: 548, loss/train: 0.00426276121288538\nStep: 548, epoch: 15.0\nStep: 549, loss/train: 0.004176189191639423\nStep: 549, epoch: 15.0\nStep: 550, loss/train: 0.00409641582518816\nStep: 550, epoch: 15.0\nStep: 551, loss/train: 0.004138492979109287\nStep: 551, epoch: 15.0\nStep: 552, loss/train: 0.004114874638617039\nStep: 552, epoch: 15.0\nStep: 553, loss/train: 0.004064885899424553\nStep: 553, epoch: 15.0\nStep: 554, loss/train: 0.004145858809351921\nStep: 554, epoch: 15.0\nStep: 555, loss/train: 0.00400646822527051\nStep: 555, epoch: 15.0\nStep: 556, loss/train: 0.004037441685795784\nStep: 556, epoch: 15.0\nStep: 557, loss/train: 0.004037803038954735\nStep: 557, epoch: 15.0\nStep: 558, loss/train: 0.004009197931736708\nStep: 558, epoch: 15.0\nStep: 559, loss/train: 0.0041335392743349075\nStep: 559, epoch: 15.0\nStep: 560, loss/train: 0.004040595144033432\nStep: 560, epoch: 15.0\nStep: 561, loss/train: 0.004132654517889023\nStep: 561, epoch: 15.0\nStep: 562, loss/train: 0.004019489511847496\nStep: 562, epoch: 15.0\nStep: 563, loss/train: 0.00403220672160387\nStep: 563, epoch: 15.0\nStep: 564, loss/train: 0.003993626683950424\nStep: 564, epoch: 15.0\nStep: 565, loss/train: 0.00403671246021986\nStep: 565, epoch: 15.0\nStep: 566, loss/train: 0.0039652264676988125\nStep: 566, epoch: 15.0\nStep: 567, loss/train: 0.003990545868873596\nStep: 567, epoch: 15.0\nStep: 568, loss/train: 0.004126320127397776\nStep: 568, epoch: 15.0\nStep: 569, loss/train: 0.0040892050601542\nStep: 569, epoch: 15.0\nStep: 570, loss/train: 0.003954690415412188\nStep: 570, epoch: 15.0\nStep: 571, loss/train: 0.0040035671554505825\nStep: 571, epoch: 15.0\nStep: 572, loss/train: 0.004013538360595703\nStep: 572, epoch: 15.0\nStep: 573, loss/train: 0.004039110615849495\nStep: 573, epoch: 15.0\nStep: 574, loss/train: 0.0039228228852152824\nStep: 574, epoch: 15.0\nStep: 575, loss/train: 0.004098973236978054\nStep: 575, epoch: 15.0\nStep: 575, loss/val: 0.0036712479777634144\nStep: 575, epoch: 15.0\nStep: 575, roc_auc: 0.9966298937797546\nStep: 575, opt_thresh: 0.004035475663840771\nStep: 575, metrics/tpr: 0.7596899271011353\nStep: 575, metrics/tnr: 0.8144611120223999\nStep: 575, metrics/mean: 0.7870755195617676\nStep: 575, epoch: 15.0\nStep: 576, loss/train: 0.003976087085902691\nStep: 576, epoch: 16.0\nStep: 577, loss/train: 0.003993531689047813\nStep: 577, epoch: 16.0\nStep: 578, loss/train: 0.004013027064502239\nStep: 578, epoch: 16.0\nStep: 579, loss/train: 0.003921171650290489\nStep: 579, epoch: 16.0\nStep: 580, loss/train: 0.0039016050286591053\nStep: 580, epoch: 16.0\nStep: 581, loss/train: 0.003898093244060874\nStep: 581, epoch: 16.0\nStep: 582, loss/train: 0.003907737787812948\nStep: 582, epoch: 16.0\nStep: 583, loss/train: 0.00392622034996748\nStep: 583, epoch: 16.0\nStep: 584, loss/train: 0.003958072047680616\nStep: 584, epoch: 16.0\nStep: 585, loss/train: 0.003979017026722431\nStep: 585, epoch: 16.0\nStep: 586, loss/train: 0.003939070273190737\nStep: 586, epoch: 16.0\nStep: 587, loss/train: 0.0039242347702383995\nStep: 587, epoch: 16.0\nStep: 588, loss/train: 0.0039025808218866587\nStep: 588, epoch: 16.0\nStep: 589, loss/train: 0.003852125722914934\nStep: 589, epoch: 16.0\nStep: 590, loss/train: 0.00393945537507534\nStep: 590, epoch: 16.0\nStep: 591, loss/train: 0.0038662999868392944\nStep: 591, epoch: 16.0\nStep: 592, loss/train: 0.003848064225167036\nStep: 592, epoch: 16.0\nStep: 593, loss/train: 0.00394577719271183\nStep: 593, epoch: 16.0\nStep: 594, loss/train: 0.003856442403048277\nStep: 594, epoch: 16.0\nStep: 595, loss/train: 0.0038958005607128143\nStep: 595, epoch: 16.0\nStep: 596, loss/train: 0.003912849351763725\nStep: 596, epoch: 16.0\nStep: 597, loss/train: 0.003912300802767277\nStep: 597, epoch: 16.0\nStep: 598, loss/train: 0.0038074960466474295\nStep: 598, epoch: 16.0\nStep: 599, loss/train: 0.003809656947851181\nStep: 599, epoch: 16.0\nStep: 600, loss/train: 0.0038450937718153\nStep: 600, epoch: 16.0\nStep: 601, loss/train: 0.0038089307490736246\nStep: 601, epoch: 16.0\nStep: 602, loss/train: 0.003861051984131336\nStep: 602, epoch: 16.0\nStep: 603, loss/train: 0.0038022827357053757\nStep: 603, epoch: 16.0\nStep: 604, loss/train: 0.003794577205553651\nStep: 604, epoch: 16.0\nStep: 605, loss/train: 0.0038358818273991346\nStep: 605, epoch: 16.0\nStep: 606, loss/train: 0.003923480398952961\nStep: 606, epoch: 16.0\nStep: 607, loss/train: 0.0037951129488646984\nStep: 607, epoch: 16.0\nStep: 608, loss/train: 0.0038369616959244013\nStep: 608, epoch: 16.0\nStep: 609, loss/train: 0.0038484930992126465\nStep: 609, epoch: 16.0\nStep: 610, loss/train: 0.0037932037375867367\nStep: 610, epoch: 16.0\nStep: 611, loss/train: 0.003916088026016951\nStep: 611, epoch: 16.0\nStep: 611, loss/val: 0.003542168065905571\nStep: 611, epoch: 16.0\nStep: 612, loss/train: 0.003836027579382062\nStep: 612, epoch: 17.0\nStep: 613, loss/train: 0.003725977847352624\nStep: 613, epoch: 17.0\nStep: 614, loss/train: 0.0037417886778712273\nStep: 614, epoch: 17.0\nStep: 615, loss/train: 0.0037940845359116793\nStep: 615, epoch: 17.0\nStep: 616, loss/train: 0.00388496951200068\nStep: 616, epoch: 17.0\nStep: 617, loss/train: 0.003860533470287919\nStep: 617, epoch: 17.0\nStep: 618, loss/train: 0.003758676815778017\nStep: 618, epoch: 17.0\nStep: 619, loss/train: 0.0038393079303205013\nStep: 619, epoch: 17.0\nStep: 620, loss/train: 0.0038072308525443077\nStep: 620, epoch: 17.0\nStep: 621, loss/train: 0.0037660016678273678\nStep: 621, epoch: 17.0\nStep: 622, loss/train: 0.003745842957869172\nStep: 622, epoch: 17.0\nStep: 623, loss/train: 0.0037049339152872562\nStep: 623, epoch: 17.0\nStep: 624, loss/train: 0.0037570190615952015\nStep: 624, epoch: 17.0\nStep: 625, loss/train: 0.0038707635831087828\nStep: 625, epoch: 17.0\nStep: 626, loss/train: 0.0037547762040048838\nStep: 626, epoch: 17.0\nStep: 627, loss/train: 0.0037540632765740156\nStep: 627, epoch: 17.0\nStep: 628, loss/train: 0.003753390396013856\nStep: 628, epoch: 17.0\nStep: 629, loss/train: 0.00373412249609828\nStep: 629, epoch: 17.0\nStep: 630, loss/train: 0.003681248752400279\nStep: 630, epoch: 17.0\nStep: 631, loss/train: 0.0037848791107535362\nStep: 631, epoch: 17.0\nStep: 632, loss/train: 0.0037396885454654694\nStep: 632, epoch: 17.0\nStep: 633, loss/train: 0.0037283431738615036\nStep: 633, epoch: 17.0\nStep: 634, loss/train: 0.003716421313583851\nStep: 634, epoch: 17.0\nStep: 635, loss/train: 0.0038048825226724148\nStep: 635, epoch: 17.0\nStep: 636, loss/train: 0.003701908513903618\nStep: 636, epoch: 17.0\nStep: 637, loss/train: 0.003742228727787733\nStep: 637, epoch: 17.0\nStep: 638, loss/train: 0.003719624597579241\nStep: 638, epoch: 17.0\nStep: 639, loss/train: 0.00378859112970531\nStep: 639, epoch: 17.0\nStep: 640, loss/train: 0.003663147334009409\nStep: 640, epoch: 17.0\nStep: 641, loss/train: 0.0036489167250692844\nStep: 641, epoch: 17.0\nStep: 642, loss/train: 0.0037226653657853603\nStep: 642, epoch: 17.0\nStep: 643, loss/train: 0.003679126501083374\nStep: 643, epoch: 17.0\nStep: 644, loss/train: 0.0037031297106295824\nStep: 644, epoch: 17.0\nStep: 645, loss/train: 0.003630991093814373\nStep: 645, epoch: 17.0\nStep: 646, loss/train: 0.0037042079493403435\nStep: 646, epoch: 17.0\nStep: 647, loss/train: 0.003581274300813675\nStep: 647, epoch: 17.0\nStep: 647, loss/val: 0.0034065255895256996\nStep: 647, epoch: 17.0\nStep: 648, loss/train: 0.0036477723624557257\nStep: 648, epoch: 18.0\nStep: 649, loss/train: 0.0037178145721554756\nStep: 649, epoch: 18.0\nStep: 650, loss/train: 0.003725618589669466\nStep: 650, epoch: 18.0\nStep: 651, loss/train: 0.0036305286921560764\nStep: 651, epoch: 18.0\nStep: 652, loss/train: 0.0036461285781115294\nStep: 652, epoch: 18.0\nStep: 653, loss/train: 0.003667141543701291\nStep: 653, epoch: 18.0\nStep: 654, loss/train: 0.0036368342116475105\nStep: 654, epoch: 18.0\nStep: 655, loss/train: 0.003670917823910713\nStep: 655, epoch: 18.0\nStep: 656, loss/train: 0.0036449283361434937\nStep: 656, epoch: 18.0\nStep: 657, loss/train: 0.0036116507835686207\nStep: 657, epoch: 18.0\nStep: 658, loss/train: 0.003631321480497718\nStep: 658, epoch: 18.0\nStep: 659, loss/train: 0.0036086770705878735\nStep: 659, epoch: 18.0\nStep: 660, loss/train: 0.003659461624920368\nStep: 660, epoch: 18.0\nStep: 661, loss/train: 0.0036268457770347595\nStep: 661, epoch: 18.0\nStep: 662, loss/train: 0.0036123222671449184\nStep: 662, epoch: 18.0\nStep: 663, loss/train: 0.0035912860184907913\nStep: 663, epoch: 18.0\nStep: 664, loss/train: 0.003582664765417576\nStep: 664, epoch: 18.0\nStep: 665, loss/train: 0.0036463774740695953\nStep: 665, epoch: 18.0\nStep: 666, loss/train: 0.003582959994673729\nStep: 666, epoch: 18.0\nStep: 667, loss/train: 0.003618056420236826\nStep: 667, epoch: 18.0\nStep: 668, loss/train: 0.003601787379011512\nStep: 668, epoch: 18.0\nStep: 669, loss/train: 0.0036339890211820602\nStep: 669, epoch: 18.0\nStep: 670, loss/train: 0.003598468843847513\nStep: 670, epoch: 18.0\nStep: 671, loss/train: 0.003575324546545744\nStep: 671, epoch: 18.0\nStep: 672, loss/train: 0.0036403280682861805\nStep: 672, epoch: 18.0\nStep: 673, loss/train: 0.003651109291240573\nStep: 673, epoch: 18.0\nStep: 674, loss/train: 0.0035765881184488535\nStep: 674, epoch: 18.0\nStep: 675, loss/train: 0.003585598897188902\nStep: 675, epoch: 18.0\nStep: 676, loss/train: 0.0035846782848238945\nStep: 676, epoch: 18.0\nStep: 677, loss/train: 0.0036253558937460184\nStep: 677, epoch: 18.0\nStep: 678, loss/train: 0.003669651923701167\nStep: 678, epoch: 18.0\nStep: 679, loss/train: 0.003536610398441553\nStep: 679, epoch: 18.0\nStep: 680, loss/train: 0.003653143299743533\nStep: 680, epoch: 18.0\nStep: 681, loss/train: 0.0035373668652027845\nStep: 681, epoch: 18.0\nStep: 682, loss/train: 0.0035272277891635895\nStep: 682, epoch: 18.0\nStep: 683, loss/train: 0.003474919591099024\nStep: 683, epoch: 18.0\nStep: 683, loss/val: 0.0033353876788169146\nStep: 683, epoch: 18.0\nStep: 684, loss/train: 0.00350856501609087\nStep: 684, epoch: 19.0\nStep: 685, loss/train: 0.0035606056917458773\nStep: 685, epoch: 19.0\nStep: 686, loss/train: 0.003507963614538312\nStep: 686, epoch: 19.0\nStep: 687, loss/train: 0.0035528189036995173\nStep: 687, epoch: 19.0\nStep: 688, loss/train: 0.003535400377586484\nStep: 688, epoch: 19.0\nStep: 689, loss/train: 0.003556490410119295\nStep: 689, epoch: 19.0\nStep: 690, loss/train: 0.003551570000126958\nStep: 690, epoch: 19.0\nStep: 691, loss/train: 0.003486358094960451\nStep: 691, epoch: 19.0\nStep: 692, loss/train: 0.0035559830721467733\nStep: 692, epoch: 19.0\nStep: 693, loss/train: 0.0034887397196143866\nStep: 693, epoch: 19.0\nStep: 694, loss/train: 0.003527785651385784\nStep: 694, epoch: 19.0\nStep: 695, loss/train: 0.0035541527904570103\nStep: 695, epoch: 19.0\nStep: 696, loss/train: 0.0034871785901486874\nStep: 696, epoch: 19.0\nStep: 697, loss/train: 0.003479356411844492\nStep: 697, epoch: 19.0\nStep: 698, loss/train: 0.0034445710480213165\nStep: 698, epoch: 19.0\nStep: 699, loss/train: 0.0035867681726813316\nStep: 699, epoch: 19.0\nStep: 700, loss/train: 0.003461895976215601\nStep: 700, epoch: 19.0\nStep: 701, loss/train: 0.003594642737880349\nStep: 701, epoch: 19.0\nStep: 702, loss/train: 0.0035505357664078474\nStep: 702, epoch: 19.0\nStep: 703, loss/train: 0.00349445384927094\nStep: 703, epoch: 19.0\nStep: 704, loss/train: 0.0034380201250314713\nStep: 704, epoch: 19.0\nStep: 705, loss/train: 0.0035889330320060253\nStep: 705, epoch: 19.0\nStep: 706, loss/train: 0.0034413947723805904\nStep: 706, epoch: 19.0\nStep: 707, loss/train: 0.0034342147409915924\nStep: 707, epoch: 19.0\nStep: 708, loss/train: 0.0034648615401238203\nStep: 708, epoch: 19.0\nStep: 709, loss/train: 0.0034385453909635544\nStep: 709, epoch: 19.0\nStep: 710, loss/train: 0.0034074026625603437\nStep: 710, epoch: 19.0\nStep: 711, loss/train: 0.003502612467855215\nStep: 711, epoch: 19.0\nStep: 712, loss/train: 0.0033845165744423866\nStep: 712, epoch: 19.0\nStep: 713, loss/train: 0.00344759039580822\nStep: 713, epoch: 19.0\nStep: 714, loss/train: 0.0034096394665539265\nStep: 714, epoch: 19.0\nStep: 715, loss/train: 0.003410958917811513\nStep: 715, epoch: 19.0\nStep: 716, loss/train: 0.003461496438831091\nStep: 716, epoch: 19.0\nStep: 717, loss/train: 0.0033621492329984903\nStep: 717, epoch: 19.0\nStep: 718, loss/train: 0.0033969013020396233\nStep: 718, epoch: 19.0\nStep: 719, loss/train: 0.0033749330323189497\nStep: 719, epoch: 19.0\nStep: 719, loss/val: 0.0031539401970803738\nStep: 719, epoch: 19.0\nStep: 720, loss/train: 0.0033664419315755367\nStep: 720, epoch: 20.0\nStep: 721, loss/train: 0.0033785426057875156\nStep: 721, epoch: 20.0\nStep: 722, loss/train: 0.0033746242988854647\nStep: 722, epoch: 20.0\nStep: 723, loss/train: 0.003378509311005473\nStep: 723, epoch: 20.0\nStep: 724, loss/train: 0.0033417758531868458\nStep: 724, epoch: 20.0\nStep: 725, loss/train: 0.003346215235069394\nStep: 725, epoch: 20.0\nStep: 726, loss/train: 0.003341164905577898\nStep: 726, epoch: 20.0\nStep: 727, loss/train: 0.0033442508429288864\nStep: 727, epoch: 20.0\nStep: 728, loss/train: 0.0033197158481925726\nStep: 728, epoch: 20.0\nStep: 729, loss/train: 0.0033256299793720245\nStep: 729, epoch: 20.0\nStep: 730, loss/train: 0.003357794601470232\nStep: 730, epoch: 20.0\nStep: 731, loss/train: 0.0033393208868801594\nStep: 731, epoch: 20.0\nStep: 732, loss/train: 0.00327326194383204\nStep: 732, epoch: 20.0\nStep: 733, loss/train: 0.003247658722102642\nStep: 733, epoch: 20.0\nStep: 734, loss/train: 0.003261175937950611\nStep: 734, epoch: 20.0\nStep: 735, loss/train: 0.0032793208956718445\nStep: 735, epoch: 20.0\nStep: 736, loss/train: 0.0033026353921741247\nStep: 736, epoch: 20.0\nStep: 737, loss/train: 0.0032552373595535755\nStep: 737, epoch: 20.0\nStep: 738, loss/train: 0.003244317602366209\nStep: 738, epoch: 20.0\nStep: 739, loss/train: 0.0032777045853435993\nStep: 739, epoch: 20.0\nStep: 740, loss/train: 0.0032661641016602516\nStep: 740, epoch: 20.0\nStep: 741, loss/train: 0.003214919939637184\nStep: 741, epoch: 20.0\nStep: 742, loss/train: 0.0032545053400099277\nStep: 742, epoch: 20.0\nStep: 743, loss/train: 0.0031872920226305723\nStep: 743, epoch: 20.0\nStep: 744, loss/train: 0.0033604202326387167\nStep: 744, epoch: 20.0\nStep: 745, loss/train: 0.0032958355732262135\nStep: 745, epoch: 20.0\nStep: 746, loss/train: 0.0032464400865137577\nStep: 746, epoch: 20.0\nStep: 747, loss/train: 0.0031805832404643297\nStep: 747, epoch: 20.0\nStep: 748, loss/train: 0.0032141460105776787\nStep: 748, epoch: 20.0\nStep: 749, loss/train: 0.003211711999028921\nStep: 749, epoch: 20.0\nStep: 750, loss/train: 0.003190868068486452\nStep: 750, epoch: 20.0\nStep: 751, loss/train: 0.003207226749509573\nStep: 751, epoch: 20.0\nStep: 752, loss/train: 0.003146817907691002\nStep: 752, epoch: 20.0\nStep: 753, loss/train: 0.003156198188662529\nStep: 753, epoch: 20.0\nStep: 754, loss/train: 0.0031978334300220013\nStep: 754, epoch: 20.0\nStep: 755, loss/train: 0.0033528655767440796\nStep: 755, epoch: 20.0\nStep: 755, loss/val: 0.002971121808513999\nStep: 755, epoch: 20.0\nStep: 755, roc_auc: 0.9964350461959839\nStep: 755, opt_thresh: 0.0032851346768438816\nStep: 755, metrics/tpr: 0.751937985420227\nStep: 755, metrics/tnr: 0.7754433751106262\nStep: 755, metrics/mean: 0.763690710067749\nStep: 755, epoch: 20.0\nStep: 756, loss/train: 0.003143169917166233\nStep: 756, epoch: 21.0\nStep: 757, loss/train: 0.00314549682661891\nStep: 757, epoch: 21.0\nStep: 758, loss/train: 0.0031237653456628323\nStep: 758, epoch: 21.0\nStep: 759, loss/train: 0.003105130512267351\nStep: 759, epoch: 21.0\nStep: 760, loss/train: 0.003133977996185422\nStep: 760, epoch: 21.0\nStep: 761, loss/train: 0.003124290145933628\nStep: 761, epoch: 21.0\nStep: 762, loss/train: 0.0030590728856623173\nStep: 762, epoch: 21.0\nStep: 763, loss/train: 0.003110072109848261\nStep: 763, epoch: 21.0\nStep: 764, loss/train: 0.00305331707932055\nStep: 764, epoch: 21.0\nStep: 765, loss/train: 0.00302716763690114\nStep: 765, epoch: 21.0\nStep: 766, loss/train: 0.003082531038671732\nStep: 766, epoch: 21.0\nStep: 767, loss/train: 0.003073005471378565\nStep: 767, epoch: 21.0\nStep: 768, loss/train: 0.0030375886708498\nStep: 768, epoch: 21.0\nStep: 769, loss/train: 0.0030659036710858345\nStep: 769, epoch: 21.0\nStep: 770, loss/train: 0.0030211242847144604\nStep: 770, epoch: 21.0\nStep: 771, loss/train: 0.0030374201014637947\nStep: 771, epoch: 21.0\nStep: 772, loss/train: 0.002980454359203577\nStep: 772, epoch: 21.0\nStep: 773, loss/train: 0.003056108020246029\nStep: 773, epoch: 21.0\nStep: 774, loss/train: 0.0029680083971470594\nStep: 774, epoch: 21.0\nStep: 775, loss/train: 0.0029654642567038536\nStep: 775, epoch: 21.0\nStep: 776, loss/train: 0.0030009993351995945\nStep: 776, epoch: 21.0\nStep: 777, loss/train: 0.002976856427267194\nStep: 777, epoch: 21.0\nStep: 778, loss/train: 0.0029232357628643513\nStep: 778, epoch: 21.0\nStep: 779, loss/train: 0.002918223151937127\nStep: 779, epoch: 21.0\nStep: 780, loss/train: 0.002949790097773075\nStep: 780, epoch: 21.0\nStep: 781, loss/train: 0.002951447619125247\nStep: 781, epoch: 21.0\nStep: 782, loss/train: 0.0029490452725440264\nStep: 782, epoch: 21.0\nStep: 783, loss/train: 0.002878537168726325\nStep: 783, epoch: 21.0\nStep: 784, loss/train: 0.002863306552171707\nStep: 784, epoch: 21.0\nStep: 785, loss/train: 0.002914904151111841\nStep: 785, epoch: 21.0\nStep: 786, loss/train: 0.002848049858585\nStep: 786, epoch: 21.0\nStep: 787, loss/train: 0.0028875498101115227\nStep: 787, epoch: 21.0\nStep: 788, loss/train: 0.002881673164665699\nStep: 788, epoch: 21.0\nStep: 789, loss/train: 0.002839993219822645\nStep: 789, epoch: 21.0\nStep: 790, loss/train: 0.002818548120558262\nStep: 790, epoch: 21.0\nStep: 791, loss/train: 0.002849683864042163\nStep: 791, epoch: 21.0\nStep: 791, loss/val: 0.0026133365463465452\nStep: 791, epoch: 21.0\nStep: 792, loss/train: 0.002984458114951849\nStep: 792, epoch: 22.0\nStep: 793, loss/train: 0.0028916033916175365\nStep: 793, epoch: 22.0\nStep: 794, loss/train: 0.002772204577922821\nStep: 794, epoch: 22.0\nStep: 795, loss/train: 0.002754097105935216\nStep: 795, epoch: 22.0\nStep: 796, loss/train: 0.0028071608394384384\nStep: 796, epoch: 22.0\nStep: 797, loss/train: 0.0027706073597073555\nStep: 797, epoch: 22.0\nStep: 798, loss/train: 0.002850757911801338\nStep: 798, epoch: 22.0\nStep: 799, loss/train: 0.002813988830894232\nStep: 799, epoch: 22.0\nStep: 800, loss/train: 0.002751403022557497\nStep: 800, epoch: 22.0\nStep: 801, loss/train: 0.002848327159881592\nStep: 801, epoch: 22.0\nStep: 802, loss/train: 0.002841259352862835\nStep: 802, epoch: 22.0\nStep: 803, loss/train: 0.002770032500848174\nStep: 803, epoch: 22.0\nStep: 804, loss/train: 0.0027709114365279675\nStep: 804, epoch: 22.0\nStep: 805, loss/train: 0.002758423797786236\nStep: 805, epoch: 22.0\nStep: 806, loss/train: 0.0027460537385195494\nStep: 806, epoch: 22.0\nStep: 807, loss/train: 0.0027293029706925154\nStep: 807, epoch: 22.0\nStep: 808, loss/train: 0.0027217338792979717\nStep: 808, epoch: 22.0\nStep: 809, loss/train: 0.00271819275803864\nStep: 809, epoch: 22.0\nStep: 810, loss/train: 0.002707404550164938\nStep: 810, epoch: 22.0\nStep: 811, loss/train: 0.0026820171624422073\nStep: 811, epoch: 22.0\nStep: 812, loss/train: 0.0027135261334478855\nStep: 812, epoch: 22.0\nStep: 813, loss/train: 0.0026980750262737274\nStep: 813, epoch: 22.0\nStep: 814, loss/train: 0.0026721954345703125\nStep: 814, epoch: 22.0\nStep: 815, loss/train: 0.002723025158047676\nStep: 815, epoch: 22.0\nStep: 816, loss/train: 0.00267778430134058\nStep: 816, epoch: 22.0\nStep: 817, loss/train: 0.0027033996302634478\nStep: 817, epoch: 22.0\nStep: 818, loss/train: 0.0026467861607670784\nStep: 818, epoch: 22.0\nStep: 819, loss/train: 0.0026821624487638474\nStep: 819, epoch: 22.0\nStep: 820, loss/train: 0.0027159638702869415\nStep: 820, epoch: 22.0\nStep: 821, loss/train: 0.002681134268641472\nStep: 821, epoch: 22.0\nStep: 822, loss/train: 0.0026610861532390118\nStep: 822, epoch: 22.0\nStep: 823, loss/train: 0.0026264702901244164\nStep: 823, epoch: 22.0\nStep: 824, loss/train: 0.0026981905102729797\nStep: 824, epoch: 22.0\nStep: 825, loss/train: 0.0027249527629464865\nStep: 825, epoch: 22.0\nStep: 826, loss/train: 0.002680981531739235\nStep: 826, epoch: 22.0\nStep: 827, loss/train: 0.002956822281703353\nStep: 827, epoch: 22.0\nStep: 827, loss/val: 0.002480414928868413\nStep: 827, epoch: 22.0\nStep: 828, loss/train: 0.0026116434019058943\nStep: 828, epoch: 23.0\nStep: 829, loss/train: 0.0026404722593724728\nStep: 829, epoch: 23.0\nStep: 830, loss/train: 0.002687745029106736\nStep: 830, epoch: 23.0\nStep: 831, loss/train: 0.002657270058989525\nStep: 831, epoch: 23.0\nStep: 832, loss/train: 0.00261174445040524\nStep: 832, epoch: 23.0\nStep: 833, loss/train: 0.002702743746340275\nStep: 833, epoch: 23.0\nStep: 834, loss/train: 0.0026243964675813913\nStep: 834, epoch: 23.0\nStep: 835, loss/train: 0.00259453896433115\nStep: 835, epoch: 23.0\nStep: 836, loss/train: 0.0026862043887376785\nStep: 836, epoch: 23.0\nStep: 837, loss/train: 0.0026108049787580967\nStep: 837, epoch: 23.0\nStep: 838, loss/train: 0.002579551888629794\nStep: 838, epoch: 23.0\nStep: 839, loss/train: 0.002594398334622383\nStep: 839, epoch: 23.0\nStep: 840, loss/train: 0.002630861708894372\nStep: 840, epoch: 23.0\nStep: 841, loss/train: 0.0026602456346154213\nStep: 841, epoch: 23.0\nStep: 842, loss/train: 0.002573728561401367\nStep: 842, epoch: 23.0\nStep: 843, loss/train: 0.0025869719684123993\nStep: 843, epoch: 23.0\nStep: 844, loss/train: 0.0027023525908589363\nStep: 844, epoch: 23.0\nStep: 845, loss/train: 0.002568538999184966\nStep: 845, epoch: 23.0\nStep: 846, loss/train: 0.002585975220426917\nStep: 846, epoch: 23.0\nStep: 847, loss/train: 0.002567056566476822\nStep: 847, epoch: 23.0\nStep: 848, loss/train: 0.00265196873806417\nStep: 848, epoch: 23.0\nStep: 849, loss/train: 0.0025695995427668095\nStep: 849, epoch: 23.0\nStep: 850, loss/train: 0.002621521009132266\nStep: 850, epoch: 23.0\nStep: 851, loss/train: 0.002630493137985468\nStep: 851, epoch: 23.0\nStep: 852, loss/train: 0.0025206776335835457\nStep: 852, epoch: 23.0\nStep: 853, loss/train: 0.002609080169349909\nStep: 853, epoch: 23.0\nStep: 854, loss/train: 0.002515083644539118\nStep: 854, epoch: 23.0\nStep: 855, loss/train: 0.002552440157160163\nStep: 855, epoch: 23.0\nStep: 856, loss/train: 0.002564255613833666\nStep: 856, epoch: 23.0\nStep: 857, loss/train: 0.0025612139143049717\nStep: 857, epoch: 23.0\nStep: 858, loss/train: 0.0025868364609777927\nStep: 858, epoch: 23.0\nStep: 859, loss/train: 0.0025048134848475456\nStep: 859, epoch: 23.0\nStep: 860, loss/train: 0.0025582925882190466\nStep: 860, epoch: 23.0\nStep: 861, loss/train: 0.0026386671233922243\nStep: 861, epoch: 23.0\nStep: 862, loss/train: 0.0025654176715761423\nStep: 862, epoch: 23.0\nStep: 863, loss/train: 0.0025952502619475126\nStep: 863, epoch: 23.0\nStep: 863, loss/val: 0.0023609166964888573\nStep: 863, epoch: 23.0\nStep: 864, loss/train: 0.0025609282311052084\nStep: 864, epoch: 24.0\nStep: 865, loss/train: 0.002513738814741373\nStep: 865, epoch: 24.0\nStep: 866, loss/train: 0.0025542378425598145\nStep: 866, epoch: 24.0\nStep: 867, loss/train: 0.0025219349190592766\nStep: 867, epoch: 24.0\nStep: 868, loss/train: 0.0025347680784761906\nStep: 868, epoch: 24.0\nStep: 869, loss/train: 0.0025006267242133617\nStep: 869, epoch: 24.0\nStep: 870, loss/train: 0.00263098138384521\nStep: 870, epoch: 24.0\nStep: 871, loss/train: 0.0025574977044016123\nStep: 871, epoch: 24.0\nStep: 872, loss/train: 0.002523512113839388\nStep: 872, epoch: 24.0\nStep: 873, loss/train: 0.0025271661579608917\nStep: 873, epoch: 24.0\nStep: 874, loss/train: 0.0025291540659964085\nStep: 874, epoch: 24.0\nStep: 875, loss/train: 0.0025278839748352766\nStep: 875, epoch: 24.0\nStep: 876, loss/train: 0.002477997215464711\nStep: 876, epoch: 24.0\nStep: 877, loss/train: 0.0025936353486031294\nStep: 877, epoch: 24.0\nStep: 878, loss/train: 0.0024988616351038218\nStep: 878, epoch: 24.0\nStep: 879, loss/train: 0.002491077408194542\nStep: 879, epoch: 24.0\nStep: 880, loss/train: 0.0024774360936135054\nStep: 880, epoch: 24.0\nStep: 881, loss/train: 0.0024667703546583652\nStep: 881, epoch: 24.0\nStep: 882, loss/train: 0.0025496110320091248\nStep: 882, epoch: 24.0\nStep: 883, loss/train: 0.002459199633449316\nStep: 883, epoch: 24.0\nStep: 884, loss/train: 0.002493223175406456\nStep: 884, epoch: 24.0\nStep: 885, loss/train: 0.00244521745480597\nStep: 885, epoch: 24.0\nStep: 886, loss/train: 0.0024289218708872795\nStep: 886, epoch: 24.0\nStep: 887, loss/train: 0.002437991090118885\nStep: 887, epoch: 24.0\nStep: 888, loss/train: 0.002437341958284378\nStep: 888, epoch: 24.0\nStep: 889, loss/train: 0.0024230489507317543\nStep: 889, epoch: 24.0\nStep: 890, loss/train: 0.002508424688130617\nStep: 890, epoch: 24.0\nStep: 891, loss/train: 0.002437395742163062\nStep: 891, epoch: 24.0\nStep: 892, loss/train: 0.0025154780596494675\nStep: 892, epoch: 24.0\nStep: 893, loss/train: 0.002407459542155266\nStep: 893, epoch: 24.0\nStep: 894, loss/train: 0.0024195900186896324\nStep: 894, epoch: 24.0\nStep: 895, loss/train: 0.002464116085320711\nStep: 895, epoch: 24.0\nStep: 896, loss/train: 0.0024260603822767735\nStep: 896, epoch: 24.0\nStep: 897, loss/train: 0.0024486060719937086\nStep: 897, epoch: 24.0\nStep: 898, loss/train: 0.002468548249453306\nStep: 898, epoch: 24.0\nStep: 899, loss/train: 0.0028161059599369764\nStep: 899, epoch: 24.0\nStep: 899, loss/val: 0.0022695502266287804\nStep: 899, epoch: 24.0\nStep: 900, loss/train: 0.0025139651261270046\nStep: 900, epoch: 25.0\nStep: 901, loss/train: 0.0024284678511321545\nStep: 901, epoch: 25.0\nStep: 902, loss/train: 0.0023891394957900047\nStep: 902, epoch: 25.0\nStep: 903, loss/train: 0.0024083948228508234\nStep: 903, epoch: 25.0\nStep: 904, loss/train: 0.0024156467989087105\nStep: 904, epoch: 25.0\nStep: 905, loss/train: 0.0024069547653198242\nStep: 905, epoch: 25.0\nStep: 906, loss/train: 0.0024070898070931435\nStep: 906, epoch: 25.0\nStep: 907, loss/train: 0.002463975688442588\nStep: 907, epoch: 25.0\nStep: 908, loss/train: 0.0024338739458471537\nStep: 908, epoch: 25.0\nStep: 909, loss/train: 0.0023754374124109745\nStep: 909, epoch: 25.0\nStep: 910, loss/train: 0.002367178676649928\nStep: 910, epoch: 25.0\nStep: 911, loss/train: 0.002387567888945341\nStep: 911, epoch: 25.0\nStep: 912, loss/train: 0.0024078856222331524\nStep: 912, epoch: 25.0\nStep: 913, loss/train: 0.0023464569821953773\nStep: 913, epoch: 25.0\nStep: 914, loss/train: 0.002353132236748934\nStep: 914, epoch: 25.0\nStep: 915, loss/train: 0.0023488765582442284\nStep: 915, epoch: 25.0\nStep: 916, loss/train: 0.002387278014793992\nStep: 916, epoch: 25.0\nStep: 917, loss/train: 0.0023636494297534227\nStep: 917, epoch: 25.0\nStep: 918, loss/train: 0.002389480359852314\nStep: 918, epoch: 25.0\nStep: 919, loss/train: 0.002400718629360199\nStep: 919, epoch: 25.0\nStep: 920, loss/train: 0.0023335281293839216\nStep: 920, epoch: 25.0\nStep: 921, loss/train: 0.0023557492531836033\nStep: 921, epoch: 25.0\nStep: 922, loss/train: 0.0023237757850438356\nStep: 922, epoch: 25.0\nStep: 923, loss/train: 0.0023310366086661816\nStep: 923, epoch: 25.0\nStep: 924, loss/train: 0.002376632299274206\nStep: 924, epoch: 25.0\nStep: 925, loss/train: 0.002352739218622446\nStep: 925, epoch: 25.0\nStep: 926, loss/train: 0.0023192022927105427\nStep: 926, epoch: 25.0\nStep: 927, loss/train: 0.002331070601940155\nStep: 927, epoch: 25.0\nStep: 928, loss/train: 0.0023238868452608585\nStep: 928, epoch: 25.0\nStep: 929, loss/train: 0.0023096674121916294\nStep: 929, epoch: 25.0\nStep: 930, loss/train: 0.0023367388639599085\nStep: 930, epoch: 25.0\nStep: 931, loss/train: 0.002379879355430603\nStep: 931, epoch: 25.0\nStep: 932, loss/train: 0.0023128939792513847\nStep: 932, epoch: 25.0\nStep: 933, loss/train: 0.002286746632307768\nStep: 933, epoch: 25.0\nStep: 934, loss/train: 0.002336968434974551\nStep: 934, epoch: 25.0\nStep: 935, loss/train: 0.00226958142593503\nStep: 935, epoch: 25.0\nStep: 935, loss/val: 0.0021119259763509035\nStep: 935, epoch: 25.0\nStep: 935, roc_auc: 0.9966428279876709\nStep: 935, opt_thresh: 0.002329582115635276\nStep: 935, metrics/tpr: 0.7596899271011353\nStep: 935, metrics/tnr: 0.7773533463478088\nStep: 935, metrics/mean: 0.7685216069221497\nStep: 935, epoch: 25.0\nStep: 936, loss/train: 0.002310719806700945\nStep: 936, epoch: 26.0\nStep: 937, loss/train: 0.0023061027750372887\nStep: 937, epoch: 26.0\nStep: 938, loss/train: 0.0023614636156708\nStep: 938, epoch: 26.0\nStep: 939, loss/train: 0.0022834278643131256\nStep: 939, epoch: 26.0\nStep: 940, loss/train: 0.002266866620630026\nStep: 940, epoch: 26.0\nStep: 941, loss/train: 0.002266940660774708\nStep: 941, epoch: 26.0\nStep: 942, loss/train: 0.0022913855500519276\nStep: 942, epoch: 26.0\nStep: 943, loss/train: 0.0023081237450242043\nStep: 943, epoch: 26.0\nStep: 944, loss/train: 0.0023705337662249804\nStep: 944, epoch: 26.0\nStep: 945, loss/train: 0.002261563204228878\nStep: 945, epoch: 26.0\nStep: 946, loss/train: 0.002280002925544977\nStep: 946, epoch: 26.0\nStep: 947, loss/train: 0.002262537134811282\nStep: 947, epoch: 26.0\nStep: 948, loss/train: 0.0023246738128364086\nStep: 948, epoch: 26.0\nStep: 949, loss/train: 0.0022841712925583124\nStep: 949, epoch: 26.0\nStep: 950, loss/train: 0.002254289574921131\nStep: 950, epoch: 26.0\nStep: 951, loss/train: 0.0022547300904989243\nStep: 951, epoch: 26.0\nStep: 952, loss/train: 0.002296162536367774\nStep: 952, epoch: 26.0\nStep: 953, loss/train: 0.00223055062815547\nStep: 953, epoch: 26.0\nStep: 954, loss/train: 0.0022215668577700853\nStep: 954, epoch: 26.0\nStep: 955, loss/train: 0.0022410815581679344\nStep: 955, epoch: 26.0\nStep: 956, loss/train: 0.002219625748693943\nStep: 956, epoch: 26.0\nStep: 957, loss/train: 0.0022181628737598658\nStep: 957, epoch: 26.0\nStep: 958, loss/train: 0.0022083637304604053\nStep: 958, epoch: 26.0\nStep: 959, loss/train: 0.0022085988894104958\nStep: 959, epoch: 26.0\nStep: 960, loss/train: 0.0021855419036000967\nStep: 960, epoch: 26.0\nStep: 961, loss/train: 0.0022329078055918217\nStep: 961, epoch: 26.0\nStep: 962, loss/train: 0.0022118231281638145\nStep: 962, epoch: 26.0\nStep: 963, loss/train: 0.0022099476773291826\nStep: 963, epoch: 26.0\nStep: 964, loss/train: 0.0021866639144718647\nStep: 964, epoch: 26.0\nStep: 965, loss/train: 0.0021730661392211914\nStep: 965, epoch: 26.0\nStep: 966, loss/train: 0.0021785064600408077\nStep: 966, epoch: 26.0\nStep: 967, loss/train: 0.002188941463828087\nStep: 967, epoch: 26.0\nStep: 968, loss/train: 0.0022065136581659317\nStep: 968, epoch: 26.0\nStep: 969, loss/train: 0.0021460899151861668\nStep: 969, epoch: 26.0\nStep: 970, loss/train: 0.00225613615475595\nStep: 970, epoch: 26.0\nStep: 971, loss/train: 0.0021276422776281834\nStep: 971, epoch: 26.0\nStep: 971, loss/val: 0.0019773582462221384\nStep: 971, epoch: 26.0\nStep: 972, loss/train: 0.0021962400060147047\nStep: 972, epoch: 27.0\nStep: 973, loss/train: 0.0021444191224873066\nStep: 973, epoch: 27.0\nStep: 974, loss/train: 0.0022414212580770254\nStep: 974, epoch: 27.0\nStep: 975, loss/train: 0.002148228231817484\nStep: 975, epoch: 27.0\nStep: 976, loss/train: 0.0022077139001339674\nStep: 976, epoch: 27.0\nStep: 977, loss/train: 0.002190893981605768\nStep: 977, epoch: 27.0\nStep: 978, loss/train: 0.0021342732943594456\nStep: 978, epoch: 27.0\nStep: 979, loss/train: 0.0021335093770176172\nStep: 979, epoch: 27.0\nStep: 980, loss/train: 0.002106410451233387\nStep: 980, epoch: 27.0\nStep: 981, loss/train: 0.0021046639885753393\nStep: 981, epoch: 27.0\nStep: 982, loss/train: 0.002110864967107773\nStep: 982, epoch: 27.0\nStep: 983, loss/train: 0.0021185229998081923\nStep: 983, epoch: 27.0\nStep: 984, loss/train: 0.002117014955729246\nStep: 984, epoch: 27.0\nStep: 985, loss/train: 0.0021937491837888956\nStep: 985, epoch: 27.0\nStep: 986, loss/train: 0.002115947660058737\nStep: 986, epoch: 27.0\nStep: 987, loss/train: 0.0020826123654842377\nStep: 987, epoch: 27.0\nStep: 988, loss/train: 0.0020937963854521513\nStep: 988, epoch: 27.0\nStep: 989, loss/train: 0.002058926038444042\nStep: 989, epoch: 27.0\nStep: 990, loss/train: 0.0020592999644577503\nStep: 990, epoch: 27.0\nStep: 991, loss/train: 0.002067029010504484\nStep: 991, epoch: 27.0\nStep: 992, loss/train: 0.002087417058646679\nStep: 992, epoch: 27.0\nStep: 993, loss/train: 0.0020810095593333244\nStep: 993, epoch: 27.0\nStep: 994, loss/train: 0.0020545534789562225\nStep: 994, epoch: 27.0\nStep: 995, loss/train: 0.002057923236861825\nStep: 995, epoch: 27.0\nStep: 996, loss/train: 0.002058781683444977\nStep: 996, epoch: 27.0\nStep: 997, loss/train: 0.0021145720966160297\nStep: 997, epoch: 27.0\nStep: 998, loss/train: 0.002034025965258479\nStep: 998, epoch: 27.0\nStep: 999, loss/train: 0.0020910240709781647\nStep: 999, epoch: 27.0\nStep: 1000, loss/train: 0.002021919470280409\nStep: 1000, epoch: 27.0\nStep: 1001, loss/train: 0.0020674054976552725\nStep: 1001, epoch: 27.0\nStep: 1002, loss/train: 0.002015783917158842\nStep: 1002, epoch: 27.0\nStep: 1003, loss/train: 0.0020336525049060583\nStep: 1003, epoch: 27.0\nStep: 1004, loss/train: 0.002048903377726674\nStep: 1004, epoch: 27.0\nStep: 1005, loss/train: 0.0020171282812952995\nStep: 1005, epoch: 27.0\nStep: 1006, loss/train: 0.002021763939410448\nStep: 1006, epoch: 27.0\nStep: 1007, loss/train: 0.0020061384420841932\nStep: 1007, epoch: 27.0\nStep: 1007, loss/val: 0.0018327129073441029\nStep: 1007, epoch: 27.0\nStep: 1008, loss/train: 0.002011955715715885\nStep: 1008, epoch: 28.0\nStep: 1009, loss/train: 0.002043346641585231\nStep: 1009, epoch: 28.0\nStep: 1010, loss/train: 0.002038791310042143\nStep: 1010, epoch: 28.0\nStep: 1011, loss/train: 0.002035002689808607\nStep: 1011, epoch: 28.0\nStep: 1012, loss/train: 0.0020290801767259836\nStep: 1012, epoch: 28.0\nStep: 1013, loss/train: 0.002097093965858221\nStep: 1013, epoch: 28.0\nStep: 1014, loss/train: 0.002032926771789789\nStep: 1014, epoch: 28.0\nStep: 1015, loss/train: 0.001983454916626215\nStep: 1015, epoch: 28.0\nStep: 1016, loss/train: 0.0020290385000407696\nStep: 1016, epoch: 28.0\nStep: 1017, loss/train: 0.002079155994579196\nStep: 1017, epoch: 28.0\nStep: 1018, loss/train: 0.001971874153241515\nStep: 1018, epoch: 28.0\nStep: 1019, loss/train: 0.0019666184671223164\nStep: 1019, epoch: 28.0\nStep: 1020, loss/train: 0.001984347589313984\nStep: 1020, epoch: 28.0\nStep: 1021, loss/train: 0.001994771184399724\nStep: 1021, epoch: 28.0\nStep: 1022, loss/train: 0.001989108044654131\nStep: 1022, epoch: 28.0\nStep: 1023, loss/train: 0.001983206020668149\nStep: 1023, epoch: 28.0\nStep: 1024, loss/train: 0.002038141479715705\nStep: 1024, epoch: 28.0\nStep: 1025, loss/train: 0.0019749985076487064\nStep: 1025, epoch: 28.0\nStep: 1026, loss/train: 0.0019986960105597973\nStep: 1026, epoch: 28.0\nStep: 1027, loss/train: 0.0019488490652292967\nStep: 1027, epoch: 28.0\nStep: 1028, loss/train: 0.0020330166444182396\nStep: 1028, epoch: 28.0\nStep: 1029, loss/train: 0.0019660997204482555\nStep: 1029, epoch: 28.0\nStep: 1030, loss/train: 0.00196235254406929\nStep: 1030, epoch: 28.0\nStep: 1031, loss/train: 0.0020402809605002403\nStep: 1031, epoch: 28.0\nStep: 1032, loss/train: 0.0020430446602404118\nStep: 1032, epoch: 28.0\nStep: 1033, loss/train: 0.0019874735735356808\nStep: 1033, epoch: 28.0\nStep: 1034, loss/train: 0.001962261740118265\nStep: 1034, epoch: 28.0\nStep: 1035, loss/train: 0.0019597774371504784\nStep: 1035, epoch: 28.0\nStep: 1036, loss/train: 0.002025672234594822\nStep: 1036, epoch: 28.0\nStep: 1037, loss/train: 0.001959830056875944\nStep: 1037, epoch: 28.0\nStep: 1038, loss/train: 0.0019529389683157206\nStep: 1038, epoch: 28.0\nStep: 1039, loss/train: 0.0019407263025641441\nStep: 1039, epoch: 28.0\nStep: 1040, loss/train: 0.0019261629786342382\nStep: 1040, epoch: 28.0\nStep: 1041, loss/train: 0.001921239192597568\nStep: 1041, epoch: 28.0\nStep: 1042, loss/train: 0.00195349776186049\nStep: 1042, epoch: 28.0\nStep: 1043, loss/train: 0.002166095422580838\nStep: 1043, epoch: 28.0\nStep: 1043, loss/val: 0.0017916385550051928\nStep: 1043, epoch: 28.0\nStep: 1044, loss/train: 0.001957779750227928\nStep: 1044, epoch: 29.0\nStep: 1045, loss/train: 0.0019537373445928097\nStep: 1045, epoch: 29.0\nStep: 1046, loss/train: 0.0019415966235101223\nStep: 1046, epoch: 29.0\nStep: 1047, loss/train: 0.0019719202537089586\nStep: 1047, epoch: 29.0\nStep: 1048, loss/train: 0.0019414550624787807\nStep: 1048, epoch: 29.0\nStep: 1049, loss/train: 0.0019541785586625338\nStep: 1049, epoch: 29.0\nStep: 1050, loss/train: 0.0019290801137685776\nStep: 1050, epoch: 29.0\nStep: 1051, loss/train: 0.0019184682751074433\nStep: 1051, epoch: 29.0\nStep: 1052, loss/train: 0.0019947823602706194\nStep: 1052, epoch: 29.0\nStep: 1053, loss/train: 0.002009589457884431\nStep: 1053, epoch: 29.0\nStep: 1054, loss/train: 0.001991980243474245\nStep: 1054, epoch: 29.0\nStep: 1055, loss/train: 0.0019415270071476698\nStep: 1055, epoch: 29.0\nStep: 1056, loss/train: 0.0019152082968503237\nStep: 1056, epoch: 29.0\nStep: 1057, loss/train: 0.0019190897000953555\nStep: 1057, epoch: 29.0\nStep: 1058, loss/train: 0.0018994146957993507\nStep: 1058, epoch: 29.0\nStep: 1059, loss/train: 0.001935087377205491\nStep: 1059, epoch: 29.0\nStep: 1060, loss/train: 0.0019205035641789436\nStep: 1060, epoch: 29.0\nStep: 1061, loss/train: 0.0018955713603645563\nStep: 1061, epoch: 29.0\nStep: 1062, loss/train: 0.0019437042064964771\nStep: 1062, epoch: 29.0\nStep: 1063, loss/train: 0.0019255499355494976\nStep: 1063, epoch: 29.0\nStep: 1064, loss/train: 0.0019273721845820546\nStep: 1064, epoch: 29.0\nStep: 1065, loss/train: 0.001918519614264369\nStep: 1065, epoch: 29.0\nStep: 1066, loss/train: 0.0018948046490550041\nStep: 1066, epoch: 29.0\nStep: 1067, loss/train: 0.0019961060024797916\nStep: 1067, epoch: 29.0\nStep: 1068, loss/train: 0.001895169960334897\nStep: 1068, epoch: 29.0\nStep: 1069, loss/train: 0.001926326658576727\nStep: 1069, epoch: 29.0\nStep: 1070, loss/train: 0.0019221811089664698\nStep: 1070, epoch: 29.0\nStep: 1071, loss/train: 0.0018930489895865321\nStep: 1071, epoch: 29.0\nStep: 1072, loss/train: 0.0018864605808630586\nStep: 1072, epoch: 29.0\nStep: 1073, loss/train: 0.0019366012420505285\nStep: 1073, epoch: 29.0\nStep: 1074, loss/train: 0.0019041183404624462\nStep: 1074, epoch: 29.0\nStep: 1075, loss/train: 0.0019008663948625326\nStep: 1075, epoch: 29.0\nStep: 1076, loss/train: 0.0019059230107814074\nStep: 1076, epoch: 29.0\nStep: 1077, loss/train: 0.0018836181843653321\nStep: 1077, epoch: 29.0\nStep: 1078, loss/train: 0.0019024325301870704\nStep: 1078, epoch: 29.0\nStep: 1079, loss/train: 0.0019444769714027643\nStep: 1079, epoch: 29.0\nStep: 1079, loss/val: 0.001719264080747962\nStep: 1079, epoch: 29.0\nStep: 1080, loss/train: 0.0018768318695947528\nStep: 1080, epoch: 30.0\nStep: 1081, loss/train: 0.0019389644730836153\nStep: 1081, epoch: 30.0\nStep: 1082, loss/train: 0.0019048342946916819\nStep: 1082, epoch: 30.0\nStep: 1083, loss/train: 0.0019222642295062542\nStep: 1083, epoch: 30.0\nStep: 1084, loss/train: 0.0018855424132198095\nStep: 1084, epoch: 30.0\nStep: 1085, loss/train: 0.0019047108944505453\nStep: 1085, epoch: 30.0\nStep: 1086, loss/train: 0.0019294586963951588\nStep: 1086, epoch: 30.0\nStep: 1087, loss/train: 0.0019045963417738676\nStep: 1087, epoch: 30.0\nStep: 1088, loss/train: 0.001884078374132514\nStep: 1088, epoch: 30.0\nStep: 1089, loss/train: 0.0018836543895304203\nStep: 1089, epoch: 30.0\nStep: 1090, loss/train: 0.001873876666650176\nStep: 1090, epoch: 30.0\nStep: 1091, loss/train: 0.001867865677922964\nStep: 1091, epoch: 30.0\nStep: 1092, loss/train: 0.0018972542602568865\nStep: 1092, epoch: 30.0\nStep: 1093, loss/train: 0.0018874749075621367\nStep: 1093, epoch: 30.0\nStep: 1094, loss/train: 0.0018744140397757292\nStep: 1094, epoch: 30.0\nStep: 1095, loss/train: 0.001902429386973381\nStep: 1095, epoch: 30.0\nStep: 1096, loss/train: 0.001873185858130455\nStep: 1096, epoch: 30.0\nStep: 1097, loss/train: 0.001864854246377945\nStep: 1097, epoch: 30.0\nStep: 1098, loss/train: 0.0018832627683877945\nStep: 1098, epoch: 30.0\nStep: 1099, loss/train: 0.0018756514182314277\nStep: 1099, epoch: 30.0\nStep: 1100, loss/train: 0.0018609333783388138\nStep: 1100, epoch: 30.0\nStep: 1101, loss/train: 0.0018732543103396893\nStep: 1101, epoch: 30.0\nStep: 1102, loss/train: 0.0018947725184261799\nStep: 1102, epoch: 30.0\nStep: 1103, loss/train: 0.0018508224748075008\nStep: 1103, epoch: 30.0\nStep: 1104, loss/train: 0.0018574295099824667\nStep: 1104, epoch: 30.0\nStep: 1105, loss/train: 0.0018647541292011738\nStep: 1105, epoch: 30.0\nStep: 1106, loss/train: 0.0018562679179012775\nStep: 1106, epoch: 30.0\nStep: 1107, loss/train: 0.0018441840074956417\nStep: 1107, epoch: 30.0\nStep: 1108, loss/train: 0.001864931546151638\nStep: 1108, epoch: 30.0\nStep: 1109, loss/train: 0.001849679509177804\nStep: 1109, epoch: 30.0\nStep: 1110, loss/train: 0.001866113394498825\nStep: 1110, epoch: 30.0\nStep: 1111, loss/train: 0.001854871865361929\nStep: 1111, epoch: 30.0\nStep: 1112, loss/train: 0.001891063991934061\nStep: 1112, epoch: 30.0\nStep: 1113, loss/train: 0.0018794918432831764\nStep: 1113, epoch: 30.0\nStep: 1114, loss/train: 0.0018730403389781713\nStep: 1114, epoch: 30.0\nStep: 1115, loss/train: 0.00193367141764611\nStep: 1115, epoch: 30.0\nStep: 1115, loss/val: 0.0016849744133651257\nStep: 1115, epoch: 30.0\nStep: 1115, roc_auc: 0.9970389604568481\nStep: 1115, opt_thresh: 0.0018768770387396216\nStep: 1115, metrics/tpr: 0.7751938104629517\nStep: 1115, metrics/tnr: 0.8701227903366089\nStep: 1115, metrics/mean: 0.8226583003997803\nStep: 1115, epoch: 30.0\nStep: 1116, loss/train: 0.001878501963801682\nStep: 1116, epoch: 31.0\nStep: 1117, loss/train: 0.0018375267973169684\nStep: 1117, epoch: 31.0\nStep: 1118, loss/train: 0.0018604544457048178\nStep: 1118, epoch: 31.0\nStep: 1119, loss/train: 0.0018953689141198993\nStep: 1119, epoch: 31.0\nStep: 1120, loss/train: 0.0018380277324467897\nStep: 1120, epoch: 31.0\nStep: 1121, loss/train: 0.001847152365371585\nStep: 1121, epoch: 31.0\nStep: 1122, loss/train: 0.0018488477217033505\nStep: 1122, epoch: 31.0\nStep: 1123, loss/train: 0.0018578872550278902\nStep: 1123, epoch: 31.0\nStep: 1124, loss/train: 0.001854040427133441\nStep: 1124, epoch: 31.0\nStep: 1125, loss/train: 0.001867041690275073\nStep: 1125, epoch: 31.0\nStep: 1126, loss/train: 0.0018473351374268532\nStep: 1126, epoch: 31.0\nStep: 1127, loss/train: 0.0018432904034852982\nStep: 1127, epoch: 31.0\nStep: 1128, loss/train: 0.0018651876598596573\nStep: 1128, epoch: 31.0\nStep: 1129, loss/train: 0.0018762536346912384\nStep: 1129, epoch: 31.0\nStep: 1130, loss/train: 0.0018782656406983733\nStep: 1130, epoch: 31.0\nStep: 1131, loss/train: 0.001848468091338873\nStep: 1131, epoch: 31.0\nStep: 1132, loss/train: 0.0018752827309072018\nStep: 1132, epoch: 31.0\nStep: 1133, loss/train: 0.0018842166755348444\nStep: 1133, epoch: 31.0\nStep: 1134, loss/train: 0.0018393193604424596\nStep: 1134, epoch: 31.0\nStep: 1135, loss/train: 0.0018639989430084825\nStep: 1135, epoch: 31.0\nStep: 1136, loss/train: 0.0018725430127233267\nStep: 1136, epoch: 31.0\nStep: 1137, loss/train: 0.0018505952320992947\nStep: 1137, epoch: 31.0\nStep: 1138, loss/train: 0.0018511642701923847\nStep: 1138, epoch: 31.0\nStep: 1139, loss/train: 0.0018327763536944985\nStep: 1139, epoch: 31.0\nStep: 1140, loss/train: 0.0018299093935638666\nStep: 1140, epoch: 31.0\nStep: 1141, loss/train: 0.0018267016857862473\nStep: 1141, epoch: 31.0\nStep: 1142, loss/train: 0.0018276805058121681\nStep: 1142, epoch: 31.0\nStep: 1143, loss/train: 0.0018617953173816204\nStep: 1143, epoch: 31.0\nStep: 1144, loss/train: 0.0018461181316524744\nStep: 1144, epoch: 31.0\nStep: 1145, loss/train: 0.0018241319339722395\nStep: 1145, epoch: 31.0\nStep: 1146, loss/train: 0.0018602644558995962\nStep: 1146, epoch: 31.0\nStep: 1147, loss/train: 0.0018713359022513032\nStep: 1147, epoch: 31.0\nStep: 1148, loss/train: 0.0018440511776134372\nStep: 1148, epoch: 31.0\nStep: 1149, loss/train: 0.0018497809069231153\nStep: 1149, epoch: 31.0\nStep: 1150, loss/train: 0.001910647377371788\nStep: 1150, epoch: 31.0\nStep: 1151, loss/train: 0.0019417315488681197\nStep: 1151, epoch: 31.0\nStep: 1151, loss/val: 0.001705835573375225\nStep: 1151, epoch: 31.0\nStep: 1152, loss/train: 0.0018236287869513035\nStep: 1152, epoch: 32.0\nStep: 1153, loss/train: 0.001820695586502552\nStep: 1153, epoch: 32.0\nStep: 1154, loss/train: 0.0018290632870048285\nStep: 1154, epoch: 32.0\nStep: 1155, loss/train: 0.0018682582303881645\nStep: 1155, epoch: 32.0\nStep: 1156, loss/train: 0.001837405376136303\nStep: 1156, epoch: 32.0\nStep: 1157, loss/train: 0.001801804406568408\nStep: 1157, epoch: 32.0\nStep: 1158, loss/train: 0.0018173697171732783\nStep: 1158, epoch: 32.0\nStep: 1159, loss/train: 0.0018177216406911612\nStep: 1159, epoch: 32.0\nStep: 1160, loss/train: 0.0018337041838094592\nStep: 1160, epoch: 32.0\nStep: 1161, loss/train: 0.0018275612965226173\nStep: 1161, epoch: 32.0\nStep: 1162, loss/train: 0.001826312392950058\nStep: 1162, epoch: 32.0\nStep: 1163, loss/train: 0.0018700661603361368\nStep: 1163, epoch: 32.0\nStep: 1164, loss/train: 0.0018398643005639315\nStep: 1164, epoch: 32.0\nStep: 1165, loss/train: 0.0018174670403823256\nStep: 1165, epoch: 32.0\nStep: 1166, loss/train: 0.0018302322132512927\nStep: 1166, epoch: 32.0\nStep: 1167, loss/train: 0.0018506592605262995\nStep: 1167, epoch: 32.0\nStep: 1168, loss/train: 0.0018411207711324096\nStep: 1168, epoch: 32.0\nStep: 1169, loss/train: 0.0018275455804541707\nStep: 1169, epoch: 32.0\nStep: 1170, loss/train: 0.0018141537439078093\nStep: 1170, epoch: 32.0\nStep: 1171, loss/train: 0.0018892297521233559\nStep: 1171, epoch: 32.0\nStep: 1172, loss/train: 0.0018135607242584229\nStep: 1172, epoch: 32.0\nStep: 1173, loss/train: 0.0018097867723554373\nStep: 1173, epoch: 32.0\nStep: 1174, loss/train: 0.001821363577619195\nStep: 1174, epoch: 32.0\nStep: 1175, loss/train: 0.0018238639459013939\nStep: 1175, epoch: 32.0\nStep: 1176, loss/train: 0.0018371896585449576\nStep: 1176, epoch: 32.0\nStep: 1177, loss/train: 0.001807691529393196\nStep: 1177, epoch: 32.0\nStep: 1178, loss/train: 0.0018414093647152185\nStep: 1178, epoch: 32.0\nStep: 1179, loss/train: 0.0018098850268870592\nStep: 1179, epoch: 32.0\nStep: 1180, loss/train: 0.0018188618123531342\nStep: 1180, epoch: 32.0\nStep: 1181, loss/train: 0.0018025555182248354\nStep: 1181, epoch: 32.0\nStep: 1182, loss/train: 0.0018233524169772863\nStep: 1182, epoch: 32.0\nStep: 1183, loss/train: 0.0018338323570787907\nStep: 1183, epoch: 32.0\nStep: 1184, loss/train: 0.0017963321879506111\nStep: 1184, epoch: 32.0\nStep: 1185, loss/train: 0.001807557768188417\nStep: 1185, epoch: 32.0\nStep: 1186, loss/train: 0.0018066642805933952\nStep: 1186, epoch: 32.0\nStep: 1187, loss/train: 0.001892408006824553\nStep: 1187, epoch: 32.0\nStep: 1187, loss/val: 0.0016453969292342663\nStep: 1187, epoch: 32.0\nStep: 1188, loss/train: 0.0017873171018436551\nStep: 1188, epoch: 33.0\nStep: 1189, loss/train: 0.001842303667217493\nStep: 1189, epoch: 33.0\nStep: 1190, loss/train: 0.0018362232949584723\nStep: 1190, epoch: 33.0\nStep: 1191, loss/train: 0.001846053171902895\nStep: 1191, epoch: 33.0\nStep: 1192, loss/train: 0.001792676281183958\nStep: 1192, epoch: 33.0\nStep: 1193, loss/train: 0.0017982886638492346\nStep: 1193, epoch: 33.0\nStep: 1194, loss/train: 0.0018406230956315994\nStep: 1194, epoch: 33.0\nStep: 1195, loss/train: 0.0018117029685527086\nStep: 1195, epoch: 33.0\nStep: 1196, loss/train: 0.0018073911778628826\nStep: 1196, epoch: 33.0\nStep: 1197, loss/train: 0.0018538031727075577\nStep: 1197, epoch: 33.0\nStep: 1198, loss/train: 0.0018467578338459134\nStep: 1198, epoch: 33.0\nStep: 1199, loss/train: 0.0018146035727113485\nStep: 1199, epoch: 33.0\nStep: 1200, loss/train: 0.0017962503479793668\nStep: 1200, epoch: 33.0\nStep: 1201, loss/train: 0.0018955980194732547\nStep: 1201, epoch: 33.0\nStep: 1202, loss/train: 0.0018125280039384961\nStep: 1202, epoch: 33.0\nStep: 1203, loss/train: 0.0017932381015270948\nStep: 1203, epoch: 33.0\nStep: 1204, loss/train: 0.0018465786706656218\nStep: 1204, epoch: 33.0\nStep: 1205, loss/train: 0.0018172934651374817\nStep: 1205, epoch: 33.0\nStep: 1206, loss/train: 0.0018896372057497501\nStep: 1206, epoch: 33.0\nStep: 1207, loss/train: 0.0018103311304003\nStep: 1207, epoch: 33.0\nStep: 1208, loss/train: 0.0018010265193879604\nStep: 1208, epoch: 33.0\nStep: 1209, loss/train: 0.0018052825471386313\nStep: 1209, epoch: 33.0\nStep: 1210, loss/train: 0.0018092095851898193\nStep: 1210, epoch: 33.0\nStep: 1211, loss/train: 0.001852292800322175\nStep: 1211, epoch: 33.0\nStep: 1212, loss/train: 0.0017915747594088316\nStep: 1212, epoch: 33.0\nStep: 1213, loss/train: 0.0018266548868268728\nStep: 1213, epoch: 33.0\nStep: 1214, loss/train: 0.0018178366590291262\nStep: 1214, epoch: 33.0\nStep: 1215, loss/train: 0.00177924451418221\nStep: 1215, epoch: 33.0\nStep: 1216, loss/train: 0.0017863473622128367\nStep: 1216, epoch: 33.0\nStep: 1217, loss/train: 0.001791556365787983\nStep: 1217, epoch: 33.0\nStep: 1218, loss/train: 0.0018025117460638285\nStep: 1218, epoch: 33.0\nStep: 1219, loss/train: 0.0018020260613411665\nStep: 1219, epoch: 33.0\nStep: 1220, loss/train: 0.0018141670152544975\nStep: 1220, epoch: 33.0\nStep: 1221, loss/train: 0.001785236643627286\nStep: 1221, epoch: 33.0\nStep: 1222, loss/train: 0.0018105404451489449\nStep: 1222, epoch: 33.0\nStep: 1223, loss/train: 0.002012193202972412\nStep: 1223, epoch: 33.0\nStep: 1223, loss/val: 0.0016722133150324225\nStep: 1223, epoch: 33.0\nStep: 1224, loss/train: 0.0017783904913812876\nStep: 1224, epoch: 34.0\nStep: 1225, loss/train: 0.0018130149692296982\nStep: 1225, epoch: 34.0\nStep: 1226, loss/train: 0.0017837011255323887\nStep: 1226, epoch: 34.0\nStep: 1227, loss/train: 0.0017735077999532223\nStep: 1227, epoch: 34.0\nStep: 1228, loss/train: 0.0018354215426370502\nStep: 1228, epoch: 34.0\nStep: 1229, loss/train: 0.0017937873490154743\nStep: 1229, epoch: 34.0\nStep: 1230, loss/train: 0.0018048175843432546\nStep: 1230, epoch: 34.0\nStep: 1231, loss/train: 0.001773799885995686\nStep: 1231, epoch: 34.0\nStep: 1232, loss/train: 0.0018336486537009478\nStep: 1232, epoch: 34.0\nStep: 1233, loss/train: 0.0017726407386362553\nStep: 1233, epoch: 34.0\nStep: 1234, loss/train: 0.001765522756613791\nStep: 1234, epoch: 34.0\nStep: 1235, loss/train: 0.001815672148950398\nStep: 1235, epoch: 34.0\nStep: 1236, loss/train: 0.001806854736059904\nStep: 1236, epoch: 34.0\nStep: 1237, loss/train: 0.0017866597045212984\nStep: 1237, epoch: 34.0\nStep: 1238, loss/train: 0.0017909714952111244\nStep: 1238, epoch: 34.0\nStep: 1239, loss/train: 0.0017977372044697404\nStep: 1239, epoch: 34.0\nStep: 1240, loss/train: 0.0018030689097940922\nStep: 1240, epoch: 34.0\nStep: 1241, loss/train: 0.0017733534332364798\nStep: 1241, epoch: 34.0\nStep: 1242, loss/train: 0.001769638736732304\nStep: 1242, epoch: 34.0\nStep: 1243, loss/train: 0.0017700742464512587\nStep: 1243, epoch: 34.0\nStep: 1244, loss/train: 0.0017996190581470728\nStep: 1244, epoch: 34.0\nStep: 1245, loss/train: 0.0017990416381508112\nStep: 1245, epoch: 34.0\nStep: 1246, loss/train: 0.0017736513400450349\nStep: 1246, epoch: 34.0\nStep: 1247, loss/train: 0.0017660974990576506\nStep: 1247, epoch: 34.0\nStep: 1248, loss/train: 0.0017746284138411283\nStep: 1248, epoch: 34.0\nStep: 1249, loss/train: 0.0017841029912233353\nStep: 1249, epoch: 34.0\nStep: 1250, loss/train: 0.001780334860086441\nStep: 1250, epoch: 34.0\nStep: 1251, loss/train: 0.0018168101087212563\nStep: 1251, epoch: 34.0\nStep: 1252, loss/train: 0.0017764884978532791\nStep: 1252, epoch: 34.0\nStep: 1253, loss/train: 0.001819770084694028\nStep: 1253, epoch: 34.0\nStep: 1254, loss/train: 0.0017776868771761656\nStep: 1254, epoch: 34.0\nStep: 1255, loss/train: 0.0018058978021144867\nStep: 1255, epoch: 34.0\nStep: 1256, loss/train: 0.0017726196674630046\nStep: 1256, epoch: 34.0\nStep: 1257, loss/train: 0.0017619191203266382\nStep: 1257, epoch: 34.0\nStep: 1258, loss/train: 0.0017856271006166935\nStep: 1258, epoch: 34.0\nStep: 1259, loss/train: 0.0018330225721001625\nStep: 1259, epoch: 34.0\nStep: 1259, loss/val: 0.0016410048119723797\nStep: 1259, epoch: 34.0\nStep: 1260, loss/train: 0.0017657347489148378\nStep: 1260, epoch: 35.0\nStep: 1261, loss/train: 0.0018370477482676506\nStep: 1261, epoch: 35.0\nStep: 1262, loss/train: 0.0017572756623849273\nStep: 1262, epoch: 35.0\nStep: 1263, loss/train: 0.0017788046970963478\nStep: 1263, epoch: 35.0\nStep: 1264, loss/train: 0.0017681366298347712\nStep: 1264, epoch: 35.0\nStep: 1265, loss/train: 0.0017692097462713718\nStep: 1265, epoch: 35.0\nStep: 1266, loss/train: 0.0017600215505808592\nStep: 1266, epoch: 35.0\nStep: 1267, loss/train: 0.001777940196916461\nStep: 1267, epoch: 35.0\nStep: 1268, loss/train: 0.001856552087701857\nStep: 1268, epoch: 35.0\nStep: 1269, loss/train: 0.0017598719568923116\nStep: 1269, epoch: 35.0\nStep: 1270, loss/train: 0.0017580479616299272\nStep: 1270, epoch: 35.0\nStep: 1271, loss/train: 0.0017595605459064245\nStep: 1271, epoch: 35.0\nStep: 1272, loss/train: 0.0017687384970486164\nStep: 1272, epoch: 35.0\nStep: 1273, loss/train: 0.0017604883760213852\nStep: 1273, epoch: 35.0\nStep: 1274, loss/train: 0.001771477865986526\nStep: 1274, epoch: 35.0\nStep: 1275, loss/train: 0.0017762776697054505\nStep: 1275, epoch: 35.0\nStep: 1276, loss/train: 0.0017597435507923365\nStep: 1276, epoch: 35.0\nStep: 1277, loss/train: 0.0017914214404299855\nStep: 1277, epoch: 35.0\nStep: 1278, loss/train: 0.001747624482959509\nStep: 1278, epoch: 35.0\nStep: 1279, loss/train: 0.001753304386511445\nStep: 1279, epoch: 35.0\nStep: 1280, loss/train: 0.0017641232116147876\nStep: 1280, epoch: 35.0\nStep: 1281, loss/train: 0.0017540636472404003\nStep: 1281, epoch: 35.0\nStep: 1282, loss/train: 0.001762108295224607\nStep: 1282, epoch: 35.0\nStep: 1283, loss/train: 0.0017627206398174167\nStep: 1283, epoch: 35.0\nStep: 1284, loss/train: 0.0018397844396531582\nStep: 1284, epoch: 35.0\nStep: 1285, loss/train: 0.00176769751124084\nStep: 1285, epoch: 35.0\nStep: 1286, loss/train: 0.0017489383462816477\nStep: 1286, epoch: 35.0\nStep: 1287, loss/train: 0.0017921753460541368\nStep: 1287, epoch: 35.0\nStep: 1288, loss/train: 0.0017696256982162595\nStep: 1288, epoch: 35.0\nStep: 1289, loss/train: 0.0017575861420482397\nStep: 1289, epoch: 35.0\nStep: 1290, loss/train: 0.0018453069496899843\nStep: 1290, epoch: 35.0\nStep: 1291, loss/train: 0.0017579331761226058\nStep: 1291, epoch: 35.0\nStep: 1292, loss/train: 0.0017624904867261648\nStep: 1292, epoch: 35.0\nStep: 1293, loss/train: 0.0017491624457761645\nStep: 1293, epoch: 35.0\nStep: 1294, loss/train: 0.0017720961477607489\nStep: 1294, epoch: 35.0\nStep: 1295, loss/train: 0.0017450841842219234\nStep: 1295, epoch: 35.0\nStep: 1295, loss/val: 0.0016298193950206041\nStep: 1295, epoch: 35.0\nStep: 1295, roc_auc: 0.9970584511756897\nStep: 1295, opt_thresh: 0.0017835535109043121\nStep: 1295, metrics/tpr: 0.7596899271011353\nStep: 1295, metrics/tnr: 0.8499317765235901\nStep: 1295, metrics/mean: 0.8048108816146851\nStep: 1295, epoch: 35.0\nStep: 1296, loss/train: 0.0018029870698228478\nStep: 1296, epoch: 36.0\nStep: 1297, loss/train: 0.0017650530207902193\nStep: 1297, epoch: 36.0\nStep: 1298, loss/train: 0.0017637819983065128\nStep: 1298, epoch: 36.0\nStep: 1299, loss/train: 0.0017696924041956663\nStep: 1299, epoch: 36.0\nStep: 1300, loss/train: 0.0017564703011885285\nStep: 1300, epoch: 36.0\nStep: 1301, loss/train: 0.0017671918030828238\nStep: 1301, epoch: 36.0\nStep: 1302, loss/train: 0.0017713699489831924\nStep: 1302, epoch: 36.0\nStep: 1303, loss/train: 0.0017779105110093951\nStep: 1303, epoch: 36.0\nStep: 1304, loss/train: 0.0017446024576202035\nStep: 1304, epoch: 36.0\nStep: 1305, loss/train: 0.0017835346516221762\nStep: 1305, epoch: 36.0\nStep: 1306, loss/train: 0.0017571590142324567\nStep: 1306, epoch: 36.0\nStep: 1307, loss/train: 0.0017652744427323341\nStep: 1307, epoch: 36.0\nStep: 1308, loss/train: 0.0017484736163169146\nStep: 1308, epoch: 36.0\nStep: 1309, loss/train: 0.0017742716008797288\nStep: 1309, epoch: 36.0\nStep: 1310, loss/train: 0.001741745974868536\nStep: 1310, epoch: 36.0\nStep: 1311, loss/train: 0.0017942574340850115\nStep: 1311, epoch: 36.0\nStep: 1312, loss/train: 0.0017375464085489511\nStep: 1312, epoch: 36.0\nStep: 1313, loss/train: 0.0017756070010364056\nStep: 1313, epoch: 36.0\nStep: 1314, loss/train: 0.0017673789989203215\nStep: 1314, epoch: 36.0\nStep: 1315, loss/train: 0.0017519493121653795\nStep: 1315, epoch: 36.0\nStep: 1316, loss/train: 0.0017765650991350412\nStep: 1316, epoch: 36.0\nStep: 1317, loss/train: 0.0017463148105889559\nStep: 1317, epoch: 36.0\nStep: 1318, loss/train: 0.0017367061227560043\nStep: 1318, epoch: 36.0\nStep: 1319, loss/train: 0.0017651614034548402\nStep: 1319, epoch: 36.0\nStep: 1320, loss/train: 0.00174032524228096\nStep: 1320, epoch: 36.0\nStep: 1321, loss/train: 0.0017346283420920372\nStep: 1321, epoch: 36.0\nStep: 1322, loss/train: 0.0017483506817370653\nStep: 1322, epoch: 36.0\nStep: 1323, loss/train: 0.0017343182116746902\nStep: 1323, epoch: 36.0\nStep: 1324, loss/train: 0.0017479474190622568\nStep: 1324, epoch: 36.0\nStep: 1325, loss/train: 0.0017622539307922125\nStep: 1325, epoch: 36.0\nStep: 1326, loss/train: 0.0017274855636060238\nStep: 1326, epoch: 36.0\nStep: 1327, loss/train: 0.001731516094878316\nStep: 1327, epoch: 36.0\nStep: 1328, loss/train: 0.0017269875388592482\nStep: 1328, epoch: 36.0\nStep: 1329, loss/train: 0.001735122874379158\nStep: 1329, epoch: 36.0\nStep: 1330, loss/train: 0.00174669548869133\nStep: 1330, epoch: 36.0\nStep: 1331, loss/train: 0.0018645016243681312\nStep: 1331, epoch: 36.0\nStep: 1331, loss/val: 0.0016056388849392533\nStep: 1331, epoch: 36.0\nStep: 1332, loss/train: 0.0017417579656466842\nStep: 1332, epoch: 37.0\nStep: 1333, loss/train: 0.0017415694892406464\nStep: 1333, epoch: 37.0\nStep: 1334, loss/train: 0.0017420349176973104\nStep: 1334, epoch: 37.0\nStep: 1335, loss/train: 0.0017345056403428316\nStep: 1335, epoch: 37.0\nStep: 1336, loss/train: 0.0017514718929305673\nStep: 1336, epoch: 37.0\nStep: 1337, loss/train: 0.0017363236984238029\nStep: 1337, epoch: 37.0\nStep: 1338, loss/train: 0.0017307905945926905\nStep: 1338, epoch: 37.0\nStep: 1339, loss/train: 0.0017375536262989044\nStep: 1339, epoch: 37.0\nStep: 1340, loss/train: 0.0017290061805397272\nStep: 1340, epoch: 37.0\nStep: 1341, loss/train: 0.0017205809708684683\nStep: 1341, epoch: 37.0\nStep: 1342, loss/train: 0.0017581997672095895\nStep: 1342, epoch: 37.0\nStep: 1343, loss/train: 0.0017325732624158263\nStep: 1343, epoch: 37.0\nStep: 1344, loss/train: 0.001747166272252798\nStep: 1344, epoch: 37.0\nStep: 1345, loss/train: 0.001800022553652525\nStep: 1345, epoch: 37.0\nStep: 1346, loss/train: 0.0017267420189455152\nStep: 1346, epoch: 37.0\nStep: 1347, loss/train: 0.0017390139400959015\nStep: 1347, epoch: 37.0\nStep: 1348, loss/train: 0.0017336324090138078\nStep: 1348, epoch: 37.0\nStep: 1349, loss/train: 0.0017589927883818746\nStep: 1349, epoch: 37.0\nStep: 1350, loss/train: 0.00172419601585716\nStep: 1350, epoch: 37.0\nStep: 1351, loss/train: 0.001761148450896144\nStep: 1351, epoch: 37.0\nStep: 1352, loss/train: 0.0017298676539212465\nStep: 1352, epoch: 37.0\nStep: 1353, loss/train: 0.001771985786035657\nStep: 1353, epoch: 37.0\nStep: 1354, loss/train: 0.0017561584245413542\nStep: 1354, epoch: 37.0\nStep: 1355, loss/train: 0.0017707068473100662\nStep: 1355, epoch: 37.0\nStep: 1356, loss/train: 0.0018177743768319488\nStep: 1356, epoch: 37.0\nStep: 1357, loss/train: 0.0017527866875752807\nStep: 1357, epoch: 37.0\nStep: 1358, loss/train: 0.0017201440641656518\nStep: 1358, epoch: 37.0\nStep: 1359, loss/train: 0.0017342512728646398\nStep: 1359, epoch: 37.0\nStep: 1360, loss/train: 0.0017291216645389795\nStep: 1360, epoch: 37.0\nStep: 1361, loss/train: 0.0017299021128565073\nStep: 1361, epoch: 37.0\nStep: 1362, loss/train: 0.0017288841772824526\nStep: 1362, epoch: 37.0\nStep: 1363, loss/train: 0.0017394651658833027\nStep: 1363, epoch: 37.0\nStep: 1364, loss/train: 0.001730877673253417\nStep: 1364, epoch: 37.0\nStep: 1365, loss/train: 0.0017444975674152374\nStep: 1365, epoch: 37.0\nStep: 1366, loss/train: 0.0017165010794997215\nStep: 1366, epoch: 37.0\nStep: 1367, loss/train: 0.001811360940337181\nStep: 1367, epoch: 37.0\nStep: 1367, loss/val: 0.001613255706615746\nStep: 1367, epoch: 37.0\nStep: 1368, loss/train: 0.0017566564492881298\nStep: 1368, epoch: 38.0\nStep: 1369, loss/train: 0.001733699580654502\nStep: 1369, epoch: 38.0\nStep: 1370, loss/train: 0.0017439981456845999\nStep: 1370, epoch: 38.0\nStep: 1371, loss/train: 0.0017347971443086863\nStep: 1371, epoch: 38.0\nStep: 1372, loss/train: 0.0017317382153123617\nStep: 1372, epoch: 38.0\nStep: 1373, loss/train: 0.001737350132316351\nStep: 1373, epoch: 38.0\nStep: 1374, loss/train: 0.0017480708193033934\nStep: 1374, epoch: 38.0\nStep: 1375, loss/train: 0.001717861508950591\nStep: 1375, epoch: 38.0\nStep: 1376, loss/train: 0.0017289711395278573\nStep: 1376, epoch: 38.0\nStep: 1377, loss/train: 0.0017326512606814504\nStep: 1377, epoch: 38.0\nStep: 1378, loss/train: 0.0017275256104767323\nStep: 1378, epoch: 38.0\nStep: 1379, loss/train: 0.0017366546671837568\nStep: 1379, epoch: 38.0\nStep: 1380, loss/train: 0.0017348455730825663\nStep: 1380, epoch: 38.0\nStep: 1381, loss/train: 0.0017013087635859847\nStep: 1381, epoch: 38.0\nStep: 1382, loss/train: 0.0017166135367006063\nStep: 1382, epoch: 38.0\nStep: 1383, loss/train: 0.0017597228288650513\nStep: 1383, epoch: 38.0\nStep: 1384, loss/train: 0.0017223646864295006\nStep: 1384, epoch: 38.0\nStep: 1385, loss/train: 0.0017172559164464474\nStep: 1385, epoch: 38.0\nStep: 1386, loss/train: 0.0017098496900871396\nStep: 1386, epoch: 38.0\nStep: 1387, loss/train: 0.001750369556248188\nStep: 1387, epoch: 38.0\nStep: 1388, loss/train: 0.0017078034579753876\nStep: 1388, epoch: 38.0\nStep: 1389, loss/train: 0.0017343552317470312\nStep: 1389, epoch: 38.0\nStep: 1390, loss/train: 0.0018440124113112688\nStep: 1390, epoch: 38.0\nStep: 1391, loss/train: 0.0017541702836751938\nStep: 1391, epoch: 38.0\nStep: 1392, loss/train: 0.0017958494136109948\nStep: 1392, epoch: 38.0\nStep: 1393, loss/train: 0.001716105965897441\nStep: 1393, epoch: 38.0\nStep: 1394, loss/train: 0.0017168011981993914\nStep: 1394, epoch: 38.0\nStep: 1395, loss/train: 0.0017043659463524818\nStep: 1395, epoch: 38.0\nStep: 1396, loss/train: 0.001803367049433291\nStep: 1396, epoch: 38.0\nStep: 1397, loss/train: 0.0017236790154129267\nStep: 1397, epoch: 38.0\nStep: 1398, loss/train: 0.0017161526484414935\nStep: 1398, epoch: 38.0\nStep: 1399, loss/train: 0.0017096855444833636\nStep: 1399, epoch: 38.0\nStep: 1400, loss/train: 0.0017068411689251661\nStep: 1400, epoch: 38.0\nStep: 1401, loss/train: 0.0017135308589786291\nStep: 1401, epoch: 38.0\nStep: 1402, loss/train: 0.0017432051245123148\nStep: 1402, epoch: 38.0\nStep: 1403, loss/train: 0.0017515007639303803\nStep: 1403, epoch: 38.0\nStep: 1403, loss/val: 0.001600716495886445\nStep: 1403, epoch: 38.0\nStep: 1404, loss/train: 0.0017106325831264257\nStep: 1404, epoch: 39.0\nStep: 1405, loss/train: 0.0017242119647562504\nStep: 1405, epoch: 39.0\nStep: 1406, loss/train: 0.0017035456839948893\nStep: 1406, epoch: 39.0\nStep: 1407, loss/train: 0.0017355225281789899\nStep: 1407, epoch: 39.0\nStep: 1408, loss/train: 0.0017191874794661999\nStep: 1408, epoch: 39.0\nStep: 1409, loss/train: 0.0017413608729839325\nStep: 1409, epoch: 39.0\nStep: 1410, loss/train: 0.0017045075073838234\nStep: 1410, epoch: 39.0\nStep: 1411, loss/train: 0.001714917365461588\nStep: 1411, epoch: 39.0\nStep: 1412, loss/train: 0.0017402864759787917\nStep: 1412, epoch: 39.0\nStep: 1413, loss/train: 0.0017015128396451473\nStep: 1413, epoch: 39.0\nStep: 1414, loss/train: 0.0017116072122007608\nStep: 1414, epoch: 39.0\nStep: 1415, loss/train: 0.0017512066988274455\nStep: 1415, epoch: 39.0\nStep: 1416, loss/train: 0.0017079940298572183\nStep: 1416, epoch: 39.0\nStep: 1417, loss/train: 0.0017109642503783107\nStep: 1417, epoch: 39.0\nStep: 1418, loss/train: 0.0017215427942574024\nStep: 1418, epoch: 39.0\nStep: 1419, loss/train: 0.0017168867634609342\nStep: 1419, epoch: 39.0\nStep: 1420, loss/train: 0.0017051242757588625\nStep: 1420, epoch: 39.0\nStep: 1421, loss/train: 0.0017129265470430255\nStep: 1421, epoch: 39.0\nStep: 1422, loss/train: 0.0017083443235605955\nStep: 1422, epoch: 39.0\nStep: 1423, loss/train: 0.0017691348912194371\nStep: 1423, epoch: 39.0\nStep: 1424, loss/train: 0.0016983437817543745\nStep: 1424, epoch: 39.0\nStep: 1425, loss/train: 0.0017038362566381693\nStep: 1425, epoch: 39.0\nStep: 1426, loss/train: 0.0017469516023993492\nStep: 1426, epoch: 39.0\nStep: 1427, loss/train: 0.0017279207240790129\nStep: 1427, epoch: 39.0\nStep: 1428, loss/train: 0.0017051587346941233\nStep: 1428, epoch: 39.0\nStep: 1429, loss/train: 0.0017484233248978853\nStep: 1429, epoch: 39.0\nStep: 1430, loss/train: 0.0016946087125688791\nStep: 1430, epoch: 39.0\nStep: 1431, loss/train: 0.0017238517757505178\nStep: 1431, epoch: 39.0\nStep: 1432, loss/train: 0.0016973610036075115\nStep: 1432, epoch: 39.0\nStep: 1433, loss/train: 0.00174008309841156\nStep: 1433, epoch: 39.0\nStep: 1434, loss/train: 0.0017166296020150185\nStep: 1434, epoch: 39.0\nStep: 1435, loss/train: 0.0016945410752668977\nStep: 1435, epoch: 39.0\nStep: 1436, loss/train: 0.0017051087925210595\nStep: 1436, epoch: 39.0\nStep: 1437, loss/train: 0.0016965399263426661\nStep: 1437, epoch: 39.0\nStep: 1438, loss/train: 0.0016947875265032053\nStep: 1438, epoch: 39.0\nStep: 1439, loss/train: 0.0016989194555208087\nStep: 1439, epoch: 39.0\nStep: 1439, loss/val: 0.0015735680935904384\nStep: 1439, epoch: 39.0\nStep: 1440, loss/train: 0.0017067627049982548\nStep: 1440, epoch: 40.0\nStep: 1441, loss/train: 0.0016897231107577682\nStep: 1441, epoch: 40.0\nStep: 1442, loss/train: 0.001707020914182067\nStep: 1442, epoch: 40.0\nStep: 1443, loss/train: 0.001702386187389493\nStep: 1443, epoch: 40.0\nStep: 1444, loss/train: 0.001696931547485292\nStep: 1444, epoch: 40.0\nStep: 1445, loss/train: 0.001696996041573584\nStep: 1445, epoch: 40.0\nStep: 1446, loss/train: 0.001713082892820239\nStep: 1446, epoch: 40.0\nStep: 1447, loss/train: 0.0017312746495008469\nStep: 1447, epoch: 40.0\nStep: 1448, loss/train: 0.0017173243686556816\nStep: 1448, epoch: 40.0\nStep: 1449, loss/train: 0.0016937532927840948\nStep: 1449, epoch: 40.0\nStep: 1450, loss/train: 0.001706794835627079\nStep: 1450, epoch: 40.0\nStep: 1451, loss/train: 0.0016979756765067577\nStep: 1451, epoch: 40.0\nStep: 1452, loss/train: 0.001684362767264247\nStep: 1452, epoch: 40.0\nStep: 1453, loss/train: 0.001694900682196021\nStep: 1453, epoch: 40.0\nStep: 1454, loss/train: 0.0018040573922917247\nStep: 1454, epoch: 40.0\nStep: 1455, loss/train: 0.0016986969858407974\nStep: 1455, epoch: 40.0\nStep: 1456, loss/train: 0.0017014503246173263\nStep: 1456, epoch: 40.0\nStep: 1457, loss/train: 0.0017135841771960258\nStep: 1457, epoch: 40.0\nStep: 1458, loss/train: 0.0016964217647910118\nStep: 1458, epoch: 40.0\nStep: 1459, loss/train: 0.0016892834100872278\nStep: 1459, epoch: 40.0\nStep: 1460, loss/train: 0.0016942203510552645\nStep: 1460, epoch: 40.0\nStep: 1461, loss/train: 0.001718649989925325\nStep: 1461, epoch: 40.0\nStep: 1462, loss/train: 0.0016973346937447786\nStep: 1462, epoch: 40.0\nStep: 1463, loss/train: 0.001673748018220067\nStep: 1463, epoch: 40.0\nStep: 1464, loss/train: 0.0017039350932464004\nStep: 1464, epoch: 40.0\nStep: 1465, loss/train: 0.0016973861493170261\nStep: 1465, epoch: 40.0\nStep: 1466, loss/train: 0.0016912865685299039\nStep: 1466, epoch: 40.0\nStep: 1467, loss/train: 0.0017072553746402264\nStep: 1467, epoch: 40.0\nStep: 1468, loss/train: 0.001712567638605833\nStep: 1468, epoch: 40.0\nStep: 1469, loss/train: 0.0017026696586981416\nStep: 1469, epoch: 40.0\nStep: 1470, loss/train: 0.0017084642313420773\nStep: 1470, epoch: 40.0\nStep: 1471, loss/train: 0.0017115550581365824\nStep: 1471, epoch: 40.0\nStep: 1472, loss/train: 0.0016910666599869728\nStep: 1472, epoch: 40.0\nStep: 1473, loss/train: 0.001708621857687831\nStep: 1473, epoch: 40.0\nStep: 1474, loss/train: 0.0017495888751000166\nStep: 1474, epoch: 40.0\nStep: 1475, loss/train: 0.001707576448097825\nStep: 1475, epoch: 40.0\nStep: 1475, loss/val: 0.001582572003826499\nStep: 1475, epoch: 40.0\nStep: 1475, roc_auc: 0.9970779418945312\nStep: 1475, opt_thresh: 0.0017089775064960122\nStep: 1475, metrics/tpr: 0.7596899271011353\nStep: 1475, metrics/tnr: 0.8169167637825012\nStep: 1475, metrics/mean: 0.7883033752441406\nStep: 1475, epoch: 40.0\nStep: 1476, loss/train: 0.001684204675257206\nStep: 1476, epoch: 41.0\nStep: 1477, loss/train: 0.0016914409352466464\nStep: 1477, epoch: 41.0\nStep: 1478, loss/train: 0.0016812016256153584\nStep: 1478, epoch: 41.0\nStep: 1479, loss/train: 0.001698866719380021\nStep: 1479, epoch: 41.0\nStep: 1480, loss/train: 0.001719954190775752\nStep: 1480, epoch: 41.0\nStep: 1481, loss/train: 0.0016834614798426628\nStep: 1481, epoch: 41.0\nStep: 1482, loss/train: 0.0017073804046958685\nStep: 1482, epoch: 41.0\nStep: 1483, loss/train: 0.0016840742900967598\nStep: 1483, epoch: 41.0\nStep: 1484, loss/train: 0.0017169067868962884\nStep: 1484, epoch: 41.0\nStep: 1485, loss/train: 0.001696372521109879\nStep: 1485, epoch: 41.0\nStep: 1486, loss/train: 0.0017121436540037394\nStep: 1486, epoch: 41.0\nStep: 1487, loss/train: 0.0016732013318687677\nStep: 1487, epoch: 41.0\nStep: 1488, loss/train: 0.0016889995895326138\nStep: 1488, epoch: 41.0\nStep: 1489, loss/train: 0.0016700706910341978\nStep: 1489, epoch: 41.0\nStep: 1490, loss/train: 0.001678304746747017\nStep: 1490, epoch: 41.0\nStep: 1491, loss/train: 0.0016876000445336103\nStep: 1491, epoch: 41.0\nStep: 1492, loss/train: 0.0016981910448521376\nStep: 1492, epoch: 41.0\nStep: 1493, loss/train: 0.001681040390394628\nStep: 1493, epoch: 41.0\nStep: 1494, loss/train: 0.0016863172641023993\nStep: 1494, epoch: 41.0\nStep: 1495, loss/train: 0.0016821653116494417\nStep: 1495, epoch: 41.0\nStep: 1496, loss/train: 0.0017064769053831697\nStep: 1496, epoch: 41.0\nStep: 1497, loss/train: 0.0016780050937086344\nStep: 1497, epoch: 41.0\nStep: 1498, loss/train: 0.0016722576692700386\nStep: 1498, epoch: 41.0\nStep: 1499, loss/train: 0.0017005179543048143\nStep: 1499, epoch: 41.0\nStep: 1500, loss/train: 0.001753336749970913\nStep: 1500, epoch: 41.0\nStep: 1501, loss/train: 0.001674825674854219\nStep: 1501, epoch: 41.0\nStep: 1502, loss/train: 0.0016720732674002647\nStep: 1502, epoch: 41.0\nStep: 1503, loss/train: 0.001681837602518499\nStep: 1503, epoch: 41.0\nStep: 1504, loss/train: 0.0016795685514807701\nStep: 1504, epoch: 41.0\nStep: 1505, loss/train: 0.0016717081889510155\nStep: 1505, epoch: 41.0\nStep: 1506, loss/train: 0.0016733675729483366\nStep: 1506, epoch: 41.0\nStep: 1507, loss/train: 0.0016738652484491467\nStep: 1507, epoch: 41.0\nStep: 1508, loss/train: 0.0017192927189171314\nStep: 1508, epoch: 41.0\nStep: 1509, loss/train: 0.0016873050481081009\nStep: 1509, epoch: 41.0\nStep: 1510, loss/train: 0.0016713283257558942\nStep: 1510, epoch: 41.0\nStep: 1511, loss/train: 0.001717327511869371\nStep: 1511, epoch: 41.0\nStep: 1511, loss/val: 0.001565613318234682\nStep: 1511, epoch: 41.0\nStep: 1512, loss/train: 0.0016818782314658165\nStep: 1512, epoch: 42.0\nStep: 1513, loss/train: 0.001680209068581462\nStep: 1513, epoch: 42.0\nStep: 1514, loss/train: 0.0016907177632674575\nStep: 1514, epoch: 42.0\nStep: 1515, loss/train: 0.001680984627455473\nStep: 1515, epoch: 42.0\nStep: 1516, loss/train: 0.0016780575970187783\nStep: 1516, epoch: 42.0\nStep: 1517, loss/train: 0.0016677611274644732\nStep: 1517, epoch: 42.0\nStep: 1518, loss/train: 0.0016741817817091942\nStep: 1518, epoch: 42.0\nStep: 1519, loss/train: 0.0016726806061342359\nStep: 1519, epoch: 42.0\nStep: 1520, loss/train: 0.0016870629042387009\nStep: 1520, epoch: 42.0\nStep: 1521, loss/train: 0.0016765339532867074\nStep: 1521, epoch: 42.0\nStep: 1522, loss/train: 0.0016694980440661311\nStep: 1522, epoch: 42.0\nStep: 1523, loss/train: 0.0016661097761243582\nStep: 1523, epoch: 42.0\nStep: 1524, loss/train: 0.0017566853202879429\nStep: 1524, epoch: 42.0\nStep: 1525, loss/train: 0.0016699666157364845\nStep: 1525, epoch: 42.0\nStep: 1526, loss/train: 0.001737585524097085\nStep: 1526, epoch: 42.0\nStep: 1527, loss/train: 0.0016750656068325043\nStep: 1527, epoch: 42.0\nStep: 1528, loss/train: 0.0016621637623757124\nStep: 1528, epoch: 42.0\nStep: 1529, loss/train: 0.0016757952980697155\nStep: 1529, epoch: 42.0\nStep: 1530, loss/train: 0.0016956906765699387\nStep: 1530, epoch: 42.0\nStep: 1531, loss/train: 0.0017308550886809826\nStep: 1531, epoch: 42.0\nStep: 1532, loss/train: 0.0016903956420719624\nStep: 1532, epoch: 42.0\nStep: 1533, loss/train: 0.00166254211217165\nStep: 1533, epoch: 42.0\nStep: 1534, loss/train: 0.0016552709275856614\nStep: 1534, epoch: 42.0\nStep: 1535, loss/train: 0.0016668470343574882\nStep: 1535, epoch: 42.0\nStep: 1536, loss/train: 0.0016758621204644442\nStep: 1536, epoch: 42.0\nStep: 1537, loss/train: 0.0016633040504530072\nStep: 1537, epoch: 42.0\nStep: 1538, loss/train: 0.0016838324954733253\nStep: 1538, epoch: 42.0\nStep: 1539, loss/train: 0.0016594264889135957\nStep: 1539, epoch: 42.0\nStep: 1540, loss/train: 0.001673741266131401\nStep: 1540, epoch: 42.0\nStep: 1541, loss/train: 0.0016611594473943114\nStep: 1541, epoch: 42.0\nStep: 1542, loss/train: 0.0016615049680694938\nStep: 1542, epoch: 42.0\nStep: 1543, loss/train: 0.0016598908696323633\nStep: 1543, epoch: 42.0\nStep: 1544, loss/train: 0.001662139082327485\nStep: 1544, epoch: 42.0\nStep: 1545, loss/train: 0.0017116800881922245\nStep: 1545, epoch: 42.0\nStep: 1546, loss/train: 0.001664995215833187\nStep: 1546, epoch: 42.0\nStep: 1547, loss/train: 0.0016622428083792329\nStep: 1547, epoch: 42.0\nStep: 1547, loss/val: 0.0015504388138651848\nStep: 1547, epoch: 42.0\nStep: 1548, loss/train: 0.0016717250691726804\nStep: 1548, epoch: 43.0\nStep: 1549, loss/train: 0.0016783915925770998\nStep: 1549, epoch: 43.0\nStep: 1550, loss/train: 0.001668088953010738\nStep: 1550, epoch: 43.0\nStep: 1551, loss/train: 0.00171629898250103\nStep: 1551, epoch: 43.0\nStep: 1552, loss/train: 0.001674387138336897\nStep: 1552, epoch: 43.0\nStep: 1553, loss/train: 0.0016808846266940236\nStep: 1553, epoch: 43.0\nStep: 1554, loss/train: 0.001749920193105936\nStep: 1554, epoch: 43.0\nStep: 1555, loss/train: 0.0016552525339648128\nStep: 1555, epoch: 43.0\nStep: 1556, loss/train: 0.0016592607134953141\nStep: 1556, epoch: 43.0\nStep: 1557, loss/train: 0.0016910117119550705\nStep: 1557, epoch: 43.0\nStep: 1558, loss/train: 0.0016694820951670408\nStep: 1558, epoch: 43.0\nStep: 1559, loss/train: 0.0016602040268480778\nStep: 1559, epoch: 43.0\nStep: 1560, loss/train: 0.0016836824361234903\nStep: 1560, epoch: 43.0\nStep: 1561, loss/train: 0.0016777723794803023\nStep: 1561, epoch: 43.0\nStep: 1562, loss/train: 0.0016637984663248062\nStep: 1562, epoch: 43.0\nStep: 1563, loss/train: 0.0016668849857524037\nStep: 1563, epoch: 43.0\nStep: 1564, loss/train: 0.0016578349750488997\nStep: 1564, epoch: 43.0\nStep: 1565, loss/train: 0.0016597895883023739\nStep: 1565, epoch: 43.0\nStep: 1566, loss/train: 0.001675875042565167\nStep: 1566, epoch: 43.0\nStep: 1567, loss/train: 0.001640774542465806\nStep: 1567, epoch: 43.0\nStep: 1568, loss/train: 0.0016480908961966634\nStep: 1568, epoch: 43.0\nStep: 1569, loss/train: 0.0016609721351414919\nStep: 1569, epoch: 43.0\nStep: 1570, loss/train: 0.0016795345582067966\nStep: 1570, epoch: 43.0\nStep: 1571, loss/train: 0.00165549386292696\nStep: 1571, epoch: 43.0\nStep: 1572, loss/train: 0.0016519057098776102\nStep: 1572, epoch: 43.0\nStep: 1573, loss/train: 0.0016598115907981992\nStep: 1573, epoch: 43.0\nStep: 1574, loss/train: 0.001675799023360014\nStep: 1574, epoch: 43.0\nStep: 1575, loss/train: 0.0016569588333368301\nStep: 1575, epoch: 43.0\nStep: 1576, loss/train: 0.001647027675062418\nStep: 1576, epoch: 43.0\nStep: 1577, loss/train: 0.0016833755653351545\nStep: 1577, epoch: 43.0\nStep: 1578, loss/train: 0.0016451472183689475\nStep: 1578, epoch: 43.0\nStep: 1579, loss/train: 0.0016445068176835775\nStep: 1579, epoch: 43.0\nStep: 1580, loss/train: 0.0016505172243341804\nStep: 1580, epoch: 43.0\nStep: 1581, loss/train: 0.0016416697762906551\nStep: 1581, epoch: 43.0\nStep: 1582, loss/train: 0.0016459542093798518\nStep: 1582, epoch: 43.0\nStep: 1583, loss/train: 0.001655662083067\nStep: 1583, epoch: 43.0\nStep: 1583, loss/val: 0.0015385749284178019\nStep: 1583, epoch: 43.0\nStep: 1584, loss/train: 0.00165039103012532\nStep: 1584, epoch: 44.0\nStep: 1585, loss/train: 0.001649051671847701\nStep: 1585, epoch: 44.0\nStep: 1586, loss/train: 0.0016480833292007446\nStep: 1586, epoch: 44.0\nStep: 1587, loss/train: 0.0016417112201452255\nStep: 1587, epoch: 44.0\nStep: 1588, loss/train: 0.0016586885321885347\nStep: 1588, epoch: 44.0\nStep: 1589, loss/train: 0.0016730916686356068\nStep: 1589, epoch: 44.0\nStep: 1590, loss/train: 0.0016671911580488086\nStep: 1590, epoch: 44.0\nStep: 1591, loss/train: 0.0016453837743028998\nStep: 1591, epoch: 44.0\nStep: 1592, loss/train: 0.001658406457863748\nStep: 1592, epoch: 44.0\nStep: 1593, loss/train: 0.0016448922688141465\nStep: 1593, epoch: 44.0\nStep: 1594, loss/train: 0.0016406590584665537\nStep: 1594, epoch: 44.0\nStep: 1595, loss/train: 0.0016518750926479697\nStep: 1595, epoch: 44.0\nStep: 1596, loss/train: 0.0016402986366301775\nStep: 1596, epoch: 44.0\nStep: 1597, loss/train: 0.0016478538746014237\nStep: 1597, epoch: 44.0\nStep: 1598, loss/train: 0.001653668936342001\nStep: 1598, epoch: 44.0\nStep: 1599, loss/train: 0.0016313273226842284\nStep: 1599, epoch: 44.0\nStep: 1600, loss/train: 0.0016432632692158222\nStep: 1600, epoch: 44.0\nStep: 1601, loss/train: 0.0016287241596728563\nStep: 1601, epoch: 44.0\nStep: 1602, loss/train: 0.001637786626815796\nStep: 1602, epoch: 44.0\nStep: 1603, loss/train: 0.0016413924749940634\nStep: 1603, epoch: 44.0\nStep: 1604, loss/train: 0.0016354918479919434\nStep: 1604, epoch: 44.0\nStep: 1605, loss/train: 0.0016357250278815627\nStep: 1605, epoch: 44.0\nStep: 1606, loss/train: 0.0016373293474316597\nStep: 1606, epoch: 44.0\nStep: 1607, loss/train: 0.0016293564112856984\nStep: 1607, epoch: 44.0\nStep: 1608, loss/train: 0.0016342435264959931\nStep: 1608, epoch: 44.0\nStep: 1609, loss/train: 0.0016461822669953108\nStep: 1609, epoch: 44.0\nStep: 1610, loss/train: 0.0016305043827742338\nStep: 1610, epoch: 44.0\nStep: 1611, loss/train: 0.0016435065772384405\nStep: 1611, epoch: 44.0\nStep: 1612, loss/train: 0.001652134582400322\nStep: 1612, epoch: 44.0\nStep: 1613, loss/train: 0.001641138456761837\nStep: 1613, epoch: 44.0\nStep: 1614, loss/train: 0.0016396058490499854\nStep: 1614, epoch: 44.0\nStep: 1615, loss/train: 0.0016370801022276282\nStep: 1615, epoch: 44.0\nStep: 1616, loss/train: 0.0016301433788612485\nStep: 1616, epoch: 44.0\nStep: 1617, loss/train: 0.0016324931057170033\nStep: 1617, epoch: 44.0\nStep: 1618, loss/train: 0.0016342668095603585\nStep: 1618, epoch: 44.0\nStep: 1619, loss/train: 0.0016475663287565112\nStep: 1619, epoch: 44.0\nStep: 1619, loss/val: 0.0015106255887076259\nStep: 1619, epoch: 44.0\n","output_type":"stream"}]},{"cell_type":"code","source":"model.to('cpu')\nmodel.eval()\nprint()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:19:25.338683Z","iopub.execute_input":"2024-01-14T23:19:25.339070Z","iopub.status.idle":"2024-01-14T23:19:25.345926Z","shell.execute_reply.started":"2024-01-14T23:19:25.339042Z","shell.execute_reply":"2024-01-14T23:19:25.344860Z"},"trusted":true},"execution_count":486,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"mse_normal = []\nfor images in val_loader:\n    with torch.inference_mode():\n        out = model(images)\n        mse = F.huber_loss(out, images, reduction='none').mean([1, 2, 3])\n    mse_normal.extend(mse.detach().cpu().numpy())\nmse_normal = np.array(mse_normal)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-14T23:19:25.629314Z","iopub.execute_input":"2024-01-14T23:19:25.630228Z","iopub.status.idle":"2024-01-14T23:19:26.976914Z","shell.execute_reply.started":"2024-01-14T23:19:25.630193Z","shell.execute_reply":"2024-01-14T23:19:26.975690Z"},"trusted":true},"execution_count":487,"outputs":[]},{"cell_type":"code","source":"%%time\nmse_anomaly = []\nfor images in proliv_loader:\n    with torch.inference_mode():\n        out = model(images)\n        mse = F.huber_loss(out, images, reduction='none').mean([1, 2, 3])\n    mse_anomaly.extend(mse.detach().cpu().numpy())\nmse_anomaly = np.array(mse_anomaly)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:19:26.979519Z","iopub.execute_input":"2024-01-14T23:19:26.980330Z","iopub.status.idle":"2024-01-14T23:19:27.469472Z","shell.execute_reply.started":"2024-01-14T23:19:26.980289Z","shell.execute_reply":"2024-01-14T23:19:27.468167Z"},"trusted":true},"execution_count":488,"outputs":[{"name":"stdout","text":"CPU times: user 181 ms, sys: 256 ms, total: 437 ms\nWall time: 480 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"labels = np.array([0] * len(mse_normal) + [1] * len(mse_anomaly))\nmse_values = np.concatenate([mse_normal, mse_anomaly])\nfpr, tpr, thresholds = roc_curve(labels, mse_values)\nroc_auc = auc(fpr, tpr)\noptimal_idx = np.argmax(tpr - fpr)\noptimal_threshold = thresholds[optimal_idx]\n\nplt.figure(figsize=(10, 5))\n\nplt.hist(mse_normal, bins=30, alpha=0.6, color='g', label='Normal')\nplt.hist(mse_anomaly, bins=30, alpha=0.6, color='r', label='Anomaly')\nplt.axvline(optimal_threshold, color='b', linestyle='dashed', linewidth=2)\nplt.title('Распределение ошибок восстановления')\nplt.xlabel('MSE восстановления')\nplt.ylabel('Частота')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:23:48.260924Z","iopub.execute_input":"2024-01-14T23:23:48.261340Z","iopub.status.idle":"2024-01-14T23:23:48.642226Z","shell.execute_reply.started":"2024-01-14T23:23:48.261304Z","shell.execute_reply":"2024-01-14T23:23:48.641289Z"},"trusted":true},"execution_count":505,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"optimal_threshold","metadata":{},"execution_count":129,"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":["0.0023036131"]},"metadata":{}}]},{"cell_type":"code","source":"test_annotation = open(os.path.join(DATA_PATH + '/test/test_annotation.txt')).readlines()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:20:03.270319Z","iopub.execute_input":"2024-01-14T23:20:03.270723Z","iopub.status.idle":"2024-01-14T23:20:03.282445Z","shell.execute_reply.started":"2024-01-14T23:20:03.270691Z","shell.execute_reply":"2024-01-14T23:20:03.281627Z"},"trusted":true},"execution_count":491,"outputs":[]},{"cell_type":"code","source":"os.path.join(DATA_PATH + '/test/test_annotation.txt')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:20:03.460781Z","iopub.execute_input":"2024-01-14T23:20:03.461098Z","iopub.status.idle":"2024-01-14T23:20:03.467144Z","shell.execute_reply.started":"2024-01-14T23:20:03.461070Z","shell.execute_reply":"2024-01-14T23:20:03.466197Z"},"trusted":true},"execution_count":492,"outputs":[{"execution_count":492,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/metal-spill-detection/dataset/test/test_annotation.txt'"},"metadata":{}}]},{"cell_type":"code","source":"test_root = os.path.join(DATA_PATH + '/test/imgs')\ntest_root","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:20:03.638530Z","iopub.execute_input":"2024-01-14T23:20:03.638812Z","iopub.status.idle":"2024-01-14T23:20:03.644916Z","shell.execute_reply.started":"2024-01-14T23:20:03.638787Z","shell.execute_reply":"2024-01-14T23:20:03.643980Z"},"trusted":true},"execution_count":493,"outputs":[{"execution_count":493,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/metal-spill-detection/dataset/test/imgs'"},"metadata":{}}]},{"cell_type":"code","source":"test_fnames = []\ngt_labels = []\nwith open(os.path.join(DATA_PATH + '/test/test_annotation.txt'), 'r') as f:\n    for line in f.readlines():\n        fname, label = line.split()\n        test_fnames.append(fname)\n        gt_labels.append(int(label))","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:20:03.731956Z","iopub.execute_input":"2024-01-14T23:20:03.732209Z","iopub.status.idle":"2024-01-14T23:20:03.742045Z","shell.execute_reply.started":"2024-01-14T23:20:03.732187Z","shell.execute_reply":"2024-01-14T23:20:03.741146Z"},"trusted":true},"execution_count":494,"outputs":[]},{"cell_type":"code","source":"gt_labels = np.array(gt_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:20:04.625206Z","iopub.execute_input":"2024-01-14T23:20:04.625617Z","iopub.status.idle":"2024-01-14T23:20:04.630433Z","shell.execute_reply.started":"2024-01-14T23:20:04.625586Z","shell.execute_reply":"2024-01-14T23:20:04.629451Z"},"trusted":true},"execution_count":495,"outputs":[]},{"cell_type":"code","source":"pred_errors = []\nfor fname in test_fnames:\n    img = Image.open(f\"{test_root}/{fname}\").convert('L')\n    tensor = val_transforms(img)\n    with torch.inference_mode():\n        out = model(tensor.unsqueeze(0))\n        mse = F.huber_loss(out.squeeze(0), tensor)\n        pred_errors.append(mse.item())","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:20:04.789448Z","iopub.execute_input":"2024-01-14T23:20:04.789744Z","iopub.status.idle":"2024-01-14T23:20:14.249793Z","shell.execute_reply.started":"2024-01-14T23:20:04.789710Z","shell.execute_reply":"2024-01-14T23:20:14.248890Z"},"trusted":true},"execution_count":496,"outputs":[]},{"cell_type":"code","source":"pred_errors = np.array(pred_errors)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:20:14.251513Z","iopub.execute_input":"2024-01-14T23:20:14.252481Z","iopub.status.idle":"2024-01-14T23:20:14.257285Z","shell.execute_reply.started":"2024-01-14T23:20:14.252442Z","shell.execute_reply":"2024-01-14T23:20:14.256367Z"},"trusted":true},"execution_count":497,"outputs":[]},{"cell_type":"code","source":"pred_labels = pred_errors > 0.0035","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:26:06.853367Z","iopub.execute_input":"2024-01-14T23:26:06.853775Z","iopub.status.idle":"2024-01-14T23:26:06.858556Z","shell.execute_reply.started":"2024-01-14T23:26:06.853742Z","shell.execute_reply":"2024-01-14T23:26:06.857386Z"},"trusted":true},"execution_count":516,"outputs":[]},{"cell_type":"code","source":"tn, fp, fn, tp = confusion_matrix(gt_labels, pred_labels).ravel()\n\n# Расчет TPR и TNR\ntpr = tp / (tp + fn)\ntnr = tn / (tn + fp)\n\nprint(f\"True Positive Rate (TPR): {tpr:.4f}\")\nprint(f\"True Negative Rate (TNR): {tnr:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-14T23:31:14.639311Z","iopub.execute_input":"2024-01-14T23:31:14.640357Z","iopub.status.idle":"2024-01-14T23:31:14.645446Z","shell.execute_reply.started":"2024-01-14T23:31:14.640319Z","shell.execute_reply":"2024-01-14T23:31:14.644401Z"},"trusted":true},"execution_count":518,"outputs":[{"name":"stdout","text":"True Positive Rate (TPR): 0.9537\nTrue Negative Rate (TNR): 0.9271\n","output_type":"stream"}]},{"cell_type":"code","source":"thresholds = np.linspace(optimal_threshold * 0.5, optimal_threshold * 1.5, 200)\n\ntpr_list = []\ntnr_list = []\n\nfor threshold in thresholds:\n    pred_labels = pred_errors > threshold\n    tn, fp, fn, tp = confusion_matrix(gt_labels, pred_labels).ravel()\n    tpr = tp / (tp + fn)\n    tnr = tn / (tn + fp)\n    tpr_list.append(tpr)\n    tnr_list.append(tnr)\n\nplt.figure(figsize=(8, 6))\nplt.plot(tpr_list, tnr_list, marker='o')\nplt.xlabel('True Positive Rate (TPR)')\nplt.ylabel('True Negative Rate (TNR)')\nplt.grid(True)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}